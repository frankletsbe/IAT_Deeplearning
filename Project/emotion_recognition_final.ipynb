{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5907622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your message\n",
      "âœ… All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Or force flush after prints\n",
    "print(\"Your message\", flush=True)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten, Dropout, Dense, Input, GlobalAveragePooling2D, Conv2D,\n",
    "    BatchNormalization, Activation, MaxPooling2D, Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    ")\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Enable mixed precision\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7e9239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "GPUs found: 0\n",
      "Hostname: xscape7x\n",
      "Built with CUDA: False\n",
      "GPU available: False\n",
      "Global policy: <DTypePolicy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "# Check all available devices\n",
    "\n",
    "import socket\n",
    "\n",
    "\n",
    "print(\"Available devices:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Check GPU specifically\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPUs found: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    print(f\"  {gpu}\")\n",
    "    \n",
    "hostname = socket.gethostname()\n",
    "print(\"Hostname:\", hostname)\n",
    "\n",
    "# Check if GPU is actually being used\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU available:\", tf.test.is_gpu_available())\n",
    "# Enable mixed precision only if a GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision enabled: mixed_float16\")\n",
    "else:\n",
    "    if hostname == \"xscape7x\":\n",
    "        # Enable oneDNN optimizations\n",
    "        tf.config.optimizer.set_jit(True)  # XLA compilation\n",
    "        os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "\n",
    "        # Set thread count for CPU\n",
    "        tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "        tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "\n",
    "        # Use mixed precision for CPU\n",
    "        from tensorflow.keras import mixed_precision\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        mixed_precision.set_global_policy(policy)\n",
    "        mixed_precision.set_global_policy('float32')\n",
    "    else:\n",
    "        print(\"No GPU detected â€” using float32\")\n",
    "        print(\"No acceleration available â€” using float32\")\n",
    "        \n",
    "print(\"Global policy:\", mixed_precision.global_policy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92809734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========================================================================\n",
    "# Clean Configuration System\n",
    "# =========================================================================\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Clean configuration class with backbone-specific presets\"\"\"\n",
    "    \n",
    "    BACKBONE_PRESETS = {\n",
    "        'custom_cnn': {\n",
    "            'picture_size': 48,\n",
    "            'color_mode': 'grayscale',\n",
    "            'batch_size': 64,\n",
    "            'epochs': 50,\n",
    "            'learning_rate': 0.001,\n",
    "            'dropout_rate': 0.25,\n",
    "            'dense_units': [512],\n",
    "            'aug_level': 'light',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "        },\n",
    "        'mobilenet': {\n",
    "            'picture_size': 96,\n",
    "            'color_mode': 'rgb',\n",
    "            'batch_size': 32,\n",
    "            'epochs': 30,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.3,\n",
    "            'dense_units': [512, 256],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'fine_tune': True,\n",
    "            'fine_tune_epochs': 20,\n",
    "            'fine_tune_unfreeze_layers': 30,\n",
    "        },\n",
    "        'efficientnet': {\n",
    "            'picture_size': 128,\n",
    "            'color_mode': 'rgb',\n",
    "            'batch_size': 16,\n",
    "            'epochs': 40,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.4,\n",
    "            'dense_units': [1024, 512],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'fine_tune': True,\n",
    "            'fine_tune_epochs': 25,\n",
    "            'fine_tune_unfreeze_layers': 50,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    AUGMENTATION_LEVELS = {\n",
    "        'none': dict(rescale=1./255),\n",
    "        'light': dict(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True\n",
    "        ),\n",
    "        'strong': dict(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.2,\n",
    "            brightness_range=[0.7, 1.3],\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, backbone='mobilenet'):\n",
    "        \"\"\"Initialize with backbone preset\"\"\"\n",
    "        if backbone not in self.BACKBONE_PRESETS:\n",
    "            raise ValueError(f\"Backbone must be one of {list(self.BACKBONE_PRESETS.keys())}\")\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.config = self.BACKBONE_PRESETS[backbone].copy()\n",
    "        self.config['backbone'] = backbone\n",
    "        self.config['no_of_classes'] = 7\n",
    "        \n",
    "    def get(self, key, default=None):\n",
    "        \"\"\"Get configuration value\"\"\"\n",
    "        return self.config.get(key, default)\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        \"\"\"Set configuration value\"\"\"\n",
    "        self.config[key] = value\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Return full configuration\"\"\"\n",
    "        return self.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f0f3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Data Loading Utilities\n",
    "# =========================================================================\n",
    "\n",
    "def get_data_path():\n",
    "    \"\"\"Get data path based on environment\"\"\"\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        import kagglehub\n",
    "        image_path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
    "        return os.path.join(image_path, \"images\")\n",
    "    else:\n",
    "        return \"data/images/\"\n",
    "\n",
    "def create_data_generators(config, data_path):\n",
    "    \"\"\"Create clean data generators\"\"\"\n",
    "    \n",
    "    # Get augmentation parameters\n",
    "    aug_params = config.AUGMENTATION_LEVELS[config.get('aug_level', 'light')]\n",
    "    \n",
    "    # Handle preprocessing based on backbone\n",
    "    if config.backbone in ['mobilenet', 'efficientnet']:\n",
    "        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "        aug_params = aug_params.copy()\n",
    "        aug_params['preprocessing_function'] = preprocess_input\n",
    "    \n",
    "    # Create generators\n",
    "    train_gen = ImageDataGenerator(**aug_params)\n",
    "    val_gen = ImageDataGenerator(**aug_params)\n",
    "    \n",
    "    # Determine color mode\n",
    "    color_mode = config.get('color_mode', 'grayscale')\n",
    "    \n",
    "    train_set = train_gen.flow_from_directory(\n",
    "        os.path.join(data_path, \"train\"),\n",
    "        target_size=(config.get('picture_size'), config.get('picture_size')),\n",
    "        color_mode=color_mode,\n",
    "        batch_size=config.get('batch_size'),\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    validation_set = val_gen.flow_from_directory(\n",
    "        os.path.join(data_path, \"validation\"),\n",
    "        target_size=(config.get('picture_size'), config.get('picture_size')),\n",
    "        color_mode=color_mode,\n",
    "        batch_size=config.get('batch_size'),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    print(\"Train image shape:\", train_set.image_shape)\n",
    "    print(\"Val image shape:  \", validation_set.image_shape)\n",
    "\n",
    "    print(f\"\\nâœ… Data loaded successfully\")\n",
    "    print (f\"Colour Mode: {color_mode}\")\n",
    "    print(f\"Training samples: {train_set.n}\")\n",
    "    print(f\"Validation samples: {validation_set.n}\")\n",
    "    print(f\"Class indices: {train_set.class_indices}\")\n",
    "    \n",
    "    return train_set, validation_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee255750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Model Building\n",
    "# =========================================================================\n",
    "\n",
    "def build_custom_cnn(config):\n",
    "    \"\"\"Build custom CNN model\"\"\"\n",
    "    picture_size = config.get('picture_size')\n",
    "    color_mode = config.get('color_mode')\n",
    "    channels = 1 if color_mode == 'grayscale' else 3\n",
    "    \n",
    "    model = Sequential()\n",
    "   # Block 1 - Double Conv\n",
    "    model.add(Conv2D(filters=32, \n",
    "                        kernel_size=(3, 3), \n",
    "                        padding='same', \n",
    "                        input_shape=input_shape,\n",
    "                        name='conv2d_1'))\n",
    "\n",
    "    # Block 2 - Double Conv\n",
    "    model.add(Conv2D(filters=128, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_2'))\n",
    "    model.add(BatchNormalization(name='bn_2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_2'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_2'))\n",
    "    \n",
    "    # Block 3 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(5, 5), \n",
    "                      padding='same',\n",
    "                      name='conv2d_3'))\n",
    "    model.add(BatchNormalization(name='bn_3'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_3'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_3'))\n",
    "    \n",
    "    # Block 4 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_4'))\n",
    "    model.add(BatchNormalization(name='bn_4'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_4'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_4'))\n",
    "\n",
    "    \n",
    "    # Block 5 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_5'))\n",
    "    model.add(BatchNormalization(name='bn_5'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_5'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_5'))\n",
    " \n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layers\n",
    "    for units in config.get('dense_units', [512]):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(config.get('dropout_rate')))\n",
    "    \n",
    "    model.add(Dense(config.get('no_of_classes'), activation='softmax', dtype='float32'))\n",
    "    \n",
    "    return model, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d2ae43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_transfer_model(config, backbone_class):\n",
    "    \"\"\"Build transfer learning model\"\"\"\n",
    "    picture_size = config.get('picture_size')\n",
    "    color_mode = config.get('color_mode')\n",
    "    channels = 1 if color_mode == 'grayscale' else 3\n",
    "    \n",
    "    inputs = Input(shape=(picture_size, picture_size, channels))\n",
    "    \n",
    "    # Convert grayscale to RGB if needed\n",
    "    if channels == 1:\n",
    "        x = Lambda(lambda z: tf.image.grayscale_to_rgb(z))(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "    \n",
    "    # Load pre-trained backbone\n",
    "    base_model = backbone_class(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(picture_size, picture_size, 3)\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(config.get('dropout_rate'))(x)\n",
    "    \n",
    "    # Add dense layers\n",
    "    for units in config.get('dense_units', [512]):\n",
    "        x = Dense(units, activation='relu')(x)\n",
    "        x = Dropout(config.get('dropout_rate'))(x)\n",
    "    \n",
    "    outputs = Dense(config.get('no_of_classes'), activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model, base_model\n",
    "\n",
    "def build_model(config):\n",
    "    \"\"\"Build model based on configuration\"\"\"\n",
    "    backbone = config.backbone\n",
    "    \n",
    "    if backbone == 'custom_cnn':\n",
    "        return build_custom_cnn(config)\n",
    "    elif backbone == 'mobilenet':\n",
    "        return build_transfer_model(config, MobileNetV2)\n",
    "    elif backbone == 'efficientnet':\n",
    "        return build_transfer_model(config, EfficientNetB0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477ff386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Training Utilities\n",
    "# =========================================================================\n",
    "\n",
    "def create_callbacks(config):\n",
    "    \"\"\"Create training callbacks\"\"\"\n",
    "    callbacks = [\n",
    "        ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_delta=0.0001)\n",
    "    ]\n",
    "    \n",
    "    if config.get('use_lr_schedule'):\n",
    "        def cosine_annealing(epoch, lr):\n",
    "            initial_lr = float(config.get('learning_rate'))\n",
    "            min_lr = 1e-7\n",
    "            warmup = 5\n",
    "            total_epochs = config.get('epochs')\n",
    "            \n",
    "            if epoch < warmup:\n",
    "                return initial_lr * (epoch + 1) / warmup\n",
    "            \n",
    "            progress = (epoch - warmup) / (total_epochs - warmup)\n",
    "            lr_out = min_lr + (initial_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "            return max(lr_out, min_lr)\n",
    "        \n",
    "        callbacks.append(LearningRateScheduler(cosine_annealing))\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def compute_class_weights(train_set):\n",
    "    \"\"\"Compute class weights for imbalanced data\"\"\"\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_set.classes),\n",
    "        y=train_set.classes\n",
    "    )\n",
    "    return dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51a087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: xscape7x\n",
      "Overiding settings for xscape7x...\n",
      "==================================================\n",
      "Configuration: MOBILENET\n",
      "==================================================\n",
      "picture_size        : 96\n",
      "color_mode          : rgb\n",
      "batch_size          : 32\n",
      "epochs              : 1\n",
      "learning_rate       : 0.0001\n",
      "dropout_rate        : 0.3\n",
      "dense_units         : [512, 256]\n",
      "aug_level           : strong\n",
      "use_class_weights   : True\n",
      "use_lr_schedule     : True\n",
      "fine_tune           : True\n",
      "fine_tune_epochs    : 1\n",
      "fine_tune_unfreeze_layers: 1\n",
      "backbone            : mobilenet\n",
      "no_of_classes       : 7\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# Run Training \n",
    "# =========================================================================\n",
    "\n",
    "# Simple usage\n",
    "config = ModelConfig(\"mobilenet\")  # or 'custom_cnn', 'efficientnet'\n",
    "\n",
    "\n",
    "import socket\n",
    "\n",
    "if hostname  == \"xscape7x\": # local machine\n",
    "    print(\"Hostname:\", hostname)\n",
    "    print(\"Overiding settings for xscape7x...\")\n",
    "    # Override any settings\n",
    "    if config.backbone == \"mobilenet\":\n",
    "        config.set(\"epochs\", 1)\n",
    "        config.set(\"batch_size\", 32)\n",
    "        config.set(\"fine_tune_epochs\", 1)\n",
    "        config.set(\"fine_tune_unfreeze_layers\", 1)\n",
    "    else:\n",
    "        config.set(\"epochs\", 1)\n",
    "        config.set(\"batch_size\", 32)\n",
    "else:                                           # run on remote server\n",
    "    pass  # No overrides\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Configuration: {config.backbone.upper()}\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in config.config.items():\n",
    "    print(f\"{key:20}: {value}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcba24b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder path: data/images/\n",
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n",
      "Train image shape: (96, 96, 3)\n",
      "Val image shape:   (96, 96, 3)\n",
      "\n",
      "âœ… Data loaded successfully\n",
      "Colour Mode: rgb\n",
      "Training samples: 28821\n",
      "Validation samples: 7066\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "Train image shape: (96, 96, 3)\n",
      "Val image shape:   (96, 96, 3)\n",
      "\n",
      "âœ… Data loaded successfully\n",
      "Colour Mode: rgb\n",
      "Training samples: 28821\n",
      "Validation samples: 7066\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "== Full Model ====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ mobilenetv2_1.00_96             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ mobilenetv2_1.00_96             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m655,872\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              â”‚         \u001b[38;5;34m1,799\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,046,983</span> (11.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,046,983\u001b[0m (11.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,999</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m788,999\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Building model with 'mobilenet' backbone...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train\n",
    "# model, history, train_set, val_set = train_model(config)\n",
    "\n",
    "# =========================================================================\n",
    "# Compile Model and Load Data\n",
    "# =========================================================================\n",
    "\n",
    "# Setup\n",
    "data_path = get_data_path()\n",
    "print(f\"Data folder path: {data_path}\")\n",
    "\n",
    "train_set, validation_set = create_data_generators(config, data_path)\n",
    "\n",
    "print(\"Train image shape:\", train_set.image_shape)\n",
    "print(\"Val image shape:  \", validation_set.image_shape)\n",
    "\n",
    "print(f\"\\nâœ… Data loaded successfully\")\n",
    "print (f\"Colour Mode: {config.config.get('color_mode')}\")    \n",
    "print(f\"Training samples: {train_set.n}\")\n",
    "print(f\"Validation samples: {validation_set.n}\")\n",
    "print(f\"Class indices: {train_set.class_indices}\")\n",
    "\n",
    "# Build model\n",
    "model, base_model = build_model(config)\n",
    "\n",
    "# Validate shapes\n",
    "assert train_set.image_shape == model.input_shape[1:], (\n",
    "    f\"Shape mismatch: {train_set.image_shape} vs {model.input_shape[1:]}\")\n",
    "\n",
    "#print (\"== Base Model ====\")\n",
    "#base_model.summary()\n",
    "print (\"== Full Model ====\")\n",
    "model.summary()\n",
    "\n",
    "# Compile\n",
    "optimizer = Adam(learning_rate=config.get(\"learning_rate\"))\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Building model with '{config.get('backbone')}' backbone...\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35159155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Callbacks configured: 4 callbacks\n",
      "Training mobilenet model...\n",
      "\n",
      "======================================================================\n",
      "ğŸš€ STARTING TRAINING\n",
      "======================================================================\n",
      "Target: 1 epochs with early stopping\n",
      "Batch size: 32\n",
      "Learning rate: 0.0001\n",
      "Augmentation: strong\n",
      "Backbone: mobilenet\n",
      "Class weights: Enabled\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marty\\anaconda3\\envs\\tf311_env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# Train the Model Stage 1\n",
    "# =========================================================================\n",
    "# Class weights\n",
    "class_weights = None\n",
    "if config.get(\"use_class_weights\"):\n",
    "    class_weights = compute_class_weights(train_set)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = create_callbacks(config)\n",
    "print(f\"âœ… Callbacks configured: {len(callbacks)} callbacks\")\n",
    "\n",
    "# Training\n",
    "print(f\"Training {config.backbone} model...\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Target: {config.get('epochs')} epochs with early stopping\")\n",
    "print(f\"Batch size: {config.get('batch_size')}\")\n",
    "print(f\"Learning rate: {config.get('learning_rate')}\")\n",
    "print(f\"Augmentation: {config.get('aug_level')}\")\n",
    "print(f\"Backbone: {config.get('backbone')}\")\n",
    "print(f\"Class weights: {'Enabled' if class_weights else 'Disabled'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Stage 1: Train head\n",
    "history_head = model.fit(\n",
    "    train_set,\n",
    "    epochs=config.get(\"epochs\"),\n",
    "    validation_data=validation_set,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Train the Model Stage 2 - Fine Tuning\n",
    "# =========================================================================\n",
    "# Stage 2: Fine-tune (if transfer learning)\n",
    "if base_model and config.get(\"fine_tune\"):\n",
    "    print(\"Fine-tuning...\")\n",
    "\n",
    "    # Unfreeze layers\n",
    "    unfreeze_layers = config.get(\"fine_tune_unfreeze_layers\", 30)\n",
    "    for layer in base_model.layers[unfreeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile with lower LR\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=config.get(\"learning_rate\") * 0.1),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Continue training\n",
    "    history = model.fit(\n",
    "        train_set,\n",
    "        epochs=config.get(\"epochs\") + config.get(\"fine_tune_epochs\", 0),\n",
    "        initial_epoch=config.get(\"epochs\"),\n",
    "        validation_data=validation_set,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27153cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Save Model\n",
    "# =========================================================================\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"emotion_recognition_{timestamp}.keras\"\n",
    "\n",
    "if os.path.exists('/kaggle/input')\n",
    "    output_dir = \"/kaggle/working/\" + timestamp + \"/\"  \n",
    "else:\n",
    "    output_dir = \"outputs/\" + timestamp + \"/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "out_path = Path(output_dir) / model_name\n",
    "try:   \n",
    "    model.save(str(out_path))\n",
    "    print(f\"\\nğŸ’¾ Model saved: {out_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00cb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Evaluate the Model\n",
    "# =========================================================================\n",
    "# Evaluate\n",
    "val_loss, val_acc = model.evaluate(validation_set)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a148d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Extract Values from the Model\n",
    "# =========================================================================\n",
    "history = history if history is not None else history_head\n",
    "\n",
    "# Helper to safely get values\n",
    "def get_vals(h, key):\n",
    "    return h.history.get(key, []) if h is not None else []\n",
    "\n",
    "head_acc = get_vals(history_head, 'accuracy')\n",
    "head_val_acc = get_vals(history_head, 'val_accuracy')\n",
    "head_loss = get_vals(history_head, 'loss')\n",
    "head_val_loss = get_vals(history_head, 'val_loss')\n",
    "\n",
    "ft_acc = get_vals(history, 'accuracy')\n",
    "ft_val_acc = get_vals(history, 'val_accuracy')\n",
    "ft_loss = get_vals(history, 'loss')\n",
    "ft_val_loss = get_vals(history, 'val_loss')\n",
    "\n",
    "train_acc = head_acc + ft_acc\n",
    "val_acc   = head_val_acc + ft_val_acc\n",
    "train_loss = head_loss + ft_loss\n",
    "val_loss = head_val_loss + ft_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# After training\n",
    "# history_head, history_ft = train_two_stage(...)\n",
    "\n",
    "print (\"plot both stages combined (recommended so plots show full training curve):\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].plot(train_set, label='Train Accuracy', linewidth=2)\n",
    "axes[0].plot(val_acc, label='Val Accuracy', linewidth=2)\n",
    "axes[0].set_title('Model Accuracy'); axes[0].legend(); axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(train_loss, label='Train Loss', linewidth=2)\n",
    "axes[1].plot(val_loss, label='Val Loss', linewidth=2)\n",
    "axes[1].set_title('Model Loss'); axes[1].legend(); axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'training_curve_head.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "#print(f\"ğŸ“Š Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Training History Visualization\n",
    "# =======================================================================\n",
    "\n",
    "# 1) Get scalar evaluation results from the model (safe)\n",
    "train_loss, train_acc = model.evaluate(train_set, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(validation_set, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š FINAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"Training Loss:       {train_loss:.4f}\")\n",
    "print(f\"Validation Loss:     {val_loss:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 2) Consolidate histories (head + fine-tune) for plotting if present\n",
    "def _get_hist_list(h):\n",
    "    return h.history if h is not None else {}\n",
    "\n",
    "head_hist = history_head if 'history_head' in globals() else None\n",
    "ft_hist = history_ft if 'history_ft' in globals() else None\n",
    "\n",
    "# Combine metrics safely\n",
    "def _concat_metric(metric):\n",
    "    vals = []\n",
    "    if head_hist is not None:\n",
    "        vals += head_hist.history.get(metric, [])\n",
    "    if ft_hist is not None:\n",
    "        vals += ft_hist.history.get(metric, [])\n",
    "    return vals\n",
    "\n",
    "train_acc_list = _concat_metric('accuracy')\n",
    "val_acc_list = _concat_metric('val_accuracy')\n",
    "train_loss_list = _concat_metric('loss')\n",
    "val_loss_list = _concat_metric('val_loss')\n",
    "\n",
    "def plot_training_history(history_data):\n",
    "    \"\"\"Plot training history with better formatting.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[0].plot(history_data['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0].plot(history_data['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0].set_title('Model Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[1].plot(history_data['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[1].plot(history_data['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[1].set_title('Model Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_curve_full.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Prepare history data dictionary for plotting\n",
    "history_data = {\n",
    "    'accuracy': train_acc_list,\n",
    "    'val_accuracy': val_acc_list,\n",
    "    'loss': train_loss_list,\n",
    "    'val_loss': val_loss_list\n",
    "}\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š FINAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"Training Loss:       {train_loss:.4f}\")\n",
    "print(f\"Validation Loss:     {val_loss:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80015392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Performance Visualizations\n",
    "# =======================================================================\n",
    "# Add this before the visualization section\n",
    "# before visualization\n",
    "validation_set.reset()\n",
    "preds = model.predict(validation_set, verbose=0)\n",
    "predicted_classes = np.argmax(preds, axis=1)\n",
    "true_classes = validation_set.classes\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray')\n",
    "plt.title('Confusion Matrix - Emotion Recognition', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_path, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Normalized Confusion Matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Percentage'})\n",
    "plt.title('Normalized Confusion Matrix (%)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_path, 'confusion_matrix_normalized.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ DETAILED CLASSIFICATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                           target_names=class_labels,\n",
    "                           digits=4))\n",
    "\n",
    "# 4. Per-Class Metrics Bar Chart\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    true_classes, predicted_classes, labels=range(7)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "x = np.arange(len(class_labels))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, precision, width, label='Precision', color='#3498db')\n",
    "bars2 = ax.bar(x, recall, width, label='Recall', color='#2ecc71')\n",
    "bars3 = ax.bar(x + width, f1, width, label='F1-Score', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Emotion', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Per-Emotion Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_path, 'per_class_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Summary Table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Emotion': class_labels,\n",
    "    'Precision': [f'{p:.2%}' for p in precision],\n",
    "    'Recall': [f'{r:.2%}' for r in recall],\n",
    "    'F1-Score': [f'{f:.2%}' for f in f1],\n",
    "    'Support': support.astype(int)\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š PERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 6. Misclassification Analysis\n",
    "misclassified = cm.copy()\n",
    "np.fill_diagonal(misclassified, 0)\n",
    "\n",
    "top_confusions = []\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        if i != j:\n",
    "            top_confusions.append((class_labels[i], class_labels[j], misclassified[i, j]))\n",
    "\n",
    "top_confusions.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš ï¸  TOP 5 MISCLASSIFICATION PAIRS\")\n",
    "print(\"=\"*70)\n",
    "for true_label, pred_label, count in top_confusions[:5]:\n",
    "    print(f\"{true_label:>10} â†’ {pred_label:<10} : {count:>4} times\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Sample Predictions Visualization\n",
    "# =======================================================================\n",
    "import random\n",
    "\n",
    "# Get a random batch from validation set\n",
    "random_batch_idx = random.randint(0, len(validation_set) - 1)\n",
    "sample_images, sample_labels = validation_set[random_batch_idx]\n",
    "\n",
    "# Predict\n",
    "sample_preds = model.predict(sample_images, verbose=0)\n",
    "sample_pred_classes = np.argmax(sample_preds, axis=1)\n",
    "sample_true_classes = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "# Randomly select 16 indices from the batch\n",
    "num_samples = min(16, len(sample_images))\n",
    "random_indices = random.sample(range(len(sample_images)), num_samples)\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    axes[i].imshow(sample_images[idx].squeeze(), cmap='gray')\n",
    "    \n",
    "    true_label = class_labels[sample_true_classes[idx]]\n",
    "    pred_label = class_labels[sample_pred_classes[idx]]\n",
    "    confidence = sample_preds[idx][sample_pred_classes[idx]] * 100\n",
    "\n",
    "    # Color: green if correct, red if wrong\n",
    "    color = 'green' if sample_true_classes[idx] == sample_pred_classes[idx] else 'red'\n",
    "    \n",
    "    axes[i].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
    "                     color=color, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_path, 'sample_predictions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Global policy:\", mixed_precision.global_policy())\n",
    "print(\"Model dtype policy:\", model.dtype_policy)   # or model.input_dtype / model.output_dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
