{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e63eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0134c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hostname():\n",
    "        \n",
    "    print(\"Available devices:\")\n",
    "    hostname = socket.gethostname()\n",
    "    return hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2daa59c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n"
     ]
    }
   ],
   "source": [
    "skip_if_set_local_env_done=True\n",
    "\n",
    "if get_hostname() == \"xscape7x\" and skip_if_set_local_env_done is False:\n",
    "\n",
    "    print(\"üîÑ Snapdragon X Elite detected - optimizing for CPU\")\n",
    "\n",
    "    # Use environment variables instead (set before TF init)\n",
    "    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "    os.environ['OMP_NUM_THREADS'] = '8'\n",
    "    os.environ['TF_NUM_INTEROP_THREADS'] = '8'\n",
    "    os.environ['TF_NUM_INTRAOP_THREADS'] = '8'\n",
    "    # Restart Python kernel after setting these\n",
    "    print(\"‚úÖ Environment configured - restart kernel for full effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13765dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 22:13:26.205134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763244806.352563      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763244806.395331      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs found: 2\n",
      " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "#print(tf.config.list_physical_devices())\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPUs found: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    print(f\" {gpu}\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a536b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# At the top of your notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import socket\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten, Dropout, Dense, Input, GlobalAveragePooling2D, Conv2D,\n",
    "    BatchNormalization, Activation, MaxPooling2D, Lambda\n",
    ")\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    ")\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "try:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad0affc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.18.0\n",
      "Keras version: 3.8.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0f3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Data Loading Utilities\n",
    "# =========================================================================\n",
    "def is_on_kaggle():\n",
    "    \"\"\"Detect if running on Kaggle.\"\"\"\n",
    "    return os.path.exists('/kaggle/input')\n",
    "\n",
    "def get_data_path():\n",
    "    \"\"\"Detect environment and return appropriate data path.\"\"\"\n",
    "    if is_on_kaggle():\n",
    "        print(\"üåê Running on Kaggle\")\n",
    "        import kagglehub\n",
    "        image_path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
    "        folder_path = os.path.join(image_path, \"images\")\n",
    "    else:\n",
    "        print(\"üíª Running on local machine\")\n",
    "        folder_path = \"data/images/\"\n",
    "    \n",
    "    return folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee255750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Model Building\n",
    "# =========================================================================\n",
    "\n",
    "def build_custom_cnn(config):\n",
    "    \"\"\"Build custom CNN model\"\"\"\n",
    "    picture_size = config.get('picture_size')\n",
    "    color_mode = config.get('color_mode')\n",
    "    channels = 1 if color_mode == 'grayscale' else 3\n",
    "    input_shape=(picture_size,picture_size,channels)\n",
    "    dropout_rate = config.get('dropout_rate')\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "   # Block 1 - Double Conv\n",
    "    model.add(Conv2D(filters=32, \n",
    "                        kernel_size=(3, 3), \n",
    "                        padding='same', \n",
    "                        input_shape=input_shape,\n",
    "                        name='conv2d_1',\n",
    "                        activation='relu'))\n",
    "\n",
    "    # Block 2 - Double Conv\n",
    "    model.add(Conv2D(filters=64, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_2'))\n",
    "    model.add(BatchNormalization(name='bn_2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_2'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_2'))\n",
    "    \n",
    "    # Block 3 - Double Conv\n",
    "    model.add(Conv2D(filters=128, \n",
    "                      kernel_size=(5, 5), \n",
    "                      padding='same',\n",
    "                      name='conv2d_3'))\n",
    "    model.add(BatchNormalization(name='bn_3'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_3'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_3'))\n",
    "    \n",
    "    # Block 4 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_4',\n",
    "                      kernel_regularizer=regularizers.l2(0.01)\n",
    "                      ))\n",
    "    model.add(BatchNormalization(name='bn_4'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_4'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_4'))\n",
    "\n",
    "    \n",
    "    # Block 5 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_5',\n",
    "                      kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization(name='bn_5'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_5'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_5'))\n",
    "    \n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layers\n",
    "    for units in config.get('dense_units', config.get('dense_units')):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(config.get('dropout_rate')))\n",
    "    \n",
    "        model.add(Dense(config.get('no_of_classes'), activation='softmax'))\n",
    "    \n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2ae43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transfer_model(config, backbone_class):\n",
    "    \"\"\"Build transfer learning model for MobileNetV2 / EfficientNetB0.\"\"\"\n",
    "    picture_size = config.get('picture_size')\n",
    "    color_mode = config.get('color_mode')\n",
    "\n",
    "    # Determine if this is EfficientNet\n",
    "    is_efficientnet = backbone_class is EfficientNetB0\n",
    "    \n",
    "\n",
    "    # EfficientNetB0 expects 224x224 RGB\n",
    "    if is_efficientnet:\n",
    "        backbone_input_size = 224\n",
    "        backbone_channels = 3\n",
    "    else:\n",
    "        backbone_input_size = picture_size\n",
    "        backbone_channels = 3  # we‚Äôll convert grayscale to RGB if needed\n",
    "\n",
    "    # Our model input\n",
    "    channels = 1 if (color_mode == 'grayscale' and not is_efficientnet) else 3\n",
    "    inputs = Input(shape=(backbone_input_size, backbone_input_size, channels))\n",
    "\n",
    "    # Convert grayscale to RGB for non-EfficientNet cases only\n",
    "    if channels == 1:\n",
    "        x = Lambda(lambda z: tf.image.grayscale_to_rgb(z))(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Backbone always sees RGB (3 channels)\n",
    "    base_model = backbone_class(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(backbone_input_size, backbone_input_size, 3),\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(config.get('dropout_rate'))(x)\n",
    "\n",
    "    for units in config.get('dense_units', [512]):\n",
    "        x = Dense(units, activation='relu')(x)\n",
    "        x = Dropout(config.get('dropout_rate'))(x)\n",
    "\n",
    "    outputs = Dense(\n",
    "        config.get('no_of_classes'),\n",
    "        activation='softmax',\n",
    "        dtype='float32'\n",
    "    )(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54dd3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(config):\n",
    "    \"\"\"Build model based on configuration\"\"\"\n",
    "    backbone = config.backbone\n",
    "    \n",
    "    if backbone == 'custom_cnn':\n",
    "        return build_custom_cnn(config)\n",
    "    elif backbone == 'mobilenet':\n",
    "        return build_transfer_model(config, MobileNetV2)\n",
    "    elif backbone == 'efficientnet':\n",
    "        return build_transfer_model(config, EfficientNetB0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "477ff386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Training Utilities\n",
    "# =========================================================================\n",
    "\n",
    "def create_callbacks(config):\n",
    "    \"\"\"Create training callbacks\"\"\"\n",
    "    callbacks = [\n",
    "        ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_delta=0.0001)\n",
    "    ]\n",
    "    \n",
    "    if config.get('use_lr_schedule'):\n",
    "        def cosine_annealing(epoch, lr):\n",
    "            initial_lr = float(config.get('learning_rate'))\n",
    "            min_lr = 1e-7\n",
    "            warmup = 5\n",
    "            total_epochs = config.get('epochs')\n",
    "            \n",
    "            if epoch < warmup:\n",
    "                return initial_lr * (epoch + 1) / warmup\n",
    "            \n",
    "            progress = (epoch - warmup) / (total_epochs - warmup)\n",
    "            lr_out = min_lr + (initial_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "            return max(lr_out, min_lr)\n",
    "        \n",
    "        callbacks.append(LearningRateScheduler(cosine_annealing))\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def compute_class_weights(train_set):\n",
    "    \"\"\"Compute class weights for imbalanced data\"\"\"\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_set.classes),\n",
    "        y=train_set.classes\n",
    "    )\n",
    "    return dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6981b",
   "metadata": {},
   "source": [
    "<h1> Run Training </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488ef876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_dir():\n",
    "    # - create output folder and provide output path\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    if os.path.exists('/kaggle/working'):\n",
    "        output_dir = \"/kaggle/working/\" + timestamp + \"/\"  \n",
    "    else:\n",
    "        output_dir = \"outputs/\" + timestamp + \"/\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print (f\"Output directory: {output_dir}\")\n",
    "    return output_dir, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bef5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name_prefix, output_dir, folder_name):\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"{model_name_prefix}_{folder_name}.keras\"\n",
    "    out_path = Path(output_dir) / model_name\n",
    "    try:\n",
    "        model.save(str(out_path))\n",
    "        print(f\"\\nüíæ Model saved: {out_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "    \n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c896cd",
   "metadata": {},
   "source": [
    "<h1>Load Model and Generate Reports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b398f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_path():\n",
    "    import os,re, glob\n",
    "    from pathlib import Path\n",
    "    from datetime import datetime\n",
    "    \n",
    "     # ensure these are always defined\n",
    "    latest_ft = None\n",
    "    latest_dir = None\n",
    "\n",
    "    # Detect environment and set base directory\n",
    "    if os.path.exists('/kaggle/working'):\n",
    "        base_dir = \"/kaggle/working\"\n",
    "        print(\"üåê Running on Kaggle - searching in /kaggle/working\")\n",
    "    else:\n",
    "        base_dir=\"outputs\"\n",
    "        print(\"üíª Running locally - searching in outputs/\")\n",
    "    \n",
    "    # Find all valid .keras files\n",
    "    search_pattern = os.path.join(base_dir, \"*/*.keras\")\n",
    "    valid_files = [\n",
    "        f for f in glob.glob(search_pattern)\n",
    "            if re.match(r'^\\d{8}_\\d{6}$', os.path.basename(os.path.dirname(f)))\n",
    "            ]\n",
    "\n",
    "    if not valid_files:\n",
    "        print(f\"‚ùå No valid .keras files found in {base_dir}\")\n",
    "        \n",
    "    else:\n",
    "        # Find latest timestamp\n",
    "        latest = max(valid_files, key=lambda x: datetime.strptime(\n",
    "            os.path.basename(os.path.dirname(x)), \"%Y%m%d_%H%M%S\"\n",
    "        ))\n",
    "        latest_dir = os.path.dirname(latest)\n",
    "\n",
    "        # Look for ft variants in the same latest directory\n",
    "        ft_pattern = os.path.join(latest_dir, \"*_ft_*.keras\")\n",
    "        ft_files = glob.glob(ft_pattern)\n",
    "        \n",
    "        latest_ft = ft_files[0] if ft_files else None\n",
    "\n",
    "        print(f\"Latest directory: {latest_dir}\")\n",
    "        print(f\"Latest FT model: {latest_ft}\")\n",
    "    \n",
    "    return latest_ft, latest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "086c0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_from_file(path_ft):\n",
    "    from tensorflow.keras.models import load_model\n",
    "    \n",
    "    model_ft=load_model(path_ft)\n",
    "\n",
    "    return model_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history_ft):\n",
    "    \"\"\"\n",
    "    Plot training history.\n",
    "    - If only history_hd exists: plot that.\n",
    "    - If only history_ft exists: plot that.\n",
    "    - If both exist: concatenate them (head + fine‚Äëtune).\n",
    "    \"\"\"\n",
    "    # Helper to safely get metric arrays\n",
    "    def get_vals(h, key):\n",
    "        return h.history.get(key, []) if h is not None else []\n",
    "\n",
    "    # Concatenate if both present\n",
    "    train_acc  = get_vals(history_ft, 'accuracy')\n",
    "    val_acc    = get_vals(history_ft, 'val_accuracy')\n",
    "    train_loss = get_vals(history_ft, 'loss')\n",
    "    val_loss   = get_vals(history_ft, 'val_loss')\n",
    "\n",
    "    if not any([train_acc, val_acc, train_loss, val_loss]):\n",
    "        print(\"‚ö†Ô∏è No training metrics available to plot\")\n",
    "        return None\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Accuracy plot\n",
    "    if train_acc:\n",
    "        axes[0].plot(train_acc, label='Train Accuracy')\n",
    "    if val_acc:\n",
    "        axes[0].plot(val_acc, label='Val Accuracy')\n",
    "    axes[0].set_title('Model Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Loss plot\n",
    "    if train_loss:\n",
    "        axes[1].plot(train_loss, label='Train Loss')\n",
    "    if val_loss:\n",
    "        axes[1].plot(val_loss, label='Val Loss')\n",
    "    axes[1].set_title('Model Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d12a7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_final_evaluation(train_acc, val_acc, train_loss, val_loss):\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä FINAL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    print(f\"Training Loss:       {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss:     {val_loss:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaef6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Sample Predictions Visualization\n",
    "# =======================================================================\n",
    "\n",
    "def test_random_predictions(model, validation_set, class_labels):\n",
    "\n",
    "    import random\n",
    "\n",
    "    # Get a random batch from validation set\n",
    "    random_batch_idx = random.randint(0, len(validation_set) - 1)\n",
    "    sample_images, sample_labels = validation_set[random_batch_idx]\n",
    "\n",
    "    # Predict\n",
    "    sample_preds = model.predict(sample_images, verbose=0)\n",
    "    sample_pred_classes = np.argmax(sample_preds, axis=1)\n",
    "    sample_true_classes = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "    # Randomly select 16 indices from the batch\n",
    "    num_samples = min(16, len(sample_images))\n",
    "    random_indices = random.sample(range(len(sample_images)), num_samples)\n",
    "\n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        axes[i].imshow(sample_images[idx].squeeze(), cmap='gray')\n",
    "        \n",
    "        true_label = class_labels[sample_true_classes[idx]]\n",
    "        pred_label = class_labels[sample_pred_classes[idx]]\n",
    "        confidence = sample_preds[idx][sample_pred_classes[idx]] * 100\n",
    "\n",
    "        # Color: green if correct, red if wrong\n",
    "        color = 'green' if sample_true_classes[idx] == sample_pred_classes[idx] else 'red'\n",
    "        \n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
    "                        color=color, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle('Sample Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192618b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf5916b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Enhanced Model Evaluation and Reporting\n",
    "# =========================================================================\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation and report generation\"\"\"\n",
    "    \n",
    "    def __init__(self, model, test_set, class_labels, output_dir=None, save_outputs=False):\n",
    "        self.model = model\n",
    "        self.test_set = test_set\n",
    "        self.class_labels = class_labels\n",
    "        self.output_dir = output_dir\n",
    "        self.save_outputs=save_outputs\n",
    "        \n",
    " \n",
    "        \n",
    "        # Initialize prediction attributes\n",
    "        self.predictions = None\n",
    "        self.true_labels = None\n",
    "        self.pred_labels = None\n",
    "        \n",
    "    def save_output(self):\n",
    "        out_path = Path(self.output_dir) \n",
    "        try:\n",
    "            plt.savefig(os.path.join(out_path,f\"{self.fig_name}.png\"),dpi=300,bbox_inches='tight')\n",
    "            print(f\"\\nüíæ Plot saved: {out_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving report: {e}\")\n",
    "        return out_path   \n",
    "        \n",
    "    def generate_predictions(self):\n",
    "        \"\"\"Generate predictions on test set\"\"\"\n",
    "        print(\"üîÑ Generating predictions...\")\n",
    "        self.test_set.reset()\n",
    "        \n",
    "        self.predictions = self.model.predict(self.test_set, verbose=1)\n",
    "        self.true_labels = self.test_set.classes\n",
    "        self.pred_labels = np.argmax(self.predictions, axis=1)\n",
    "        \n",
    "        return self.predictions, self.true_labels\n",
    "    \n",
    "    def create_comprehensive_report(self):\n",
    "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "        if self.predictions is None:\n",
    "            self.generate_predictions()\n",
    "        \n",
    "          \n",
    "        # Generate all reports\n",
    "        self.plot_training_history()\n",
    "        self.plot_confusion_matrix()\n",
    "        self.plot_normalized_confusion_matrix()\n",
    "        self.generate_classification_report()\n",
    "        self.plot_per_class_metrics()\n",
    "        self.plot_roc_curves()\n",
    "        self.plot_precision_recall_curves()\n",
    "        self.generate_error_analysis()\n",
    "        self.create_summary_report()\n",
    "    \n",
    "    \"\"\"\n",
    "    Traning history chart will only get returned if training history in memory\n",
    "    \"\"\"    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history with head and fine-tune stages\"\"\"\n",
    "        if not hasattr(self.model, 'history'):\n",
    "            print(\"‚ö†Ô∏è No training history provided\")\n",
    "            return None\n",
    "            \n",
    "        # Combine histories\n",
    "        def _concat_metric(metric):\n",
    "            vals = []\n",
    "            if self.model is not None:\n",
    "                vals += self.model.history.get(metric, [])\n",
    "            return vals\n",
    "\n",
    "        train_acc = _concat_metric('accuracy')\n",
    "        val_acc = _concat_metric('val_accuracy')\n",
    "        train_loss = _concat_metric('loss')\n",
    "        val_loss = _concat_metric('val_loss')\n",
    "        \n",
    "        if not any([train_acc, val_acc, train_loss, val_loss]):\n",
    "            print(\"‚ö†Ô∏è No training metrics found in history\")\n",
    "            return None\n",
    "            \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        if train_acc:\n",
    "            axes[0].plot(train_acc, label='Train Accuracy', linewidth=2, color='blue')\n",
    "        if val_acc:\n",
    "            axes[0].plot(val_acc, label='Validation Accuracy', linewidth=2, color='red')\n",
    "        axes[0].set_title('Model Accuracy Over Training')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Accuracy')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss plot\n",
    "        if train_loss:\n",
    "            axes[1].plot(train_loss, label='Train Loss', linewidth=2, color='blue')\n",
    "        if val_loss:\n",
    "            axes[1].plot(val_loss, label='Validation Loss', linewidth=2, color='red')\n",
    "        axes[1].set_title('Model Loss Over Training')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Loss')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add vertical line to show fine-tuning start if applicable\n",
    "        if self.model is not None:\n",
    "            hd_epochs = len(self.model.history.get('loss', []))\n",
    "            axes[0].axvline(x=hd_epochs, color='green', linestyle='--', alpha=0.7, label='Fine-tune start')\n",
    "            axes[1].axvline(x=hd_epochs, color='green', linestyle='--', alpha=0.7, label='Fine-tune start')\n",
    "            axes[0].legend()\n",
    "            axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        self.fig_name = \"training_history\"\n",
    "        plt.show     \n",
    "        if self.save_outputs==True: self.save_output()\n",
    "        plt.close\n",
    "        return self.figure, self.fig_name\n",
    "    \n",
    "    def plot_confusion_matrix(self):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(self.true_labels, self.pred_labels)\n",
    "        \n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=self.class_labels,\n",
    "                   yticklabels=self.class_labels)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show\n",
    "        self.figure=plt\n",
    "        self.fig_name = \"confusion_matrix\"\n",
    "        if self.save_outputs==True: self.save_output()\n",
    "        plt.close\n",
    "        return self.figure, self.fig_name\n",
    "        \n",
    "    def plot_normalized_confusion_matrix(self):\n",
    "        \"\"\"Plot normalized confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(self.true_labels, self.pred_labels)\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "                   xticklabels=self.class_labels,\n",
    "                   yticklabels=self.class_labels)\n",
    "        plt.title('Confusion Matrix-Normalized')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show\n",
    "        self.figure=plt\n",
    "        self.fig_name = \"confusion_matrix_normalised\"\n",
    "        if self.save_outputs==True: self.save_output()\n",
    "        plt.close\n",
    "        return self.figure, self.fig_name\n",
    "        \n",
    "    def generate_classification_report(self):\n",
    "        \"\"\"Generate detailed classification report\"\"\"\n",
    "        report = classification_report(\n",
    "            self.true_labels, \n",
    "            self.pred_labels,\n",
    "            target_names=self.class_labels,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        # Save as JSON\n",
    "        if self.save_outputs:\n",
    "            with open(os.path.join(self.output_dir, 'classification_report.json'), 'w') as f:\n",
    "                json.dump(report, f, indent=2)\n",
    "            \n",
    "        # Save as CSV\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv(os.path.join(self.output_dir, 'classification_report.csv'))\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(\n",
    "            self.true_labels, \n",
    "            self.pred_labels,\n",
    "            target_names=self.class_labels\n",
    "        ))\n",
    "        \n",
    "    def plot_per_class_metrics(self):\n",
    "        \"\"\"Plot precision, recall, and F1-score per class\"\"\"\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            self.true_labels, self.pred_labels, average=None\n",
    "        )\n",
    "        \n",
    "        x = np.arange(len(self.class_labels))\n",
    "        width = 0.25\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        bars1 = ax.bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
    "        bars2 = ax.bar(x, recall, width, label='Recall', alpha=0.8)\n",
    "        bars3 = ax.bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Emotion Classes')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_title('Per-Class Performance Metrics')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(self.class_labels, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bars in [bars1, bars2, bars3]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show\n",
    "        self.figure=plt\n",
    "        self.fig_name = \"per_class_metrics\"\n",
    "        if self.save_outputs==True: self.save_output()\n",
    "        plt.close\n",
    "        return self.figure, self.fig_name\n",
    "            \n",
    "    def plot_roc_curves(self):\n",
    "        \"\"\"Plot ROC curves for multi-class classification\"\"\"\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        \n",
    "        # Binarize labels\n",
    "        y_test_bin = label_binarize(self.true_labels, classes=range(len(self.class_labels)))\n",
    "        \n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        for i in range(len(self.class_labels)):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], self.predictions[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(self.class_labels)))\n",
    "        \n",
    "        for i, color in zip(range(len(self.class_labels)), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                    label=f'{self.class_labels[i]} (AUC = {roc_auc[i]:0.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves-Multi-class')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show\n",
    "        self.figure=plt\n",
    "        self.fig_name = \"roc_curves\"\n",
    "        if self.save_outputs==True: self.save_output()\n",
    "        plt.close\n",
    "        return self.figure, self.fig_name      \n",
    "    \n",
    "    def plot_precision_recall_curves(self):\n",
    "        \"\"\"Plot precision-recall curves for multi-class classification\"\"\"\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "        \n",
    "        # Binarize labels\n",
    "        y_test_bin = label_binarize(self.true_labels, classes=range(len(self.class_labels)))\n",
    "        \n",
    "        # Compute precision-recall curve and average precision for each class\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        average_precision = dict()\n",
    "        \n",
    "        for i in range(len(self.class_labels)):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(\n",
    "                y_test_bin[:, i], self.predictions[:, i]\n",
    "            )\n",
    "            average_precision[i] = average_precision_score(\n",
    "                y_test_bin[:, i], self.predictions[:, i]\n",
    "            )\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(self.class_labels)))\n",
    "        \n",
    "        for i, color in zip(range(len(self.class_labels)), colors):\n",
    "            plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "                    label=f'{self.class_labels[i]} (AP = {average_precision[i]:0.2f})')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curves-Multi-class')\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show\n",
    "        self.figure=plt\n",
    "        self.fig_name = \"precision-recall-multi\"\n",
    "        if self.save_outputs==True: self.save_output()\n",
    "        \n",
    "        # Also create micro-average precision-recall curve\n",
    "        precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n",
    "            y_test_bin.ravel(), self.predictions.ravel()\n",
    "        )\n",
    "        average_precision[\"micro\"] = average_precision_score(\n",
    "            y_test_bin, self.predictions, average=\"micro\"\n",
    "        )\n",
    "        \n",
    "        # Plot micro-average\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2,\n",
    "                label=f'Micro-average (AP = {average_precision[\"micro\"]:0.2f})')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve-Micro-average')\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt_prm=plt\n",
    "        plt_prm_name = \"precision-recall-micro\"\n",
    "        plt.show\n",
    "        self.figure=plt\n",
    "        self.fig_name = \"precision-recall-microi\"\n",
    "        if self.save_outputs==True: self.save_output()\n",
    "        plt.close\n",
    "        return self.figure, self.fig_name    \n",
    "      \n",
    "    def generate_error_analysis(self):\n",
    "        \"\"\"Analyze misclassifications\"\"\"\n",
    "        errors = self.true_labels != self.pred_labels\n",
    "        error_indices = np.where(errors)[0]\n",
    "        \n",
    "        if len(error_indices) > 0:\n",
    "            # Get error details\n",
    "            error_details = []\n",
    "            for idx in error_indices[:50]:  # Limit to first 50 errors\n",
    "                true_class = self.class_labels[self.true_labels[idx]]\n",
    "                pred_class = self.class_labels[self.pred_labels[idx]]\n",
    "                confidence = self.predictions[idx][self.pred_labels[idx]]\n",
    "                \n",
    "                error_details.append({\n",
    "                    'index': idx,\n",
    "                    'true_class': true_class,\n",
    "                    'pred_class': pred_class,\n",
    "                    'confidence': confidence,\n",
    "                    'image_path': self.test_set.filepaths[idx] if hasattr(self.test_set, 'filepaths') else None\n",
    "                })\n",
    "            \n",
    "            # Save error analysis\n",
    "            error_df = pd.DataFrame(error_details)\n",
    "            error_df.to_csv(os.path.join(self.output_dir, 'error_analysis.csv'), index=False)\n",
    "            \n",
    "            # Print top misclassifications\n",
    "            print(\"\\nüîç Top 5 Misclassifications:\")\n",
    "            print(\"=\"*50)\n",
    "            for _, row in error_df.head().iterrows():\n",
    "                print(f\"True: {row['true_class']} ‚Üí Pred: {row['pred_class']} \"\n",
    "                      f\"(Confidence: {row['confidence']:.2%})\")\n",
    "                        \n",
    "    def create_summary_report(self):\n",
    "        \"\"\"Create comprehensive summary report\"\"\"\n",
    "        summary = {\n",
    "            'model_name': self.model.name,\n",
    "            'test_samples': len(self.true_labels),\n",
    "            'overall_accuracy': np.mean(self.true_labels == self.pred_labels),\n",
    "            'class_labels': self.class_labels,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Add per-class metrics\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            self.true_labels, self.pred_labels, average=None\n",
    "        )\n",
    "        \n",
    "        summary['per_class_metrics'] = {\n",
    "            label: {\n",
    "                'precision': float(p),\n",
    "                'recall': float(r),\n",
    "                'f1_score': float(f),\n",
    "                'support': int(s)\n",
    "            }\n",
    "            for label, p, r, f, s in zip(self.class_labels, precision, recall, f1, support)\n",
    "        }\n",
    "        \n",
    "        # Save summary\n",
    "        with open(os.path.join(self.output_dir, 'summary_report.json'), 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "            \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66f60a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_charts(evaluator, output_dir):\n",
    "     \n",
    "    plt_cm, plot_name= evaluator.plot_confusion_matrix()\n",
    "    save_plot(plt_cm, plot_name,output_dir)\n",
    "    plt_cm.close\n",
    "    \n",
    "    plt_cm_norm, plot_name = evaluator.plot_normalized_confusion_matrix()\n",
    "    save_plot(plt_cm_norm, plot_name,output_dir)\n",
    "    plt_cm_norm.close\n",
    "    \n",
    "    plt_prm, plot_name_prm, plt_prc, plot_name_prc=evaluator.plot_precision_recall_curves()\n",
    "    save_plot(plt_prm, plot_name_prm,output_dir)\n",
    "    save_plot(plt_prc, plot_name_prc,output_dir)\n",
    "    plt_prm.close\n",
    "    plt_prc.close\n",
    "    \n",
    "    plt_class, plot_name= evaluator.plot_per_class_metrics()\n",
    "    save_plot(plt_class, plot_name,output_dir)\n",
    "    plt_class.close\n",
    "    \n",
    "    plt_roc, plot_name= evaluator.plot_roc_curves()\n",
    "    save_plot(plt_roc, plot_name,output_dir)\n",
    "    plt_roc.close\n",
    "    \n",
    "    \"\"\"\n",
    "    plots=[plt_cm, plt_cm_norm, plt_prm, plt_prc, plt_class, plt_roc]\n",
    "    \n",
    "    \n",
    "    for fig in plots:\n",
    "        if fig is None:\n",
    "            continue\n",
    "        fig.show()\n",
    "        save_plot(fig, plot_name,output_dir)\n",
    "        fig.close\n",
    "    \n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8750765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_mobilenet(config, train_set, validation_set):\n",
    "\n",
    "    # =========================================================================\n",
    "    # Load Data & Compile Model  \n",
    "    # =========================================================================\n",
    "\n",
    "    # Generate training and validation Set\n",
    "    print(\"Train image shape:\", train_set.image_shape)\n",
    "    print(\"Val image shape:  \", validation_set.image_shape)\n",
    "\n",
    "    print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "    print (f\"Colour Mode: {config.config.get('color_mode')}\")    \n",
    "    print(f\"Training samples: {train_set.n}\")\n",
    "    print(f\"Validation samples: {validation_set.n}\")\n",
    "    print(f\"Class indices: {train_set.class_indices}\")\n",
    "\n",
    "    history_ft= None\n",
    "    history_hd=None\n",
    "    # Build model\n",
    "    model, base_model = build_model(config)\n",
    "\n",
    "    # Validate shapes\n",
    "    assert train_set.image_shape == model.input_shape[1:], (\n",
    "        f\"Shape mismatch: {train_set.image_shape} vs {model.input_shape[1:]}\")\n",
    "\n",
    "    # Compile with optimizer choice\n",
    "    optimizer_name =  \"adam\"\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = Adam(learning_rate=config.get('learning_rate'))\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        opt = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=config.get('learning_rate'),\n",
    "            weight_decay=config.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt = tf.keras.optimizers.SGD(\n",
    "            learning_rate=config.get('learning_rate'),\n",
    "            momentum=0.9,\n",
    "            nesterov=True\n",
    "        )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    #print (\"== Base Model ====\")\n",
    "    \n",
    "    print (\"== Base Model ====\")\n",
    "    model.summary()\n",
    "    #base_model.summary()\n",
    "    \n",
    "    if config.get(\"use_class_weights\"):\n",
    "        class_weights = compute_class_weights(train_set)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = create_callbacks(config)\n",
    "    print(f\"‚úÖ Callbacks configured: {len(callbacks)} callbacks\")\n",
    "    \n",
    "\n",
    "    # Stage 1: Train head\n",
    "    print(f\"Training {config.backbone} model...\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ STARTING TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Target: {config.get('epochs')} epochs with early stopping\")\n",
    "    print(f\"Batch size: {config.get('batch_size')}\")\n",
    "    print(f\"Learning rate: {config.get('learning_rate')}\")\n",
    "    print(f\"Augmentation: {config.get('aug_level')}\")\n",
    "    print(f\"Backbone: {config.get('backbone')}\")\n",
    "    print(f\"Class weights: {'Enabled' if class_weights else 'Disabled'}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    \n",
    "    history_hd = model.fit(\n",
    "        train_set,\n",
    "        epochs=config.get(\"epochs\"),\n",
    "        validation_data=validation_set,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1,\n",
    "    )    \n",
    "    # save_model(model,'emotion_recognition_hd', output_dir, folder_name)\n",
    "    \n",
    "    \n",
    "    # Stage 2: Fine-tune (if transfer learning)\n",
    "    # for mobilenet backbone     \n",
    "    if base_model is not None and config.get(\"fine_tune\"):\n",
    "    \n",
    "        print(\"Fine-tuning...\")\n",
    "\n",
    "        # Unfreeze layers\n",
    "        unfreeze_layers = config.get(\"fine_tune_unfreeze_layers\", 30)\n",
    "        for layer in base_model.layers[unfreeze_layers:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Recompile with lower LR\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=config.get(\"learning_rate\") * 0.1),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        # Continue training\n",
    "        history_ft = model.fit(\n",
    "            train_set,\n",
    "            epochs=config.get(\"epochs\") + config.get(\"fine_tune_epochs\", 0),\n",
    "            initial_epoch=config.get(\"epochs\"),\n",
    "            validation_data=validation_set,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weights,\n",
    "            verbose=1,\n",
    "        ) \n",
    "    else:\n",
    "        history_ft= None\n",
    "    # save_model(model, 'emotion_recognition_ft', output_dir, folder_name)\n",
    "\n",
    "    return model, history_hd, history_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ae2f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cnn(config, train_set, validation_set):\n",
    "\n",
    "    # =========================================================================\n",
    "    # Load Data & Compile Model  \n",
    "    # =========================================================================\n",
    "\n",
    "    # Generate training and validation Set\n",
    "    print(\"Train image shape:\", train_set.image_shape)\n",
    "    print(\"Val image shape:  \", validation_set.image_shape)\n",
    "\n",
    "    print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "    print (f\"Colour Mode: {config.config.get('color_mode')}\")    \n",
    "    print(f\"Training samples: {train_set.n}\")\n",
    "    print(f\"Validation samples: {validation_set.n}\")\n",
    "    print(f\"Class indices: {train_set.class_indices}\")\n",
    "\n",
    "    history_ft= None\n",
    "    \n",
    "    # Build model\n",
    "    model, base_model = build_model(config)\n",
    "\n",
    "    # Validate shapes\n",
    "    assert train_set.image_shape == model.input_shape[1:], (\n",
    "        f\"Shape mismatch: {train_set.image_shape} vs {model.input_shape[1:]}\")\n",
    "\n",
    "    # Compile with optimizer choice\n",
    "    optimizer_name =  \"adam\"\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = Adam(learning_rate=config.get('learning_rate'))\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        opt = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=config.get('learning_rate'),\n",
    "            weight_decay=config.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt = tf.keras.optimizers.SGD(\n",
    "            learning_rate=config.get('learning_rate'),\n",
    "            momentum=0.9,\n",
    "            nesterov=True\n",
    "        )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    #print (\"== Base Model ====\")\n",
    "    \n",
    "    print (\"== Base Model ====\")\n",
    "    model.summary()\n",
    "    #base_model.summary()\n",
    "    \n",
    "    if config.get(\"use_class_weights\"):\n",
    "        class_weights = compute_class_weights(train_set)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = create_callbacks(config)\n",
    "    print(f\"‚úÖ Callbacks configured: {len(callbacks)} callbacks\")\n",
    "    \n",
    "\n",
    "    # Stage 1: Train head\n",
    "    print(f\"Training {config.backbone} model...\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ STARTING TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Target: {config.get('epochs')} epochs with early stopping\")\n",
    "    print(f\"Batch size: {config.get('batch_size')}\")\n",
    "    print(f\"Learning rate: {config.get('learning_rate')}\")\n",
    "    print(f\"Augmentation: {config.get('aug_level')}\")\n",
    "    print(f\"Backbone: {config.get('backbone')}\")\n",
    "    print(f\"Class weights: {'Enabled' if class_weights else 'Disabled'}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    \n",
    "    history_ft = model.fit(\n",
    "        train_set,\n",
    "        epochs=config.get(\"epochs\"),\n",
    "        validation_data=validation_set,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1,\n",
    "    )    \n",
    "\n",
    "\n",
    "    return model, history_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a786ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data_generators(config, data_path):\n",
    "    \"\"\"Create clean data generators\"\"\"\n",
    "    \n",
    "    # Get augmentation parameters\n",
    "    aug_params = config.AUGMENTATION_LEVELS[config.get('aug_level', 'light')]\n",
    "    \n",
    "    # Handle preprocessing based on backbone\n",
    "    if config.backbone in ['mobilenet', 'efficientnet']:\n",
    "        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "        aug_params = aug_params.copy()\n",
    "        aug_params['preprocessing_function'] = preprocess_input\n",
    "    \n",
    "    # Create generators\n",
    "    train_gen = ImageDataGenerator(**aug_params)\n",
    "    val_gen = ImageDataGenerator(**aug_params)\n",
    "    \n",
    "    # Determine color mode\n",
    "    color_mode = config.get('color_mode', 'grayscale')\n",
    "    \n",
    "    train_set = train_gen.flow_from_directory(\n",
    "        os.path.join(data_path, \"train\"),\n",
    "        target_size=(config.get('picture_size'), config.get('picture_size')),\n",
    "        color_mode=config.get('color_mode'),   \n",
    "        batch_size=config.get('batch_size'),\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    validation_set = val_gen.flow_from_directory(\n",
    "        os.path.join(data_path, \"validation\"),\n",
    "        target_size=(config.get('picture_size'), config.get('picture_size')),\n",
    "        color_mode=config.get('color_mode'),   \n",
    "        batch_size=config.get('batch_size'),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    print(\"Train image shape:\", train_set.image_shape)\n",
    "    print(\"Val image shape:  \", validation_set.image_shape)\n",
    "\n",
    "    print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "    print (f\"Colour Mode: {color_mode}\")\n",
    "    print(f\"Training samples: {train_set.n}\")\n",
    "    print(f\"Validation samples: {validation_set.n}\")\n",
    "    print(f\"Class indices: {train_set.class_indices}\")\n",
    "    \n",
    "    return train_set, validation_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1eb56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "#  Configuration System\n",
    "# =========================================================================\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Clean configuration class with backbone-specific presets\"\"\"\n",
    "    \n",
    "    BACKBONE_PRESETS = {\n",
    "        'custom_cnn': {\n",
    "            'picture_size': 48,\n",
    "            'color_mode': 'grayscale',\n",
    "            'batch_size': 64,\n",
    "            'epochs': 50,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.25,\n",
    "            'dense_units': [256,512],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'weight_decay':1e-4\n",
    "        },\n",
    "        'mobilenet': {\n",
    "            'picture_size': 96,\n",
    "            'color_mode': 'rgb',\n",
    "            'batch_size': 32,\n",
    "            'epochs': 30,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.3,\n",
    "            'dense_units': [512, 256],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'fine_tune': True,\n",
    "            'fine_tune_epochs': 20,\n",
    "            'fine_tune_unfreeze_layers': 30,\n",
    "            'weight_decay':1e-4,\n",
    "            'weights': 'imagenet'\n",
    "        },\n",
    "        'efficientnet': {\n",
    "            'picture_size': 224,       # \n",
    "            'color_mode': 'rgb',\n",
    "            'batch_size': 16,\n",
    "            'epochs': 40,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.4,\n",
    "            'dense_units': [1024, 512],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'fine_tune': True,\n",
    "            'fine_tune_epochs': 25,\n",
    "            'fine_tune_unfreeze_layers': 50,\n",
    "            'weight_decay': 1e-4,\n",
    "            'weights': None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    AUGMENTATION_LEVELS = {\n",
    "        'none': dict(rescale=1./255),\n",
    "        'light': dict(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            #zoom_range=0.2,\n",
    "            horizontal_flip=True\n",
    "        ),\n",
    "        'strong': dict(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.2,\n",
    "            brightness_range=[0.7, 1.3],\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, backbone='mobilenet'):\n",
    "        \"\"\"Initialize with backbone preset\"\"\"\n",
    "        if backbone not in self.BACKBONE_PRESETS:\n",
    "            raise ValueError(f\"Backbone must be one of {list(self.BACKBONE_PRESETS.keys())}\")\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.config = self.BACKBONE_PRESETS[backbone].copy()\n",
    "        self.config['backbone'] = backbone\n",
    "        self.config['no_of_classes'] = 7\n",
    "        \n",
    "    def get(self, key, default=None):\n",
    "        \"\"\"Get configuration value\"\"\"\n",
    "        return self.config.get(key, default)\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        \"\"\"Set configuration value\"\"\"\n",
    "        self.config[key] = value\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Return full configuration\"\"\"\n",
    "        return self.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6168b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "#  Overide\n",
    "# =========================================================================\n",
    "def set_host_config_overides(config):\n",
    "    \n",
    "    hostname = get_hostname() \n",
    "    \n",
    "    print(\"Hostname:\", hostname)\n",
    "    #print(\"Overiding settings for xscape7x...\")\n",
    "    # Override any settings\n",
    "    config.set(\"epochs\",50)\n",
    "    config.set(\"batch_size\", 128)\n",
    "    config.set(\"learning_rate\", 0.0001)\n",
    "    config.set('dense_units', [256,512])\n",
    "    config.set('aug_level', \"light\")\n",
    "    config.set(\"fine_tune_epochs\", 6)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Configuration: {config.backbone.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in config.config.items():\n",
    "        print(f\"{key:20}: {value}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c1675",
   "metadata": {},
   "source": [
    "    Last Run\n",
    "    \n",
    "    config.set(\"epochs\",50)\n",
    "    config.set(\"batch_size\", 128)\n",
    "    config.set(\"learning_rate\", 0.0001)\n",
    "    config.set('dense_units', [256,512])\n",
    "    config.set('aug_level', \"light\")\n",
    "    config.set(\"fine_tune_epochs\", 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d39444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "GPUs found: 2\n",
      "Final policy: <DTypePolicy \"mixed_float16\">\n",
      "Output directory: /kaggle/working/20251115_221351/\n",
      "üåê Running on Kaggle\n",
      "Available devices:\n",
      "Hostname: 81e918139afb\n",
      "==================================================\n",
      "Configuration: CUSTOM_CNN\n",
      "==================================================\n",
      "picture_size        : 48\n",
      "color_mode          : grayscale\n",
      "batch_size          : 128\n",
      "epochs              : 50\n",
      "learning_rate       : 0.0001\n",
      "dropout_rate        : 0.25\n",
      "dense_units         : [256, 512]\n",
      "aug_level           : light\n",
      "use_class_weights   : True\n",
      "use_lr_schedule     : True\n",
      "weight_decay        : 0.0001\n",
      "backbone            : custom_cnn\n",
      "no_of_classes       : 7\n",
      "fine_tune_epochs    : 6\n",
      "==================================================\n",
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n",
      "Train image shape: (48, 48, 1)\n",
      "Val image shape:   (48, 48, 1)\n",
      "\n",
      "‚úÖ Data loaded successfully\n",
      "Colour Mode: grayscale\n",
      "Training samples: 28821\n",
      "Validation samples: 7066\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "Train image shape: (48, 48, 1)\n",
      "Val image shape:   (48, 48, 1)\n",
      "\n",
      "‚úÖ Data loaded successfully\n",
      "Colour Mode: grayscale\n",
      "Training samples: 28821\n",
      "Validation samples: 7066\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1763244853.818188      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1763244853.818875      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Base Model ====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_1           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     ‚îÇ           \u001b[38;5;34m320\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ        \u001b[38;5;34m18,496\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ           \u001b[38;5;34m256\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation (\u001b[38;5;33mActivation\u001b[0m)         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ       \u001b[38;5;34m204,928\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_3 (\u001b[38;5;33mBatchNormalization\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ           \u001b[38;5;34m512\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    ‚îÇ       \u001b[38;5;34m590,336\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_4 (\u001b[38;5;33mBatchNormalization\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    ‚îÇ         \u001b[38;5;34m2,048\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      ‚îÇ     \u001b[38;5;34m2,359,808\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bn_5 (\u001b[38;5;33mBatchNormalization\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      ‚îÇ         \u001b[38;5;34m2,048\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ maxpool2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)      ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)      ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten (\u001b[38;5;33mFlatten\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ     \u001b[38;5;34m1,179,904\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ         \u001b[38;5;34m1,024\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              ‚îÇ         \u001b[38;5;34m1,799\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            ‚îÇ         \u001b[38;5;34m4,096\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_1           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            ‚îÇ         \u001b[38;5;34m2,048\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              ‚îÇ         \u001b[38;5;34m3,591\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,371,214</span> (16.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,371,214\u001b[0m (16.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,367,246</span> (16.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,367,246\u001b[0m (16.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> (15.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,968\u001b[0m (15.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Callbacks configured: 4 callbacks\n",
      "Training custom_cnn model...\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING TRAINING\n",
      "======================================================================\n",
      "Target: 50 epochs with early stopping\n",
      "Batch size: 128\n",
      "Learning rate: 0.0001\n",
      "Augmentation: light\n",
      "Backbone: custom_cnn\n",
      "Class weights: Enabled\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763244863.814817     125 service.cc:148] XLA service 0x7d4a6400de80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763244863.815519     125 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763244863.815541     125 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763244864.807108     125 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/226\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m1:24:10\u001b[0m 22s/step - accuracy: 0.1797 - loss: 9.5692"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763244880.091688     125 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.1538 - loss: 9.3631 - val_accuracy: 0.0157 - val_loss: 9.0014 - learning_rate: 2.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 199ms/step - accuracy: 0.1620 - loss: 9.0329 - val_accuracy: 0.0238 - val_loss: 8.7115 - learning_rate: 4.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 209ms/step - accuracy: 0.1725 - loss: 8.6388 - val_accuracy: 0.1537 - val_loss: 8.2614 - learning_rate: 6.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 203ms/step - accuracy: 0.1807 - loss: 8.0997 - val_accuracy: 0.2552 - val_loss: 7.5460 - learning_rate: 8.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 199ms/step - accuracy: 0.1950 - loss: 7.3889 - val_accuracy: 0.1018 - val_loss: 6.8295 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 197ms/step - accuracy: 0.1942 - loss: 6.5874 - val_accuracy: 0.0593 - val_loss: 6.2095 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 198ms/step - accuracy: 0.2107 - loss: 5.8470 - val_accuracy: 0.2491 - val_loss: 5.3079 - learning_rate: 9.9878e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 196ms/step - accuracy: 0.2390 - loss: 5.1448 - val_accuracy: 0.2160 - val_loss: 4.7239 - learning_rate: 9.9514e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 196ms/step - accuracy: 0.2522 - loss: 4.5516 - val_accuracy: 0.1318 - val_loss: 4.3580 - learning_rate: 9.8908e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 204ms/step - accuracy: 0.2853 - loss: 3.9995 - val_accuracy: 0.3330 - val_loss: 3.6378 - learning_rate: 9.8065e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 221ms/step - accuracy: 0.3230 - loss: 3.5439 - val_accuracy: 0.3299 - val_loss: 3.2920 - learning_rate: 9.6988e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 225ms/step - accuracy: 0.3370 - loss: 3.1647 - val_accuracy: 0.3858 - val_loss: 2.8730 - learning_rate: 9.5682e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 226ms/step - accuracy: 0.3449 - loss: 2.8940 - val_accuracy: 0.3330 - val_loss: 2.7541 - learning_rate: 9.4153e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 221ms/step - accuracy: 0.3680 - loss: 2.6486 - val_accuracy: 0.3667 - val_loss: 2.5452 - learning_rate: 9.2410e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 203ms/step - accuracy: 0.4034 - loss: 2.1361 - val_accuracy: 0.4427 - val_loss: 2.0033 - learning_rate: 8.5981e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 198ms/step - accuracy: 0.4051 - loss: 2.0592 - val_accuracy: 0.3868 - val_loss: 2.0749 - learning_rate: 8.3473e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 198ms/step - accuracy: 0.4126 - loss: 1.9615 - val_accuracy: 0.4355 - val_loss: 1.8934 - learning_rate: 8.0802e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 208ms/step - accuracy: 0.4317 - loss: 1.8808 - val_accuracy: 0.4483 - val_loss: 1.8310 - learning_rate: 7.7982e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 202ms/step - accuracy: 0.4403 - loss: 1.8383 - val_accuracy: 0.4321 - val_loss: 1.8024 - learning_rate: 7.5025e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 202ms/step - accuracy: 0.4319 - loss: 1.7996 - val_accuracy: 0.4578 - val_loss: 1.7374 - learning_rate: 7.1947e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 204ms/step - accuracy: 0.4455 - loss: 1.7541 - val_accuracy: 0.4970 - val_loss: 1.6208 - learning_rate: 6.8762e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 203ms/step - accuracy: 0.4483 - loss: 1.6918 - val_accuracy: 0.4241 - val_loss: 1.8117 - learning_rate: 6.5485e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 207ms/step - accuracy: 0.4589 - loss: 1.6691 - val_accuracy: 0.4751 - val_loss: 1.6351 - learning_rate: 3.1067e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 198ms/step - accuracy: 0.4608 - loss: 1.6307 - val_accuracy: 0.4598 - val_loss: 1.6849 - learning_rate: 5.8724e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 201ms/step - accuracy: 0.4674 - loss: 1.6232 - val_accuracy: 0.4905 - val_loss: 1.5987 - learning_rate: 5.5271e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 198ms/step - accuracy: 0.4765 - loss: 1.6000 - val_accuracy: 0.4990 - val_loss: 1.5485 - learning_rate: 5.1793e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 204ms/step - accuracy: 0.4850 - loss: 1.5723 - val_accuracy: 0.4909 - val_loss: 1.5729 - learning_rate: 4.8307e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 203ms/step - accuracy: 0.4863 - loss: 1.5368 - val_accuracy: 0.4778 - val_loss: 1.5838 - learning_rate: 2.2414e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 201ms/step - accuracy: 0.4870 - loss: 1.5415 - val_accuracy: 0.5074 - val_loss: 1.5190 - learning_rate: 4.1376e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 195ms/step - accuracy: 0.4913 - loss: 1.5219 - val_accuracy: 0.5052 - val_loss: 1.5259 - learning_rate: 3.7966e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 202ms/step - accuracy: 0.4933 - loss: 1.5006 - val_accuracy: 0.5249 - val_loss: 1.4639 - learning_rate: 3.4615e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 197ms/step - accuracy: 0.5023 - loss: 1.4759 - val_accuracy: 0.5047 - val_loss: 1.5112 - learning_rate: 3.1338e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 204ms/step - accuracy: 0.5020 - loss: 1.4633 - val_accuracy: 0.5226 - val_loss: 1.4671 - learning_rate: 1.4077e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 201ms/step - accuracy: 0.5020 - loss: 1.4592 - val_accuracy: 0.4921 - val_loss: 1.5624 - learning_rate: 2.5075e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 204ms/step - accuracy: 0.5159 - loss: 1.4353 - val_accuracy: 0.5276 - val_loss: 1.4406 - learning_rate: 2.2118e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.5223 - loss: 1.4128"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================================================\n",
    "# Start Here for Training\n",
    "# ======================================================\n",
    "\n",
    "# Device available for training\n",
    "print(tf.config.list_physical_devices())\n",
    "print(\"Available devices:\", tf.config.list_physical_devices())\n",
    "print(\"GPUs found:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Final policy:\", mixed_precision.global_policy())\n",
    "# Setup\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "output_dir, folder_name = create_output_dir()\n",
    "data_path = get_data_path()\n",
    "\n",
    "model = None\n",
    "history_hd = None\n",
    "history_ft = None\n",
    "\n",
    "# retreive configuration info\n",
    "model_backbone='custom_cnn' # mobilenet | custom_cnn | efficientnet\n",
    "config = ModelConfig(model_backbone) \n",
    "set_host_config_overides(config=config)\n",
    "\n",
    "# Save config to file\n",
    "config_path = os.path.join(output_dir, \"config.json\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(config.to_dict(), f, indent=2)\n",
    "print(f\"‚úÖ Config saved to: {config_path}\")\n",
    "\n",
    "train_set, validation_set = create_data_generators(config, data_path)\n",
    "\n",
    "# Train\n",
    "if model_backbone=='custom_cnn':\n",
    "    model,  history_ft = train_model_cnn(config, train_set, validation_set)\n",
    "else:\n",
    "    model, history_hd, history_ft = train_model_mobilenet(config, train_set, validation_set)\n",
    "\n",
    "# Plot training history\n",
    "fig_hist = plot_training_history(history_ft)\n",
    "if fig_hist:\n",
    "    fig_hist.show()\n",
    "    #save_plot(fig_hist, \"model history\", output_dir)\n",
    "    \n",
    "save_model(model, 'emotion_recognition_ft', output_dir, folder_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa667b",
   "metadata": {},
   "source": [
    "<h1> Reporting </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d18ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# Start Here for Reporting if retreiving from file\n",
    "# ===================================================\n",
    "\n",
    "# Run full evaluation\n",
    "# Load model\n",
    "# retreive configuration info\n",
    "\n",
    "if 'model' not in globals():\n",
    "    # reload model\n",
    "    # don't resave plots\n",
    "    save_outputs=True\n",
    "    data_path = get_data_path()\n",
    "    class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "    model_backbone='custom_cnn' # mobilenet | custom_cnn | efficientnet\n",
    "    config = ModelConfig(model_backbone) \n",
    "    train_set, validation_set = create_data_generators(config, data_path)\n",
    "    model_path_ft, output_dir = load_model_path()\n",
    "    model= load_models_from_file(model_path_ft)\n",
    "    print(f\"\\n Output Path={output_dir}\")\n",
    "    \n",
    "# Run evaluation\n",
    "evaluator = ModelEvaluator(model, validation_set, class_labels, output_dir, save_outputs=True)\n",
    "predictions, true_labels = evaluator.generate_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c8a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator.create_comprehensive_report()\n",
    "#plot_charts (evaluator, output_dir)\n",
    "#res=evaluator.create_summary_report()\n",
    "#print(res)\n",
    "#res=evaluator.generate_classification_report()\n",
    "#print(res)\n",
    "#res=evaluator.generate_error_analysis()\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f663bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "random_predictions_plt = test_random_predictions(model_ft, validation_set, class_labels)\n",
    "print(f\"‚úÖ Evaluation complete! Reports saved to: {output_dir}\")\n",
    "random_predictions_plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607eb6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Global policy:\", mixed_precision.global_policy())\n",
    "#print(\"Model dtype policy:\", model.dtype_policy)   # or model.input_dtype / model.output_dtype  \n",
    "\n",
    "# ===================================================\n",
    "# The end\n",
    "# ===================================================\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
