{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e63eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hostname():\n",
    "        \n",
    "    print(\"Available devices:\")\n",
    "    \n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    return hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_if_set_local_env_done=True\n",
    "\n",
    "if get_hostname() == \"xscape7x\" and skip_if_set_local_env_done is False:\n",
    "\n",
    "    print(\"üîÑ Snapdragon X Elite detected - optimizing for CPU\")\n",
    "\n",
    "    # Use environment variables instead (set before TF init)\n",
    "    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "    os.environ['OMP_NUM_THREADS'] = '8'\n",
    "    os.environ['TF_NUM_INTEROP_THREADS'] = '8'\n",
    "    os.environ['TF_NUM_INTRAOP_THREADS'] = '8'\n",
    "    # Restart Python kernel after setting these\n",
    "    print(\"‚úÖ Environment configured - restart kernel for full effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13765dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPUs found: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    print(f\" {gpu}\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "\n",
    "    \n",
    "print(\"Available devices:\", tf.config.list_physical_devices())\n",
    "print(\"GPUs found:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Final policy:\", mixed_precision.global_policy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a536b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# At the top of your notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import socket\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten, Dropout, Dense, Input, GlobalAveragePooling2D, Conv2D,\n",
    "    BatchNormalization, Activation, MaxPooling2D, Lambda\n",
    ")\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    ")\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "try:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Data Loading Utilities\n",
    "# =========================================================================\n",
    "def is_on_kaggle():\n",
    "    \"\"\"Detect if running on Kaggle.\"\"\"\n",
    "    return os.path.exists('/kaggle/input')\n",
    "\n",
    "def get_data_path():\n",
    "    \"\"\"Detect environment and return appropriate data path.\"\"\"\n",
    "    if is_on_kaggle():\n",
    "        print(\"üåê Running on Kaggle\")\n",
    "        import kagglehub\n",
    "        image_path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
    "        folder_path = os.path.join(image_path, \"images\")\n",
    "    else:\n",
    "        print(\"üíª Running on local machine\")\n",
    "        folder_path = \"data/images/\"\n",
    "    \n",
    "    return folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee255750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Model Building\n",
    "# =========================================================================\n",
    "\n",
    "def build_custom_cnn(config):\n",
    "    \"\"\"Build custom CNN model\"\"\"\n",
    "    picture_size = config.get('picture_size')\n",
    "    color_mode = config.get('color_mode')\n",
    "    channels = 1 if color_mode == 'grayscale' else 3\n",
    "    input_shape=(picture_size,picture_size,channels)\n",
    "    dropout_rate = config.get('dropout_rate')\n",
    "    \n",
    "    model = Sequential()\n",
    "   # Block 1 - Double Conv\n",
    "    model.add(Conv2D(filters=32, \n",
    "                        kernel_size=(3, 3), \n",
    "                        padding='same', \n",
    "                        input_shape=input_shape,\n",
    "                        name='conv2d_1'),\n",
    "                        )\n",
    "\n",
    "    # Block 2 - Double Conv\n",
    "    model.add(Conv2D(filters=64, \n",
    "                      kernel_size=(5, 5), \n",
    "                      padding='same',\n",
    "                      name='conv2d_2'))\n",
    "    model.add(BatchNormalization(name='bn_2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_2'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_2'))\n",
    "    \n",
    "    # Block 3 - Double Conv\n",
    "    model.add(Conv2D(filters=128, \n",
    "                      kernel_size=(5, 5), \n",
    "                      padding='same',\n",
    "                      name='conv2d_3'))\n",
    "    model.add(BatchNormalization(name='bn_3'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_3'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_3'))\n",
    "    \n",
    "    # Block 4 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_4',\n",
    "                      kernel_regularizer=regularizers.l2(0.01)\n",
    "                      ))\n",
    "    model.add(BatchNormalization(name='bn_4'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_4'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_4'))\n",
    "\n",
    "    \n",
    "    # Block 5 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same',\n",
    "                      name='conv2d_5',\n",
    "                      kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization(name='bn_5'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_5'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_5'))\n",
    "    \n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layers\n",
    "    for units in config.get('dense_units', [256,512]):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(config.get('dropout_rate')))\n",
    "    \n",
    "        model.add(Dense(config.get('no_of_classes'), \n",
    "                    activation='softmax', \n",
    "                    dtype='float32'))\n",
    "    \n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ae43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transfer_model(config, backbone_class):\n",
    "    \"\"\"Build transfer learning model for MobileNetV2 / EfficientNetB0.\"\"\"\n",
    "    picture_size = config.get('picture_size')\n",
    "    color_mode = config.get('color_mode')\n",
    "\n",
    "    # Determine if this is EfficientNet\n",
    "    is_efficientnet = backbone_class is EfficientNetB0\n",
    "    \n",
    "\n",
    "    # EfficientNetB0 expects 224x224 RGB\n",
    "    if is_efficientnet:\n",
    "        backbone_input_size = 224\n",
    "        backbone_channels = 3\n",
    "    else:\n",
    "        backbone_input_size = picture_size\n",
    "        backbone_channels = 3  # we‚Äôll convert grayscale to RGB if needed\n",
    "\n",
    "    # Our model input\n",
    "    channels = 1 if (color_mode == 'grayscale' and not is_efficientnet) else 3\n",
    "    inputs = Input(shape=(backbone_input_size, backbone_input_size, channels))\n",
    "\n",
    "    # Convert grayscale to RGB for non-EfficientNet cases only\n",
    "    if channels == 1:\n",
    "        x = Lambda(lambda z: tf.image.grayscale_to_rgb(z))(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Backbone always sees RGB (3 channels)\n",
    "    base_model = backbone_class(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(backbone_input_size, backbone_input_size, 3),\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(config.get('dropout_rate'))(x)\n",
    "\n",
    "    for units in config.get('dense_units', [512]):\n",
    "        x = Dense(units, activation='relu')(x)\n",
    "        x = Dropout(config.get('dropout_rate'))(x)\n",
    "\n",
    "    outputs = Dense(\n",
    "        config.get('no_of_classes'),\n",
    "        activation='softmax',\n",
    "        dtype='float32'\n",
    "    )(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(config):\n",
    "    \"\"\"Build model based on configuration\"\"\"\n",
    "    backbone = config.backbone\n",
    "    \n",
    "    if backbone == 'custom_cnn':\n",
    "        return build_custom_cnn(config)\n",
    "    elif backbone == 'mobilenet':\n",
    "        return build_transfer_model(config, MobileNetV2)\n",
    "    elif backbone == 'efficientnet':\n",
    "        return build_transfer_model(config, EfficientNetB0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ff386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================\n",
    "# Training Utilities\n",
    "# =========================================================================\n",
    "\n",
    "def create_callbacks(config):\n",
    "    \"\"\"Create training callbacks\"\"\"\n",
    "    callbacks = [\n",
    "        ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_delta=0.0001)\n",
    "    ]\n",
    "    \n",
    "    if config.get('use_lr_schedule'):\n",
    "        def cosine_annealing(epoch, lr):\n",
    "            initial_lr = float(config.get('learning_rate'))\n",
    "            min_lr = 1e-7\n",
    "            warmup = 5\n",
    "            total_epochs = config.get('epochs')\n",
    "            \n",
    "            if epoch < warmup:\n",
    "                return initial_lr * (epoch + 1) / warmup\n",
    "            \n",
    "            progress = (epoch - warmup) / (total_epochs - warmup)\n",
    "            lr_out = min_lr + (initial_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "            return max(lr_out, min_lr)\n",
    "        \n",
    "        callbacks.append(LearningRateScheduler(cosine_annealing))\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def compute_class_weights(train_set):\n",
    "    \"\"\"Compute class weights for imbalanced data\"\"\"\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_set.classes),\n",
    "        y=train_set.classes\n",
    "    )\n",
    "    return dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6981b",
   "metadata": {},
   "source": [
    "<h1> Run Training </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ef876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_dir():\n",
    "    # - create output folder and provide output path\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        output_dir = \"/kaggle/working/\" + timestamp + \"/\"  \n",
    "    else:\n",
    "        output_dir = \"outputs/\" + timestamp + \"/\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print (f\"Output directory: {output_dir}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name_prefix, output_dir):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"{model_name_prefix}_{timestamp}.keras\"\n",
    "    out_path = Path(output_dir) / model_name\n",
    "    try:\n",
    "        model.save(str(out_path))\n",
    "        print(f\"\\nüíæ Model saved: {out_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "    \n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c896cd",
   "metadata": {},
   "source": [
    "<h1>Load Model and Generate Reports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_path():\n",
    "    import os,re, glob\n",
    "    from pathlib import Path\n",
    "    from datetime import datetime\n",
    "    \n",
    "     # ensure these are always defined\n",
    "    latest_ft = None\n",
    "    latest_hd = None\n",
    "    latest_dir = None\n",
    "\n",
    "    # Find all valid .keras files\n",
    "    valid_files = [\n",
    "        f for f in glob.glob(\"outputs/*/*.keras\")\n",
    "        if re.match(r'^\\d{8}_\\d{6}$', os.path.basename(os.path.dirname(f)))\n",
    "    ]\n",
    "\n",
    "    if not valid_files:\n",
    "        print(\"‚ùå No valid .keras files found\")\n",
    "        \n",
    "    else:\n",
    "        # Find latest timestamp\n",
    "        latest = max(valid_files, key=lambda x: datetime.strptime(\n",
    "            os.path.basename(os.path.dirname(x)), \"%Y%m%d_%H%M%S\"\n",
    "        ))\n",
    "        latest_dir = os.path.dirname(latest)\n",
    "\n",
    "        # Look for hd and ft variants in the same latest directory\n",
    "        hd_pattern = os.path.join(latest_dir, \"*_hd_*.keras\")\n",
    "        ft_pattern = os.path.join(latest_dir, \"*_ft_*.keras\")\n",
    "\n",
    "        hd_files = glob.glob(hd_pattern)\n",
    "        ft_files = glob.glob(ft_pattern)\n",
    "\n",
    "        latest_hd = hd_files[0] if hd_files else None\n",
    "        latest_ft = ft_files[0] if ft_files else None\n",
    "\n",
    "        print(f\"Latest HD: {latest_hd}\")\n",
    "        print(f\"Latest FT: {latest_ft}\")\n",
    "    \n",
    "    return latest_ft, latest_hd, latest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_from_file(path_hd, path_ft):\n",
    "    from tensorflow.keras.models import load_model\n",
    "    model_hd=load_model(path_hd)\n",
    "    model_ft=load_model(path_ft)\n",
    "\n",
    "    return model_hd, model_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history_hd, history_ft):\n",
    "    \"\"\"\n",
    "    Plot training history.\n",
    "    - If only history_hd exists: plot that.\n",
    "    - If only history_ft exists: plot that.\n",
    "    - If both exist: concatenate them (head + fine‚Äëtune).\n",
    "    \"\"\"\n",
    "    # Helper to safely get metric arrays\n",
    "    def get_vals(h, key):\n",
    "        return h.history.get(key, []) if h is not None else []\n",
    "\n",
    "    # Head-only metrics\n",
    "    head_acc      = get_vals(history_hd, 'accuracy')\n",
    "    head_val_acc  = get_vals(history_hd, 'val_accuracy')\n",
    "    head_loss     = get_vals(history_hd, 'loss')\n",
    "    head_val_loss = get_vals(history_hd, 'val_loss')\n",
    "\n",
    "    # Fine‚Äëtune metrics\n",
    "    ft_acc      = get_vals(history_ft, 'accuracy')\n",
    "    ft_val_acc  = get_vals(history_ft, 'val_accuracy')\n",
    "    ft_loss     = get_vals(history_ft, 'loss')\n",
    "    ft_val_loss = get_vals(history_ft, 'val_loss')\n",
    "\n",
    "    # Concatenate if both present\n",
    "    train_acc  = head_acc + ft_acc\n",
    "    val_acc    = head_val_acc + ft_val_acc\n",
    "    train_loss = head_loss + ft_loss\n",
    "    val_loss   = head_val_loss + ft_val_loss\n",
    "\n",
    "    if not any([train_acc, val_acc, train_loss, val_loss]):\n",
    "        print(\"‚ö†Ô∏è No training metrics available to plot\")\n",
    "        return None\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Accuracy plot\n",
    "    if train_acc:\n",
    "        axes[0].plot(train_acc, label='Train Accuracy')\n",
    "    if val_acc:\n",
    "        axes[0].plot(val_acc, label='Val Accuracy')\n",
    "    axes[0].set_title('Model Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Loss plot\n",
    "    if train_loss:\n",
    "        axes[1].plot(train_loss, label='Train Loss')\n",
    "    if val_loss:\n",
    "        axes[1].plot(val_loss, label='Val Loss')\n",
    "    axes[1].set_title('Model Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_final_evaluation(train_acc, val_acc, train_loss, val_loss):\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä FINAL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    print(f\"Training Loss:       {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss:     {val_loss:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Sample Predictions Visualization\n",
    "# =======================================================================\n",
    "\n",
    "def test_random_predictions(model, validation_set, class_labels):\n",
    "\n",
    "    import random\n",
    "\n",
    "    # Get a random batch from validation set\n",
    "    random_batch_idx = random.randint(0, len(validation_set) - 1)\n",
    "    sample_images, sample_labels = validation_set[random_batch_idx]\n",
    "\n",
    "    # Predict\n",
    "    sample_preds = model.predict(sample_images, verbose=0)\n",
    "    sample_pred_classes = np.argmax(sample_preds, axis=1)\n",
    "    sample_true_classes = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "    # Randomly select 16 indices from the batch\n",
    "    num_samples = min(16, len(sample_images))\n",
    "    random_indices = random.sample(range(len(sample_images)), num_samples)\n",
    "\n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        axes[i].imshow(sample_images[idx].squeeze(), cmap='gray')\n",
    "        \n",
    "        true_label = class_labels[sample_true_classes[idx]]\n",
    "        pred_label = class_labels[sample_pred_classes[idx]]\n",
    "        confidence = sample_preds[idx][sample_pred_classes[idx]] * 100\n",
    "\n",
    "        # Color: green if correct, red if wrong\n",
    "        color = 'green' if sample_true_classes[idx] == sample_pred_classes[idx] else 'red'\n",
    "        \n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
    "                        color=color, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle('Sample Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192618b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(plot, output_dir):\n",
    "    if getattr(plot, \"_suptitle\", None) is not None:\n",
    "        plot_name = plot._suptitle.get_text()\n",
    "    else:\n",
    "        axes=plot.get_axes()\n",
    "        if axes:\n",
    "            plot_name = axes[0].get_title()\n",
    "    \n",
    "    \n",
    "    out_path = Path(output_dir) / plot_name\n",
    "    try:\n",
    "        plt.savefig(os.path.join(out_path,f\"{plot_name}.png\"),dpi=300,bbox_inches='tight')\n",
    "        print(f\"\\nüíæ Plot saved: {out_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving plot: {e}\")\n",
    "    \n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5916b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Enhanced Model Evaluation and Reporting\n",
    "# =========================================================================\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation and report generation\"\"\"\n",
    "    \n",
    "    def __init__(self, model, test_set, class_labels, output_dir=None, history_hd=None, history_ft=None):\n",
    "        self.model = model\n",
    "        self.test_set = test_set\n",
    "        self.class_labels = class_labels\n",
    "        self.output_dir = output_dir\n",
    "        self.history_hd = history_hd  \n",
    "        self.history_ft = history_ft\n",
    "        \n",
    "        # Initialize prediction attributes\n",
    "        self.predictions = None\n",
    "        self.true_labels = None\n",
    "        self.pred_labels = None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def generate_predictions(self):\n",
    "        \"\"\"Generate predictions on test set\"\"\"\n",
    "        print(\"üîÑ Generating predictions...\")\n",
    "        self.test_set.reset()\n",
    "        \n",
    "        self.predictions = self.model.predict(self.test_set, verbose=1)\n",
    "        self.true_labels = self.test_set.classes\n",
    "        self.pred_labels = np.argmax(self.predictions, axis=1)\n",
    "        \n",
    "        return self.predictions, self.true_labels\n",
    "    \n",
    "    def create_comprehensive_report(self):\n",
    "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "        if self.predictions is None:\n",
    "            self.generate_predictions()\n",
    "        \n",
    "          \n",
    "        # Generate all reports\n",
    "        self.plot_training_history()\n",
    "        self.plot_confusion_matrix()\n",
    "        self.plot_normalized_confusion_matrix()\n",
    "        self.generate_classification_report()\n",
    "        self.plot_per_class_metrics()\n",
    "        self.plot_roc_curves()\n",
    "        self.plot_precision_recall_curves()\n",
    "        self.generate_error_analysis()\n",
    "        self.create_summary_report()\n",
    "    \n",
    "    \"\"\"\n",
    "    Traning history chart will only get returned if training history in memeory\n",
    "    \"\"\"    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history with head and fine-tune stages\"\"\"\n",
    "        if self.history_hd is None and self.history_ft is None:\n",
    "            print(\"‚ö†Ô∏è No training history provided\")\n",
    "            return None\n",
    "            \n",
    "        # Combine histories\n",
    "        def _concat_metric(metric):\n",
    "            vals = []\n",
    "            if self.history_hd is not None:\n",
    "                vals += self.history_hd.history.get(metric, [])\n",
    "            if self.history_ft is not None:\n",
    "                vals += self.history_ft.history.get(metric, [])\n",
    "            return vals\n",
    "\n",
    "        train_acc = _concat_metric('accuracy')\n",
    "        val_acc = _concat_metric('val_accuracy')\n",
    "        train_loss = _concat_metric('loss')\n",
    "        val_loss = _concat_metric('val_loss')\n",
    "        \n",
    "        if not any([train_acc, val_acc, train_loss, val_loss]):\n",
    "            print(\"‚ö†Ô∏è No training metrics found in history\")\n",
    "            return None\n",
    "            \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        if train_acc:\n",
    "            axes[0].plot(train_acc, label='Train Accuracy', linewidth=2, color='blue')\n",
    "        if val_acc:\n",
    "            axes[0].plot(val_acc, label='Validation Accuracy', linewidth=2, color='red')\n",
    "        axes[0].set_title('Model Accuracy Over Training')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Accuracy')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss plot\n",
    "        if train_loss:\n",
    "            axes[1].plot(train_loss, label='Train Loss', linewidth=2, color='blue')\n",
    "        if val_loss:\n",
    "            axes[1].plot(val_loss, label='Validation Loss', linewidth=2, color='red')\n",
    "        axes[1].set_title('Model Loss Over Training')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Loss')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add vertical line to show fine-tuning start if applicable\n",
    "        if self.history_hd is not None and self.history_ft is not None:\n",
    "            hd_epochs = len(self.history_hd.history.get('loss', []))\n",
    "            axes[0].axvline(x=hd_epochs, color='green', linestyle='--', alpha=0.7, label='Fine-tune start')\n",
    "            axes[1].axvline(x=hd_epochs, color='green', linestyle='--', alpha=0.7, label='Fine-tune start')\n",
    "            axes[0].legend()\n",
    "            axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt\n",
    "    \n",
    "    def plot_confusion_matrix(self):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(self.true_labels, self.pred_labels)\n",
    "        \n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=self.class_labels,\n",
    "                   yticklabels=self.class_labels)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "        \n",
    "    def plot_normalized_confusion_matrix(self):\n",
    "        \"\"\"Plot normalized confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(self.true_labels, self.pred_labels)\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "                   xticklabels=self.class_labels,\n",
    "                   yticklabels=self.class_labels)\n",
    "        plt.title('Confusion Matrix-Normalized')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "        \n",
    "    def generate_classification_report(self):\n",
    "        \"\"\"Generate detailed classification report\"\"\"\n",
    "        report = classification_report(\n",
    "            self.true_labels, \n",
    "            self.pred_labels,\n",
    "            target_names=self.class_labels,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        # Save as JSON\n",
    "        with open(os.path.join(self.output_dir, 'classification_report.json'), 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "            \n",
    "        # Save as CSV\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv(os.path.join(self.output_dir, 'classification_report.csv'))\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(\n",
    "            self.true_labels, \n",
    "            self.pred_labels,\n",
    "            target_names=self.class_labels\n",
    "        ))\n",
    "        \n",
    "    def plot_per_class_metrics(self):\n",
    "        \"\"\"Plot precision, recall, and F1-score per class\"\"\"\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            self.true_labels, self.pred_labels, average=None\n",
    "        )\n",
    "        \n",
    "        x = np.arange(len(self.class_labels))\n",
    "        width = 0.25\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        bars1 = ax.bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
    "        bars2 = ax.bar(x, recall, width, label='Recall', alpha=0.8)\n",
    "        bars3 = ax.bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Emotion Classes')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_title('Per-Class Performance Metrics')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(self.class_labels, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bars in [bars1, bars2, bars3]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt_name = 'per_class_metrics.png'\n",
    "        return plt\n",
    "        \n",
    "    def plot_roc_curves(self):\n",
    "        \"\"\"Plot ROC curves for multi-class classification\"\"\"\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        \n",
    "        # Binarize labels\n",
    "        y_test_bin = label_binarize(self.true_labels, classes=range(len(self.class_labels)))\n",
    "        \n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        for i in range(len(self.class_labels)):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], self.predictions[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(self.class_labels)))\n",
    "        \n",
    "        for i, color in zip(range(len(self.class_labels)), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                    label=f'{self.class_labels[i]} (AUC = {roc_auc[i]:0.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves-Multi-class')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "        \n",
    "    \n",
    "    def plot_precision_recall_curves(self):\n",
    "        \"\"\"Plot precision-recall curves for multi-class classification\"\"\"\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "        \n",
    "        # Binarize labels\n",
    "        y_test_bin = label_binarize(self.true_labels, classes=range(len(self.class_labels)))\n",
    "        \n",
    "        # Compute precision-recall curve and average precision for each class\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        average_precision = dict()\n",
    "        \n",
    "        for i in range(len(self.class_labels)):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(\n",
    "                y_test_bin[:, i], self.predictions[:, i]\n",
    "            )\n",
    "            average_precision[i] = average_precision_score(\n",
    "                y_test_bin[:, i], self.predictions[:, i]\n",
    "            )\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(self.class_labels)))\n",
    "        \n",
    "        for i, color in zip(range(len(self.class_labels)), colors):\n",
    "            plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "                    label=f'{self.class_labels[i]} (AP = {average_precision[i]:0.2f})')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curves-Multi-class')\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt_prc=plt\n",
    "        \n",
    "        \n",
    "        # Also create micro-average precision-recall curve\n",
    "        precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n",
    "            y_test_bin.ravel(), self.predictions.ravel()\n",
    "        )\n",
    "        average_precision[\"micro\"] = average_precision_score(\n",
    "            y_test_bin, self.predictions, average=\"micro\"\n",
    "        )\n",
    "        \n",
    "        # Plot micro-average\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2,\n",
    "                label=f'Micro-average (AP = {average_precision[\"micro\"]:0.2f})')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve-Micro-average')\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt_prm=plt\n",
    "        \n",
    "        return plt_prm, plt_prc      \n",
    "      \n",
    "    def generate_error_analysis(self):\n",
    "        \"\"\"Analyze misclassifications\"\"\"\n",
    "        errors = self.true_labels != self.pred_labels\n",
    "        error_indices = np.where(errors)[0]\n",
    "        \n",
    "        if len(error_indices) > 0:\n",
    "            # Get error details\n",
    "            error_details = []\n",
    "            for idx in error_indices[:50]:  # Limit to first 50 errors\n",
    "                true_class = self.class_labels[self.true_labels[idx]]\n",
    "                pred_class = self.class_labels[self.pred_labels[idx]]\n",
    "                confidence = self.predictions[idx][self.pred_labels[idx]]\n",
    "                \n",
    "                error_details.append({\n",
    "                    'index': idx,\n",
    "                    'true_class': true_class,\n",
    "                    'pred_class': pred_class,\n",
    "                    'confidence': confidence,\n",
    "                    'image_path': self.test_set.filepaths[idx] if hasattr(self.test_set, 'filepaths') else None\n",
    "                })\n",
    "            \n",
    "            # Save error analysis\n",
    "            error_df = pd.DataFrame(error_details)\n",
    "            error_df.to_csv(os.path.join(self.output_dir, 'error_analysis.csv'), index=False)\n",
    "            \n",
    "            # Print top misclassifications\n",
    "            print(\"\\nüîç Top 5 Misclassifications:\")\n",
    "            print(\"=\"*50)\n",
    "            for _, row in error_df.head().iterrows():\n",
    "                print(f\"True: {row['true_class']} ‚Üí Pred: {row['pred_class']} \"\n",
    "                      f\"(Confidence: {row['confidence']:.2%})\")\n",
    "                        \n",
    "    def create_summary_report(self):\n",
    "        \"\"\"Create comprehensive summary report\"\"\"\n",
    "        summary = {\n",
    "            'model_name': self.model.name,\n",
    "            'test_samples': len(self.true_labels),\n",
    "            'overall_accuracy': np.mean(self.true_labels == self.pred_labels),\n",
    "            'class_labels': self.class_labels,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Add per-class metrics\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            self.true_labels, self.pred_labels, average=None\n",
    "        )\n",
    "        \n",
    "        summary['per_class_metrics'] = {\n",
    "            label: {\n",
    "                'precision': float(p),\n",
    "                'recall': float(r),\n",
    "                'f1_score': float(f),\n",
    "                'support': int(s)\n",
    "            }\n",
    "            for label, p, r, f, s in zip(self.class_labels, precision, recall, f1, support)\n",
    "        }\n",
    "        \n",
    "        # Save summary\n",
    "        with open(os.path.join(self.output_dir, 'summary_report.json'), 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "            \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f60a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(config, train_set, validation_set, class_labels, data_path):\n",
    "    \n",
    "    \n",
    "    # Load model\n",
    "    model_path_ft, model_path_hd, output_dir = load_model_path()\n",
    "    model_ft, _ = load_models_from_file(model_path_hd, model_path_ft)\n",
    "    \n",
    "    \n",
    "    # Run evaluation\n",
    "    evaluator = ModelEvaluator(model_ft, validation_set, class_labels, output_dir)\n",
    "    predictions, true_labels = evaluator.generate_predictions()\n",
    "    \n",
    "    plt_train_hist=evaluator.plot_training_history()\n",
    "    plt_cm= evaluator.plot_confusion_matrix()\n",
    "    plt_cm_norm = evaluator.plot_normalized_confusion_matrix()\n",
    "    plt_prm, plt_prc=evaluator.plot_precision_recall_curves()\n",
    "    plt_class= evaluator.plot_per_class_metrics()\n",
    "    plt_roc= evaluator.plot_roc_curves()\n",
    "    \n",
    "    plots=[plt_train_hist, plt_cm, plt_cm_norm, plt_prm, plt_prc, plt_class, plt_roc]\n",
    "    \n",
    "    \n",
    "    for fig in plots:\n",
    "        if fig is None:\n",
    "            continue\n",
    "        fig.show()\n",
    "        # save_plot(fig, output_dir)\n",
    "        fig.close\n",
    "    \n",
    "    #evaluator.create_comprehensive_report()\n",
    "    \n",
    "    random_predictions_plt = test_random_predictions(model_ft, validation_set, class_labels)\n",
    "    random_predictions_plt.show()\n",
    "    print(f\"‚úÖ Evaluation complete! Reports saved to: {output_dir}\")\n",
    "    \n",
    "    return evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, train_set, validation_set, output_dir):\n",
    "\n",
    "    # =========================================================================\n",
    "    # Load Data & Compile Model  \n",
    "    # =========================================================================\n",
    "\n",
    "    # Generate training and validation Set\n",
    "    print(\"Train image shape:\", train_set.image_shape)\n",
    "    print(\"Val image shape:  \", validation_set.image_shape)\n",
    "\n",
    "    print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "    print (f\"Colour Mode: {config.config.get('color_mode')}\")    \n",
    "    print(f\"Training samples: {train_set.n}\")\n",
    "    print(f\"Validation samples: {validation_set.n}\")\n",
    "    print(f\"Class indices: {train_set.class_indices}\")\n",
    "\n",
    "    history_ft= None\n",
    "    history_hd=None\n",
    "    # Build model\n",
    "    model, base_model = build_model(config)\n",
    "\n",
    "    # Validate shapes\n",
    "    assert train_set.image_shape == model.input_shape[1:], (\n",
    "        f\"Shape mismatch: {train_set.image_shape} vs {model.input_shape[1:]}\")\n",
    "\n",
    "    # Compile with optimizer choice\n",
    "    optimizer_name =  \"adam\"\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = Adam(learning_rate=config.get('learning_rate'))\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        opt = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=config.get('learning_rate'),\n",
    "            weight_decay=config.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt = tf.keras.optimizers.SGD(\n",
    "            learning_rate=config.get('learning_rate'),\n",
    "            momentum=0.9,\n",
    "            nesterov=True\n",
    "        )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    #print (\"== Base Model ====\")\n",
    "    \n",
    "    print (\"== Base Model ====\")\n",
    "    model.summary()\n",
    "    #base_model.summary()\n",
    "    \n",
    "    if config.get(\"use_class_weights\"):\n",
    "        class_weights = compute_class_weights(train_set)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = create_callbacks(config)\n",
    "    print(f\"‚úÖ Callbacks configured: {len(callbacks)} callbacks\")\n",
    "    \n",
    "\n",
    "    # Stage 1: Train head\n",
    "    print(f\"Training {config.backbone} model...\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ STARTING TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Target: {config.get('epochs')} epochs with early stopping\")\n",
    "    print(f\"Batch size: {config.get('batch_size')}\")\n",
    "    print(f\"Learning rate: {config.get('learning_rate')}\")\n",
    "    print(f\"Augmentation: {config.get('aug_level')}\")\n",
    "    print(f\"Backbone: {config.get('backbone')}\")\n",
    "    print(f\"Class weights: {'Enabled' if class_weights else 'Disabled'}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    \n",
    "    history_hd = model.fit(\n",
    "        train_set,\n",
    "        epochs=config.get(\"epochs\"),\n",
    "        validation_data=validation_set,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1,\n",
    "    )    \n",
    "    save_model(model,'emotion_recognition_hd', output_dir)\n",
    "    \n",
    "    \n",
    "    # Stage 2: Fine-tune (if transfer learning)    \n",
    "    if base_model is not None and config.get(\"fine_tune\"):\n",
    "    \n",
    "        print(\"Fine-tuning...\")\n",
    "\n",
    "        # Unfreeze layers\n",
    "        unfreeze_layers = config.get(\"fine_tune_unfreeze_layers\", 30)\n",
    "        for layer in base_model.layers[unfreeze_layers:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Recompile with lower LR\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=config.get(\"learning_rate\") * 0.1),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        # Continue training\n",
    "        history_ft = model.fit(\n",
    "            train_set,\n",
    "            epochs=config.get(\"epochs\") + config.get(\"fine_tune_epochs\", 0),\n",
    "            initial_epoch=config.get(\"epochs\"),\n",
    "            validation_data=validation_set,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weights,\n",
    "            verbose=1,\n",
    "        ) \n",
    "    else:\n",
    "        history_ft= None\n",
    "    save_model(model, 'emotion_recognition_ft', output_dir)\n",
    "\n",
    "\n",
    "    \n",
    "    return model, history_hd, history_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data_generators(config, data_path):\n",
    "    \"\"\"Create clean data generators\"\"\"\n",
    "    \n",
    "    # Get augmentation parameters\n",
    "    aug_params = config.AUGMENTATION_LEVELS[config.get('aug_level', 'light')]\n",
    "    \n",
    "    # Handle preprocessing based on backbone\n",
    "    if config.backbone in ['mobilenet', 'efficientnet']:\n",
    "        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "        aug_params = aug_params.copy()\n",
    "        aug_params['preprocessing_function'] = preprocess_input\n",
    "    \n",
    "    # Create generators\n",
    "    train_gen = ImageDataGenerator(**aug_params)\n",
    "    val_gen = ImageDataGenerator(**aug_params)\n",
    "    \n",
    "    # Determine color mode\n",
    "    color_mode = config.get('color_mode', 'grayscale')\n",
    "    \n",
    "    train_set = train_gen.flow_from_directory(\n",
    "        os.path.join(data_path, \"train\"),\n",
    "        target_size=(config.get('picture_size'), config.get('picture_size')),\n",
    "        color_mode=config.get('color_mode'),   \n",
    "        batch_size=config.get('batch_size'),\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    validation_set = val_gen.flow_from_directory(\n",
    "        os.path.join(data_path, \"validation\"),\n",
    "        target_size=(config.get('picture_size'), config.get('picture_size')),\n",
    "        color_mode=config.get('color_mode'),   \n",
    "        batch_size=config.get('batch_size'),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    print(\"Train image shape:\", train_set.image_shape)\n",
    "    print(\"Val image shape:  \", validation_set.image_shape)\n",
    "\n",
    "    print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "    print (f\"Colour Mode: {color_mode}\")\n",
    "    print(f\"Training samples: {train_set.n}\")\n",
    "    print(f\"Validation samples: {validation_set.n}\")\n",
    "    print(f\"Class indices: {train_set.class_indices}\")\n",
    "    \n",
    "    return train_set, validation_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "#  Configuration System\n",
    "# =========================================================================\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Clean configuration class with backbone-specific presets\"\"\"\n",
    "    \n",
    "    BACKBONE_PRESETS = {\n",
    "        'custom_cnn': {\n",
    "            'picture_size': 48,\n",
    "            'color_mode': 'grayscale',\n",
    "            'batch_size': 64,\n",
    "            'epochs': 50,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.25,\n",
    "            'dense_units': [512],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'weight_decay':1e-4\n",
    "        },\n",
    "        'mobilenet': {\n",
    "            'picture_size': 96,\n",
    "            'color_mode': 'rgb',\n",
    "            'batch_size': 32,\n",
    "            'epochs': 30,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.3,\n",
    "            'dense_units': [512, 256],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'fine_tune': True,\n",
    "            'fine_tune_epochs': 20,\n",
    "            'fine_tune_unfreeze_layers': 30,\n",
    "            'weight_decay':1e-4,\n",
    "            'weights': 'imagenet'\n",
    "        },\n",
    "        'efficientnet': {\n",
    "            'picture_size': 224,       # \n",
    "            'color_mode': 'rgb',\n",
    "            'batch_size': 16,\n",
    "            'epochs': 40,\n",
    "            'learning_rate': 0.0001,\n",
    "            'dropout_rate': 0.4,\n",
    "            'dense_units': [1024, 512],\n",
    "            'aug_level': 'strong',\n",
    "            'use_class_weights': True,\n",
    "            'use_lr_schedule': True,\n",
    "            'fine_tune': True,\n",
    "            'fine_tune_epochs': 25,\n",
    "            'fine_tune_unfreeze_layers': 50,\n",
    "            'weight_decay': 1e-4,\n",
    "            'weights': None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    AUGMENTATION_LEVELS = {\n",
    "        'none': dict(rescale=1./255),\n",
    "        'light': dict(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True\n",
    "        ),\n",
    "        'strong': dict(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.2,\n",
    "            brightness_range=[0.7, 1.3],\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, backbone='mobilenet'):\n",
    "        \"\"\"Initialize with backbone preset\"\"\"\n",
    "        if backbone not in self.BACKBONE_PRESETS:\n",
    "            raise ValueError(f\"Backbone must be one of {list(self.BACKBONE_PRESETS.keys())}\")\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.config = self.BACKBONE_PRESETS[backbone].copy()\n",
    "        self.config['backbone'] = backbone\n",
    "        self.config['no_of_classes'] = 7\n",
    "        \n",
    "    def get(self, key, default=None):\n",
    "        \"\"\"Get configuration value\"\"\"\n",
    "        return self.config.get(key, default)\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        \"\"\"Set configuration value\"\"\"\n",
    "        self.config[key] = value\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Return full configuration\"\"\"\n",
    "        return self.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_host_config_overides(config, dev=True):\n",
    "    \n",
    "    hostname = get_hostname() \n",
    "\n",
    "    if  hostname == \"xscape7x\": # local machine\n",
    "        print(\"Hostname:\", hostname)\n",
    "        if dev==True: \n",
    "            print(\"Overiding settings for xscape7x...\")\n",
    "            # Override any settings\n",
    "            config.set(\"epochs\",15)\n",
    "            config.set(\"batch_size\", 64)\n",
    "            config.set(\"learning_rate\", 0.0001)\n",
    "            config.set('denseunits', [256,512])\n",
    "            #config.set(\"fine_tune_epochs\", 6)\n",
    "            \n",
    "        \n",
    "    else:                                           # run on remote server\n",
    "        pass  # No overrides\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Configuration: {config.backbone.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in config.config.items():\n",
    "        print(f\"{key:20}: {value}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11156a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 15/451\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m11:27\u001b[0m 2s/step - accuracy: 0.1319 - loss: 9.8640"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "output_dir = create_output_dir()\n",
    "data_path = get_data_path()\n",
    "\n",
    "# retreive configuration info\n",
    "model_backbone='custom_cnn' # mobilenet | custom_cnn | efficientnet\n",
    "config = ModelConfig(model_backbone) \n",
    "set_host_config_overides(config=config, dev=True)\n",
    "\n",
    "train_set, validation_set = create_data_generators(config, data_path)\n",
    "\n",
    "# Train\n",
    "model, history_hd, history_ft = train_model(config, train_set, validation_set, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47647af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"History keys:\", history_hd.history.keys())\n",
    "print(\"acc:\", history_hd.history.get('accuracy'))\n",
    "print(\"val_acc:\", history_hd.history.get('val_accuracy'))\n",
    "print(\"loss:\", history_hd.history.get('loss'))\n",
    "print(\"val_loss:\", history_hd.history.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d18ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training history\n",
    "fig_hist = plot_training_history(history_hd, history_ft)\n",
    "if fig_hist:\n",
    "    fig_hist.show()\n",
    "\n",
    "# Run full evaluation\n",
    "evaluator = run_evaluation(config, train_set, validation_set, class_labels, data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Extract Values from the Model\n",
    "# =========================================================================\n",
    "def extract_model_values(history_hd, history_ft):\n",
    "\n",
    "    # Helper to safely get values\n",
    "    def get_vals(h, key):\n",
    "        return h.history.get(key, []) if h is not None else []\n",
    "\n",
    "    head_acc = get_vals(history_hd, 'val_accuracy')\n",
    "    head_val_acc = get_vals(history_hd, 'val_accuracy')\n",
    "    head_loss = get_vals(history_hd, 'loss')\n",
    "    head_val_loss = get_vals(history_hd, 'val_loss')\n",
    "\n",
    "    ft_acc = get_vals(history_ft, 'accuracy')\n",
    "    ft_val_acc = get_vals(history_ft, 'val_accuracy')\n",
    "    ft_loss = get_vals(history_ft, 'loss')\n",
    "    ft_val_loss = get_vals(history_ft, 'val_loss')\n",
    "\n",
    "    train_acc = head_acc + ft_acc\n",
    "    val_acc   = head_val_acc + ft_val_acc\n",
    "    train_loss = head_loss + ft_loss\n",
    "    val_loss   = head_val_loss + ft_val_loss\n",
    "    \n",
    "    return train_acc, val_acc, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    #print(\"Global policy:\", mixed_precision.global_policy())\n",
    "    #print(\"Model dtype policy:\", model.dtype_policy)   # or model.input_dtype / model.output_dtype  \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
