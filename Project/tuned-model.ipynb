{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":234911,"sourceType":"datasetVersion","datasetId":99505}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0697d144","cell_type":"markdown","source":"Tuning opportunities\n1. Configuration-Based Hyperparameter Tuning\n2. Enhanced Data Augmentation\n3. Improved Model Architecture\n4. Advanced Callbacks\n5. Transfer Learning (Often Best Results)\n6. Class Imbalance Handling\n7. Ensemble Methods\n8. Systematic Tuning Strategy","metadata":{}},{"id":"89f9fe6a","cell_type":"markdown","source":"Quick Start Guide:\nFor best results immediately: Set \"backbone\": \"mobilenet\" and \"fine_tune\": True\nFor faster training: Set \"backbone\": \"custom_cnn\" and \"aug_level\": \"light\"\nFor maximum accuracy: Enable ensemble with \"use_ensemble\": True\nFor experimentation: Uncomment Cell 17 to run systematic tuning","metadata":{}},{"id":"d00b4b66","cell_type":"code","source":"# =======================================================================\n# Facial Emotion Recognition - Enhanced with 8 Tuning Improvements\n# =======================================================================\n\nimport sys\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom PIL import Image, UnidentifiedImageError\nfrom pathlib import Path\nfrom datetime import datetime\n\n# TensorFlow and Keras\nimport tensorflow as tf\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Python executable: {sys.executable}\")\n\nimport seaborn as sns\n\n# Deep learning libraries\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import (Flatten, Dropout, Dense, Input, \n    GlobalAveragePooling2D, Conv2D, \n    BatchNormalization, Activation, MaxPooling2D)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, \n    ReduceLROnPlateau, LearningRateScheduler)\nfrom tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n\n# Metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\nfrom sklearn.utils.class_weight import compute_class_weight\n\nprint(\"‚úÖ All libraries imported successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"87c880f2","cell_type":"code","source":"# =======================================================================\n# Environment Detection\n# =======================================================================\n\ndef is_on_kaggle():\n    \"\"\"Detect if running on Kaggle.\"\"\"\n    return os.path.exists('/kaggle/input')\n\ndef get_data_path():\n    \"\"\"Detect environment and return appropriate data path.\"\"\"\n    if is_on_kaggle():\n        print(\"üåê Running on Kaggle\")\n        import kagglehub\n        image_path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n        folder_path = os.path.join(image_path, \"images\")\n    else:\n        print(\"üíª Running on local machine\")\n        folder_path = \"data/images/\"\n    \n    return folder_path\n\nfolder_path = get_data_path()\nprint(f\"Data folder path: {folder_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1475dab4","cell_type":"code","source":"# =======================================================================\n# Enhanced Configuration with Tuning Options\n# =======================================================================\n\ncfg = {\n    # Model Architecture\n    \"backbone\": \"custom_cnn\",  # Options: \"custom_cnn\", \"mobilenet\", \"efficientnet\"\n    \n    # Image Parameters\n    \"picture_size\": 48,  # Try: 64, 96 for more detail\n    \"color_mode\": \"grayscale\",  # \"grayscale\" or \"rgb\" (rgb required for transfer learning)\n    \n    # Training Parameters\n    \"batch_size\": 64,  # Reduced from 128 for better gradient estimates\n    \"epochs\": 30,  # Increased from 30\n    \"learning_rate\": 0.0001,  # Adjusted learning rate\n    \"dropout_rate\": 0.25,  # Increased from 0.25\n     \n    # Dense layers\n    \"dense_units\": [256,128],\n    #\"dense_units\": [512],\n    \n    # Data Augmentation (Improvement #2)\n    \"aug_level\": \"aggressive\",  # Options: \"none\", \"light\", \"strong\", \"aggressive\"\n    \n    # Advanced Training\n    \"precision\": \"mixed\",  # \"float32\" or \"mixed\"\n    \"fine_tune\": False,  # Enable fine-tuning for transfer learning\n    \"fine_tune_epochs\": 0,\n    \n    # Optimizer\n    \"optimizer\": \"adam\",  # Options: \"adam\", \"adamw\", \"sgd\"\n    \"weight_decay\": 1e-4,  # For AdamW\n    \n    # Learning Rate Schedule\n    \"use_lr_schedule\": True,  # Cosine annealing (Improvement #5)\n    \n    # Class Weights (Improvement #3)\n    \"use_class_weights\": True,\n    \n    # Ensemble (Improvement #7)\n    \"use_ensemble\": False,  # Set True to train multiple models\n    \"n_ensemble_models\": 3,\n    \n    # Model Parameters\n    \"no_of_classes\": 7,\n}\n\nprint(\"Configuration loaded:\")\nfor key, value in cfg.items():\n    print(f\"  {key}: {value}\")\n\n# Extract commonly used values\npicture_size = cfg[\"picture_size\"]\nbatch_size = cfg[\"batch_size\"]\nepochs = cfg[\"epochs\"]\nlearning_rate = cfg[\"learning_rate\"]\nno_of_classes = cfg[\"no_of_classes\"]\ndropout_rate = cfg[\"dropout_rate\"]\ndense_units = cfg[\"dense_units\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"cb74f8a4","cell_type":"code","source":"# =======================================================================\n# Mixed Precision Training\n# =======================================================================\n\nfrom tensorflow.keras import mixed_precision\n\nif cfg.get(\"precision\", \"float32\") == \"mixed\":\n    mixed_precision.set_global_policy('mixed_float16')\n    print(\"‚úÖ Mixed precision training enabled - expect 2-3x speedup!\")\nelse:\n    mixed_precision.set_global_policy('float32')\n    print(\"Using float32 precision\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"365719a6","cell_type":"code","source":"# =======================================================================\n# Enhanced Data Augmentation\n# =======================================================================\n\naug_map = {\n    \"none\": dict(rescale=1./255),\n    \n    \"light\": dict(\n        rescale=1./255,\n        rotation_range=10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        shear_range=0.1,\n        horizontal_flip=True\n    ),\n    \n    \"strong\": dict(\n        rescale=1./255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.2,\n        brightness_range=[0.7, 1.3],\n        horizontal_flip=True,\n        fill_mode='nearest'\n    ),\n    \n    \"aggressive\": dict(\n        rescale=1./255,\n        rotation_range=30,\n        width_shift_range=0.25,\n        height_shift_range=0.25,\n        shear_range=0.2,\n        zoom_range=0.25,\n        brightness_range=[0.6, 1.4],\n        horizontal_flip=True,\n        channel_shift_range=0.2,\n        fill_mode='nearest'\n    )\n}\n\n# Create data generators\ndatagen_train = ImageDataGenerator(**aug_map[cfg[\"aug_level\"]])\ndatagen_validation = ImageDataGenerator(rescale=1./255)\n\nprint(f\"‚úÖ Using '{cfg['aug_level']}' augmentation level\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5db6c81c","cell_type":"code","source":"# =======================================================================\n# Load Training and Validation Data\n# =======================================================================\n\n# Determine color mode\ncolor_mode = cfg[\"color_mode\"]\n\n# Create training set\ntrain_set = datagen_train.flow_from_directory(\n    os.path.join(folder_path, \"train\"),\n    target_size=(picture_size, picture_size),\n    color_mode=color_mode,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True,\n)\n\n# Create validation set\nvalidation_set = datagen_validation.flow_from_directory(\n    os.path.join(folder_path, \"validation\"),\n    target_size=(picture_size, picture_size),\n    color_mode=color_mode,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False,\n)\n\nprint(f\"\\n‚úÖ Data loaded successfully\")\nprint(f\"Training samples: {train_set.n}\")\nprint(f\"Validation samples: {validation_set.n}\")\nprint(f\"Class indices: {train_set.class_indices}\")\n\nclass_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2a196b5f","cell_type":"code","source":"# =======================================================================\n# Calculate Class Weights for Imbalanced Data\n# =======================================================================\n\nclass_weight_dict = None\n\nif cfg.get(\"use_class_weights\", False):\n    class_weights = compute_class_weight(\n        'balanced',\n        classes=np.unique(train_set.classes),\n        y=train_set.classes\n    )\n    class_weight_dict = dict(enumerate(class_weights))\n    \n    print(\"\\n‚úÖ Class weights calculated:\")\n    for emotion, weight in zip(class_labels, class_weights):\n        print(f\"  {emotion:>10}: {weight:.3f}\")\nelse:\n    print(\"\\n‚ö†Ô∏è  Class weights disabled\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"baa95eff","cell_type":"code","source":"# =======================================================================\n# Enhanced Model Building Functions\n# =======================================================================\n\n\ndef build_improved_cnn(cfg):\n    \"\"\"Enhanced CNN with better architecture.\"\"\"\n    \n    \n    #color_mode = cfg.get(\"color_mode\", \"grayscale\")\n    channels = 1 if color_mode == \"grayscale\" else 3\n    input_shape = (picture_size, picture_size, channels)\n    \n    model = Sequential()\n    \n    # Block 1 - Double Conv\n    model.add(Conv2D(filters=64, \n                      kernel_size=(3, 3), \n                      padding='same', \n                      input_shape=input_shape,\n                      name='conv2d_1'))\n    model.add(BatchNormalization(name='bn_1'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_1'))\n    model.add(Dropout(dropout_rate,name='dropout_1'))\n    \n    \n    # Block 2 - Double Conv\n    model.add(Conv2D(filters=128, \n                      kernel_size=(5, 5), \n                      padding='same', \n                      input_shape=input_shape,\n                      name='conv2d_2'))\n    model.add(BatchNormalization(name='bn_2'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_2'))\n    model.add(Dropout(dropout_rate,name='dropout_2'))\n    \n    # Block 3 - Double Conv\n    model.add(Conv2D(filters=512, \n                      kernel_size=(3, 3), \n                      padding='same', \n                      input_shape=input_shape,\n                      name='conv2d_3'))\n    model.add(BatchNormalization(name='bn_3'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_3'))\n    model.add(Dropout(dropout_rate,name='dropout_3'))\n    \n    # Block 4 - Double Conv\n    model.add(Conv2D(filters=512, \n                      kernel_size=(3, 3), \n                      padding='same', \n                      input_shape=input_shape,\n                      name='conv2d_4'))\n    model.add(BatchNormalization(name='bn_4'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_4'))\n    model.add(Dropout(dropout_rate,name='dropout_4'))\n\n    \n    # Block 5 - Double Conv\n    model.add(Conv2D(filters=512, \n                      kernel_size=(3, 3), \n                      padding='same', \n                      input_shape=input_shape,\n                      name='conv2d_5'))\n    model.add(BatchNormalization(name='bn_5'))\n    model.add(Activation('elu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_5'))\n    model.add(Dropout(dropout_rate,name='dropout_5'))\n    \n    \n    model.add(Flatten())\n    \"\"\"\n    #Fully connected 1st Layer\n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n    \n    #Fully connected 2nd layer\n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n    \"\"\"\n    \n    # Output layer\n    model.add(Dense(no_of_classes, activation='softmax', dtype='float32', name='out_layer'))\n    \n    # Compile with optimizer choice\n    optimizer_name = cfg.get(\"optimizer\", \"adam\")\n    if optimizer_name == \"adam\":\n        opt = Adam(learning_rate=learning_rate)\n    elif optimizer_name == \"adamw\":\n        opt = tf.keras.optimizers.AdamW(\n            learning_rate=learning_rate,\n            weight_decay=cfg.get(\"weight_decay\", 1e-4)\n        )\n    elif optimizer_name == \"sgd\":\n        opt = tf.keras.optimizers.SGD(\n            learning_rate=learning_rate,\n            momentum=0.9,\n            nesterov=True\n        )\n    \n    model.compile(\n        optimizer=opt,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    \n    return model, None\n\n# Build model based on configuration\nprint(f\"\\n{'='*70}\")\nprint(f\"Building model with '{cfg['backbone']}' backbone...\")\nprint(f\"{'='*70}\")\n\nif cfg[\"backbone\"] == \"custom_cnn\":\n     model, base_model = build_improved_cnn(cfg)\nelse:\n    print (\"removed mobilenet and efficientnet model code\")\n\nprint(f\"\\n‚úÖ Model built successfully\")\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"45e05a8d","cell_type":"code","source":"# =======================================================================\n# Advanced Training Callbacks\n# =======================================================================\n\n# Checkpoint\ncheckpoint = ModelCheckpoint(\n    'best_model.keras',\n    monitor='val_accuracy',\n    save_best_only=True,\n    mode='max',\n    verbose=1\n)\n\n# Early stopping with more patience\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=3,  # Increased from 10\n    restore_best_weights=True,\n    verbose=1\n)\n\n# Reduce learning rate on plateau\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,\n    patience=3,  # Increased from 5\n    min_lr=0.0001,\n    verbose=1\n)\n\n# Cosine annealing schedule (Improvement #5)\ndef cosine_annealing(epoch, lr):\n    \"\"\"Cosine annealing learning rate schedule.\"\"\"\n    import math\n    epochs = cfg.get(\"epochs\", 50)\n    initial_lr = cfg.get(\"learning_rate\", 1e-4)\n    min_lr = 1e-7\n    \n    if epoch < 5:  # Warmup phase\n        return initial_lr * (epoch + 1) / 5\n    else:\n        progress = (epoch - 5) / (epochs - 5)\n        return min_lr + (initial_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n\ncallbacks_list = [checkpoint, early_stopping, reduce_lr]\n\nif cfg.get(\"use_lr_schedule\", False):\n    lr_scheduler = LearningRateScheduler(cosine_annealing, verbose=1)\n    callbacks_list.append(lr_scheduler)\n    print(\"‚úÖ Using cosine annealing learning rate schedule\")\nelse:\n    callbacks_list.append(reduce_lr)\n    print(\"‚úÖ Using ReduceLROnPlateau\")\n\nprint(f\"‚úÖ Callbacks configured: {len(callbacks_list)} callbacks\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0ecd8386","cell_type":"code","source":"# =======================================================================\n# Model Training\n# =======================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üöÄ STARTING TRAINING\")\nprint(\"=\"*70)\nprint(f\"Target: {epochs} epochs with early stopping\")\nprint(f\"Batch size: {batch_size}\")\nprint(f\"Learning rate: {learning_rate}\")\nprint(f\"Augmentation: {cfg['aug_level']}\")\nprint(f\"Backbone: {cfg['backbone']}\")\nprint(f\"Class weights: {'Enabled' if class_weight_dict else 'Disabled'}\")\nprint(\"=\"*70)\n\nhistory = model.fit(\n    train_set,\n    steps_per_epoch=train_set.n // train_set.batch_size,\n    epochs=epochs,\n    validation_data=validation_set,\n    validation_steps=validation_set.n // validation_set.batch_size,\n    callbacks=callbacks_list,\n    class_weight=class_weight_dict,  # Improvement #3\n    verbose=1\n)\n\nprint(\"\\n‚úÖ Initial training complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0fd9c3b8","cell_type":"code","source":"# =======================================================================\n# Training History Visualization\n# =======================================================================\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# Accuracy plot\naxes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\naxes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\naxes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Epoch', fontsize=12)\naxes[0].set_ylabel('Accuracy', fontsize=12)\naxes[0].legend(fontsize=10)\naxes[0].grid(True, alpha=0.3)\n\n# Loss plot\naxes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\naxes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\naxes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Epoch', fontsize=12)\naxes[1].set_ylabel('Loss', fontsize=12)\naxes[1].legend(fontsize=10)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_history.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# Final evaluation\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìä FINAL EVALUATION\")\nprint(\"=\"*70)\ntrain_loss, train_acc = model.evaluate(train_set, verbose=0)\nval_loss, val_acc = model.evaluate(validation_set, verbose=0)\n\nprint(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\nprint(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\nprint(f\"Training Loss:       {train_loss:.4f}\")\nprint(f\"Validation Loss:     {val_loss:.4f}\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"692049e8","cell_type":"code","source":"# =======================================================================\n# Detailed Performance Analysis\n# =======================================================================\n\nfrom keras.models import load_model\n\n# Load best model\nmy_model = load_model('best_model.keras', compile=False)\n\n# Get predictions\nprint(\"Generating predictions on validation set...\")\nvalidation_set.reset()\npredictions = my_model.predict(validation_set, verbose=1)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = validation_set.classes\n\n# Calculate metrics\naccuracy = np.mean(predicted_classes == true_classes)\ncm = confusion_matrix(true_classes, predicted_classes)\n\nprint(f\"\\n‚úÖ Best Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"be851daf","cell_type":"code","source":"# =======================================================================\n# Enhanced Performance Visualizations\n# =======================================================================\n\n# 1. Confusion Matrix\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n            xticklabels=class_labels,\n            yticklabels=class_labels,\n            cbar_kws={'label': 'Count'},\n            linewidths=0.5,\n            linecolor='gray')\nplt.title('Confusion Matrix - Emotion Recognition', fontsize=16, fontweight='bold', pad=20)\nplt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\nplt.ylabel('True Emotion', fontsize=13, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# 2. Normalized Confusion Matrix\ncm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n            xticklabels=class_labels,\n            yticklabels=class_labels,\n            cbar_kws={'label': 'Percentage'})\nplt.title('Normalized Confusion Matrix (%)', fontsize=16, fontweight='bold', pad=20)\nplt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\nplt.ylabel('True Emotion', fontsize=13, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.savefig('confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# 3. Classification Report\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìà DETAILED CLASSIFICATION METRICS\")\nprint(\"=\"*70)\nprint(classification_report(true_classes, predicted_classes, \n                           target_names=class_labels,\n                           digits=4))\n\n# 4. Per-Class Metrics Bar Chart\nprecision, recall, f1, support = precision_recall_fscore_support(\n    true_classes, predicted_classes, labels=range(7)\n)\n\nfig, ax = plt.subplots(figsize=(14, 6))\nx = np.arange(len(class_labels))\nwidth = 0.25\n\nbars1 = ax.bar(x - width, precision, width, label='Precision', color='#3498db')\nbars2 = ax.bar(x, recall, width, label='Recall', color='#2ecc71')\nbars3 = ax.bar(x + width, f1, width, label='F1-Score', color='#e74c3c')\n\nax.set_xlabel('Emotion', fontsize=12, fontweight='bold')\nax.set_ylabel('Score', fontsize=12, fontweight='bold')\nax.set_title('Per-Emotion Performance Metrics', fontsize=14, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(class_labels, rotation=45, ha='right')\nax.legend()\nax.grid(axis='y', alpha=0.3)\nax.set_ylim([0, 1.1])\n\n# Add value labels on bars\nfor bars in [bars1, bars2, bars3]:\n    for bar in bars:\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.2f}',\n                ha='center', va='bottom', fontsize=8)\n\nplt.tight_layout()\nplt.savefig('per_class_metrics.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# 5. Summary Table\nsummary_df = pd.DataFrame({\n    'Emotion': class_labels,\n    'Precision': [f'{p:.2%}' for p in precision],\n    'Recall': [f'{r:.2%}' for r in recall],\n    'F1-Score': [f'{f:.2%}' for f in f1],\n    'Support': support.astype(int)\n})\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìä PERFORMANCE SUMMARY TABLE\")\nprint(\"=\"*70)\nprint(summary_df.to_string(index=False))\nprint(\"=\"*70)\n\n# 6. Misclassification Analysis\nmisclassified = cm.copy()\nnp.fill_diagonal(misclassified, 0)\n\ntop_confusions = []\nfor i in range(7):\n    for j in range(7):\n        if i != j:\n            top_confusions.append((class_labels[i], class_labels[j], misclassified[i, j]))\n\ntop_confusions.sort(key=lambda x: x[2], reverse=True)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚ö†Ô∏è  TOP 5 MISCLASSIFICATION PAIRS\")\nprint(\"=\"*70)\nfor true_label, pred_label, count in top_confusions[:5]:\n    print(f\"{true_label:>10} ‚Üí {pred_label:<10} : {count:>4} times\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ef8ce84f","cell_type":"code","source":"# =======================================================================\n# Save Model with Timestamp\n# =======================================================================\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nmodel_name = f\"emotion_recognition_{timestamp}.keras\"\n\nif is_on_kaggle():\n    output_path = \"/kaggle/working/\"+timestamp+\"/\"\nelse:\n    output_path = \"outputs/\"+timestamp+\"/\"\n    \nos.makedirs(output_path, exist_ok=True)\nfull_path = Path(output_path) / model_name\nmodel.save(str(full_path))\n\nprint(f\"\\nüíæ Model saved: {full_path}\")\nprint(f\"üìä Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"12cf82e7","cell_type":"code","source":"# =======================================================================\n# Ensemble Training (Optional)\n# =======================================================================\n\nif cfg.get(\"use_ensemble\", False):\n    print(\"\\n\" + \"=\"*70)\n    print(\"üéØ TRAINING ENSEMBLE MODELS\")\n    print(\"=\"*70)\n    \n    n_models = cfg.get(\"n_ensemble_models\", 3)\n    ensemble_models = []\n    \n    for i in range(n_models):\n        print(f\"\\n{'='*70}\")\n        print(f\"Training Ensemble Model {i+1}/{n_models}\")\n        print(f\"{'='*70}\")\n        \n        # Vary hyperparameters slightly\n        cfg_copy = cfg.copy()\n        cfg_copy[\"learning_rate\"] = cfg[\"learning_rate\"] * (0.8 + 0.4 * np.random.random())\n        cfg_copy[\"dropout_rate\"] = 0.3 + 0.2 * np.random.random()\n        \n        # Build model\n        if cfg[\"backbone\"] in [\"mobilenet\", \"efficientnet\"]:\n            ensemble_model, _ = build_transfer_learning_model(cfg_copy)\n        else:\n            ensemble_model, _ = build_improved_cnn(cfg_copy)\n        \n        # Train\n        history_ens = ensemble_model.fit(\n            train_set,\n            validation_data=validation_set,\n            epochs=30,\n            callbacks=[early_stopping, reduce_lr],\n            class_weight=class_weight_dict,\n            verbose=1\n        )\n        \n        ensemble_models.append(ensemble_model)\n        \n        # Save\n        ensemble_model.save(f\"ensemble_model_{i+1}.keras\")\n    \n    # Ensemble prediction\n    print(\"\\n\" + \"=\"*70)\n    print(\"üéØ ENSEMBLE PREDICTION\")\n    print(\"=\"*70)\n    \n    validation_set.reset()\n    ensemble_predictions = []\n    \n    for i, ens_model in enumerate(ensemble_models):\n        print(f\"Getting predictions from model {i+1}...\")\n        pred = ens_model.predict(validation_set, verbose=0)\n        ensemble_predictions.append(pred)\n    \n    # Average predictions\n    avg_predictions = np.mean(ensemble_predictions, axis=0)\n    ensemble_predicted_classes = np.argmax(avg_predictions, axis=1)\n    \n    # Evaluate ensemble\n    ensemble_accuracy = np.mean(ensemble_predicted_classes == true_classes)\n    \n    print(f\"\\n‚úÖ Ensemble Accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n    print(f\"üìà Improvement over single model: {(ensemble_accuracy - accuracy)*100:.2f}%\")\nelse:\n    print(\"\\n‚ö†Ô∏è  Ensemble training disabled (set 'use_ensemble': True to enable)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8ff50765","cell_type":"code","source":"# =======================================================================\n# Sample Predictions Visualization\n# =======================================================================\nimport random\n\n# Get a random batch from validation set\nrandom_batch_idx = random.randint(0, len(validation_set) - 1)\nsample_images, sample_labels = validation_set[random_batch_idx]\n\n# Predict\nsample_preds = my_model.predict(sample_images, verbose=0)\nsample_pred_classes = np.argmax(sample_preds, axis=1)\nsample_true_classes = np.argmax(sample_labels, axis=1)\n\n# Randomly select 16 indices from the batch\nnum_samples = min(16, len(sample_images))\nrandom_indices = random.sample(range(len(sample_images)), num_samples)\n\n# Visualize predictions\nfig, axes = plt.subplots(4, 4, figsize=(12, 12))\naxes = axes.ravel()\n\nfor i, idx in enumerate(random_indices):\n    axes[i].imshow(sample_images[idx].squeeze(), cmap='gray')\n    \n    true_label = class_labels[sample_true_classes[idx]]\n    pred_label = class_labels[sample_pred_classes[idx]]\n    confidence = sample_preds[idx][sample_pred_classes[idx]] * 100\n\n    # Color: green if correct, red if wrong\n    color = 'green' if sample_true_classes[idx] == sample_pred_classes[idx] else 'red'\n    \n    axes[i].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n                     color=color, fontweight='bold')\n    axes[i].axis('off')\n\nplt.suptitle('Sample Predictions on Validation Set', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}