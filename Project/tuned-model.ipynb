{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0697d144",
   "metadata": {},
   "source": [
    "Tuning opportunities\n",
    "1. Configuration-Based Hyperparameter Tuning\n",
    "2. Enhanced Data Augmentation\n",
    "3. Improved Model Architecture\n",
    "4. Advanced Callbacks\n",
    "5. Transfer Learning (Often Best Results)\n",
    "6. Class Imbalance Handling\n",
    "7. Ensemble Methods\n",
    "8. Systematic Tuning Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9fe6a",
   "metadata": {},
   "source": [
    "Quick Start Guide:\n",
    "For best results immediately: Set \"backbone\": \"mobilenet\" and \"fine_tune\": True\n",
    "For faster training: Set \"backbone\": \"custom_cnn\" and \"aug_level\": \"light\"\n",
    "For maximum accuracy: Enable ensemble with \"use_ensemble\": True\n",
    "For experimentation: Uncomment Cell 17 to run systematic tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00b4b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.1\n",
      "Python executable: c:\\Users\\marty\\anaconda3\\envs\\tf311_env\\python.exe\n",
      "âœ… All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Facial Emotion Recognition - Enhanced with 8 Tuning Improvements\n",
    "# =======================================================================\n",
    "\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning libraries\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Flatten, Dropout, Dense, Input, \n",
    "    GlobalAveragePooling2D, Conv2D, \n",
    "    BatchNormalization, Activation, MaxPooling2D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, \n",
    "    ReduceLROnPlateau, LearningRateScheduler)\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c880f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’» Running on local machine\n",
      "Data folder path: data/images/\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Environment Detection\n",
    "# =======================================================================\n",
    "\n",
    "def is_on_kaggle():\n",
    "    \"\"\"Detect if running on Kaggle.\"\"\"\n",
    "    return os.path.exists('/kaggle/input')\n",
    "\n",
    "def get_data_path():\n",
    "    \"\"\"Detect environment and return appropriate data path.\"\"\"\n",
    "    if is_on_kaggle():\n",
    "        print(\"ğŸŒ Running on Kaggle\")\n",
    "        import kagglehub\n",
    "        image_path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
    "        folder_path = os.path.join(image_path, \"images\")\n",
    "    else:\n",
    "        print(\"ğŸ’» Running on local machine\")\n",
    "        folder_path = \"data/images/\"\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "folder_path = get_data_path()\n",
    "print(f\"Data folder path: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1475dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  backbone: mobilenet\n",
      "  picture_size: 48\n",
      "  color_mode: rgb\n",
      "  batch_size: 32\n",
      "  epochs: 1\n",
      "  learning_rate: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  cnn_layers: [{'filters': 64, 'kernel_size': (3, 3)}, {'filters': 128, 'kernel_size': (3, 3)}, {'filters': 256, 'kernel_size': (3, 3)}, {'filters': 512, 'kernel_size': (3, 3)}, {'filters': 512, 'kernel_size': (3, 3)}]\n",
      "  dense_units: [512, 256]\n",
      "  aug_level: strong\n",
      "  precision: mixed\n",
      "  fine_tune: True\n",
      "  fine_tune_epochs: 15\n",
      "  optimizer: adam\n",
      "  weight_decay: 0.0001\n",
      "  use_lr_schedule: True\n",
      "  use_class_weights: True\n",
      "  use_ensemble: False\n",
      "  n_ensemble_models: 3\n",
      "  no_of_classes: 7\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Configuration with Tuning Options\n",
    "# =======================================================================\n",
    "\n",
    "cfg = {\n",
    "    # Model Architecture\n",
    "    \"backbone\": \"mobilenet\",  # Options: \"custom_cnn\", \"mobilenet\", \"efficientnet\"\n",
    "    \n",
    "    # Image Parameters\n",
    "    \"picture_size\": 48,  # Try: 64, 96 for more detail\n",
    "    \"color_mode\": \"rgb\",  # \"grayscale\" or \"rgb\" (rgb required for transfer learning)\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch_size\": 32,  # Reduced from 128 for better gradient estimates\n",
    "    \"epochs\": 1,  # Increased from 30\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"dropout_rate\": 0.4,  # Increased from 0.25\n",
    "    \n",
    "    # CNN Architecture (for custom_cnn only)\n",
    "    \"cnn_layers\": [\n",
    "        {\"filters\": 64, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 128, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 256, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 512, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 512, \"kernel_size\": (3, 3)},\n",
    "    ],\n",
    "    \n",
    "    # Dense layers\n",
    "    \"dense_units\": [512, 256],\n",
    "    \n",
    "    # Data Augmentation (Improvement #2)\n",
    "    \"aug_level\": \"strong\",  # Options: \"none\", \"light\", \"strong\", \"aggressive\"\n",
    "    \n",
    "    # Advanced Training\n",
    "    \"precision\": \"mixed\",  # \"float32\" or \"mixed\"\n",
    "    \"fine_tune\": True,  # Enable fine-tuning for transfer learning\n",
    "    \"fine_tune_epochs\": 15,\n",
    "    \n",
    "    # Optimizer\n",
    "    \"optimizer\": \"adam\",  # Options: \"adam\", \"adamw\", \"sgd\"\n",
    "    \"weight_decay\": 1e-4,  # For AdamW\n",
    "    \n",
    "    # Learning Rate Schedule\n",
    "    \"use_lr_schedule\": True,  # Cosine annealing (Improvement #5)\n",
    "    \n",
    "    # Class Weights (Improvement #3)\n",
    "    \"use_class_weights\": True,\n",
    "    \n",
    "    # Ensemble (Improvement #7)\n",
    "    \"use_ensemble\": False,  # Set True to train multiple models\n",
    "    \"n_ensemble_models\": 3,\n",
    "    \n",
    "    # Model Parameters\n",
    "    \"no_of_classes\": 7,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract commonly used values\n",
    "picture_size = cfg[\"picture_size\"]\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "epochs = cfg[\"epochs\"]\n",
    "learning_rate = cfg[\"learning_rate\"]\n",
    "no_of_classes = cfg[\"no_of_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb74f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mixed precision training enabled - expect 2-3x speedup!\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Mixed Precision Training\n",
    "# =======================================================================\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "if cfg.get(\"precision\", \"float32\") == \"mixed\":\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"âœ… Mixed precision training enabled - expect 2-3x speedup!\")\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "    print(\"Using float32 precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "365719a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using 'strong' augmentation level\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Data Augmentation\n",
    "# =======================================================================\n",
    "\n",
    "aug_map = {\n",
    "    \"none\": dict(rescale=1./255),\n",
    "    \n",
    "    \"light\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True\n",
    "    ),\n",
    "    \n",
    "    \"strong\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    ),\n",
    "    \n",
    "    \"aggressive\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.25,\n",
    "        brightness_range=[0.6, 1.4],\n",
    "        horizontal_flip=True,\n",
    "        channel_shift_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create data generators\n",
    "datagen_train = ImageDataGenerator(**aug_map[cfg[\"aug_level\"]])\n",
    "datagen_validation = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(f\"âœ… Using '{cfg['aug_level']}' augmentation level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db6c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n",
      "\n",
      "âœ… Data loaded successfully\n",
      "Training samples: 28821\n",
      "Validation samples: 7066\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Load Training and Validation Data\n",
    "# =======================================================================\n",
    "\n",
    "# Determine color mode\n",
    "color_mode = cfg[\"color_mode\"]\n",
    "\n",
    "# Create training set\n",
    "train_set = datagen_train.flow_from_directory(\n",
    "    os.path.join(folder_path, \"train\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Create validation set\n",
    "validation_set = datagen_validation.flow_from_directory(\n",
    "    os.path.join(folder_path, \"validation\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Data loaded successfully\")\n",
    "print(f\"Training samples: {train_set.n}\")\n",
    "print(f\"Validation samples: {validation_set.n}\")\n",
    "print(f\"Class indices: {train_set.class_indices}\")\n",
    "\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a196b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Class weights calculated:\n",
      "       Angry: 1.031\n",
      "     Disgust: 9.443\n",
      "        Fear: 1.003\n",
      "       Happy: 0.575\n",
      "     Neutral: 0.826\n",
      "         Sad: 0.834\n",
      "    Surprise: 1.285\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Calculate Class Weights for Imbalanced Data\n",
    "# =======================================================================\n",
    "\n",
    "class_weight_dict = None\n",
    "\n",
    "if cfg.get(\"use_class_weights\", False):\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_set.classes),\n",
    "        y=train_set.classes\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    print(\"\\nâœ… Class weights calculated:\")\n",
    "    for emotion, weight in zip(class_labels, class_weights):\n",
    "        print(f\"  {emotion:>10}: {weight:.3f}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Class weights disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa95eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Building model with 'mobilenet' backbone...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marty\\AppData\\Local\\Temp\\ipykernel_5740\\2284031773.py:114: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model built successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚         \u001b[38;5;34m5,120\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m655,872\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              â”‚         \u001b[38;5;34m1,799\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,054,151</span> (11.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,054,151\u001b[0m (11.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">792,583</span> (3.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m792,583\u001b[0m (3.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,261,568</span> (8.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,261,568\u001b[0m (8.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Model Building Functions\n",
    "# =======================================================================\n",
    "\n",
    "def build_improved_cnn(cfg):\n",
    "    \"\"\"Enhanced CNN with better architecture.\"\"\"\n",
    "    \n",
    "    picture_size = cfg.get(\"picture_size\", 48)\n",
    "    no_of_classes = cfg.get(\"no_of_classes\", 7)\n",
    "    learning_rate = cfg.get(\"learning_rate\", 1e-4)\n",
    "    dropout_rate = cfg.get(\"dropout_rate\", 0.4)\n",
    "    \n",
    "    color_mode = cfg.get(\"color_mode\", \"grayscale\")\n",
    "    channels = 1 if color_mode == \"grayscale\" else 3\n",
    "    input_shape = (picture_size, picture_size, channels)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1 - Double Conv\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate * 0.5))\n",
    "    \n",
    "    # Block 2 - Double Conv\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate * 0.6))\n",
    "    \n",
    "    # Block 3 - Double Conv\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate * 0.7))\n",
    "    \n",
    "    # Block 4 - Double Conv\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense layers with progressive dropout\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate * 0.7))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(no_of_classes, activation='softmax', dtype='float32'))\n",
    "    \n",
    "    # Compile with optimizer choice\n",
    "    optimizer_name = cfg.get(\"optimizer\", \"adam\")\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        opt = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=cfg.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate,\n",
    "            momentum=0.9,\n",
    "            nesterov=True\n",
    "        )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, None\n",
    "\n",
    "\n",
    "def build_transfer_learning_model(cfg):\n",
    "    \"\"\"Transfer learning with MobileNetV2 or EfficientNetB0 (Improvement #1).\"\"\"\n",
    "    \n",
    "    picture_size = cfg.get(\"picture_size\", 48)\n",
    "    no_of_classes = cfg.get(\"no_of_classes\", 7)\n",
    "    learning_rate = cfg.get(\"learning_rate\", 1e-4)\n",
    "    \n",
    "    # Must use RGB for transfer learning\n",
    "    input_shape = (picture_size, picture_size, 3)\n",
    "    \n",
    "    # Choose backbone\n",
    "    backbone = cfg.get(\"backbone\", \"mobilenet\")\n",
    "    \n",
    "    if backbone == \"mobilenet\":\n",
    "        base_model = MobileNetV2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif backbone == \"efficientnet\":\n",
    "        base_model = EfficientNetB0(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(no_of_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "\n",
    "# Build model based on configuration\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Building model with '{cfg['backbone']}' backbone...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if cfg[\"backbone\"] in [\"mobilenet\", \"efficientnet\"]:\n",
    "    model, base_model = build_transfer_learning_model(cfg)\n",
    "else:\n",
    "    model, base_model = build_improved_cnn(cfg)\n",
    "\n",
    "print(f\"\\nâœ… Model built successfully\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e05a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using cosine annealing learning rate schedule\n",
      "âœ… Callbacks configured: 4 callbacks\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Advanced Training Callbacks\n",
    "# =======================================================================\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping with more patience\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Increased from 5\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,  # Increased from 3\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Cosine annealing schedule (Improvement #5)\n",
    "def cosine_annealing(epoch, lr):\n",
    "    \"\"\"Cosine annealing learning rate schedule.\"\"\"\n",
    "    import math\n",
    "    epochs = cfg.get(\"epochs\", 50)\n",
    "    initial_lr = cfg.get(\"learning_rate\", 1e-4)\n",
    "    min_lr = 1e-7\n",
    "    \n",
    "    if epoch < 5:  # Warmup phase\n",
    "        return initial_lr * (epoch + 1) / 5\n",
    "    else:\n",
    "        progress = (epoch - 5) / (epochs - 5)\n",
    "        return min_lr + (initial_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "if cfg.get(\"use_lr_schedule\", False):\n",
    "    lr_scheduler = LearningRateScheduler(cosine_annealing, verbose=1)\n",
    "    callbacks_list.append(lr_scheduler)\n",
    "    print(\"âœ… Using cosine annealing learning rate schedule\")\n",
    "\n",
    "print(f\"âœ… Callbacks configured: {len(callbacks_list)} callbacks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ecd8386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ STARTING TRAINING\n",
      "======================================================================\n",
      "Target: 1 epochs with early stopping\n",
      "Batch size: 32\n",
      "Learning rate: 0.0001\n",
      "Augmentation: strong\n",
      "Backbone: mobilenet\n",
      "Class weights: Enabled\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marty\\anaconda3\\envs\\tf311_env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 2e-05.\n",
      "\u001b[1m900/900\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.1739 - loss: 2.6122\n",
      "Epoch 1: val_accuracy improved from None to 0.24560, saving model to best_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 311ms/step - accuracy: 0.1723 - loss: 2.5145 - val_accuracy: 0.2456 - val_loss: 1.9684 - learning_rate: 2.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "âœ… Initial training complete!\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Model Training\n",
    "# =======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Target: {epochs} epochs with early stopping\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Augmentation: {cfg['aug_level']}\")\n",
    "print(f\"Backbone: {cfg['backbone']}\")\n",
    "print(f\"Class weights: {'Enabled' if class_weight_dict else 'Disabled'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    steps_per_epoch=train_set.n // train_set.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=validation_set.n // validation_set.batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weight_dict,  # Improvement #3\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Initial training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c2f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”§ STARTING FINE-TUNING PHASE\n",
      "======================================================================\n",
      "Unfrozen layers: 20\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Fine-Tuning Phase (for Transfer Learning)\n",
    "# =======================================================================\n",
    "\n",
    "if cfg.get(\"backbone\") in [\"mobilenet\", \"efficientnet\"] and cfg.get(\"fine_tune\", False):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ”§ STARTING FINE-TUNING PHASE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Unfreeze the last layers\n",
    "    base_model.trainable = True\n",
    "    fine_tune_at = len(base_model.layers) - 20  # Unfreeze last 20 layers\n",
    "    \n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    print(f\"Unfrozen layers: {sum([1 for layer in base_model.layers if layer.trainable])}\")\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate/10),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Fine-tune for additional epochs\n",
    "    fine_tune_epochs = cfg.get(\"fine_tune_epochs\", 15)\n",
    "    \n",
    "    history_fine = model.fit(\n",
    "        train_set,\n",
    "        validation_data=validation_set,\n",
    "        epochs=fine_tune_epochs,\n",
    "        callbacks=callbacks_list,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Merge histories\n",
    "    for key in history.history.keys():\n",
    "        history.history[key].extend(history_fine.history[key])\n",
    "    \n",
    "    print(\"âœ… Fine-tuning completed!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Skipping fine-tuning (only for transfer learning models)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Training History Visualization\n",
    "# =======================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š FINAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "train_loss, train_acc = model.evaluate(train_set, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(validation_set, verbose=0)\n",
    "\n",
    "print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"Training Loss:       {train_loss:.4f}\")\n",
    "print(f\"Validation Loss:     {val_loss:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692049e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Detailed Performance Analysis\n",
    "# =======================================================================\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "my_model = load_model('best_model.keras', compile=False)\n",
    "\n",
    "# Get predictions\n",
    "print(\"Generating predictions on validation set...\")\n",
    "validation_set.reset()\n",
    "predictions = my_model.predict(validation_set, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = validation_set.classes\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "print(f\"\\nâœ… Best Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be851daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Performance Visualizations\n",
    "# =======================================================================\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray')\n",
    "plt.title('Confusion Matrix - Emotion Recognition', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Normalized Confusion Matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Percentage'})\n",
    "plt.title('Normalized Confusion Matrix (%)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ DETAILED CLASSIFICATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                           target_names=class_labels,\n",
    "                           digits=4))\n",
    "\n",
    "# 4. Per-Class Metrics Bar Chart\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    true_classes, predicted_classes, labels=range(7)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = np.arange(len(class_labels))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, precision, width, label='Precision', color='#3498db')\n",
    "bars2 = ax.bar(x, recall, width, label='Recall', color='#2ecc71')\n",
    "bars3 = ax.bar(x + width, f1, width, label='F1-Score', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Emotion', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Per-Emotion Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Summary Table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Emotion': class_labels,\n",
    "    'Precision': [f'{p:.2%}' for p in precision],\n",
    "    'Recall': [f'{r:.2%}' for r in recall],\n",
    "    'F1-Score': [f'{f:.2%}' for f in f1],\n",
    "    'Support': support.astype(int)\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š PERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 6. Misclassification Analysis\n",
    "misclassified = cm.copy()\n",
    "np.fill_diagonal(misclassified, 0)\n",
    "\n",
    "top_confusions = []\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        if i != j:\n",
    "            top_confusions.append((class_labels[i], class_labels[j], misclassified[i, j]))\n",
    "\n",
    "top_confusions.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš ï¸  TOP 5 MISCLASSIFICATION PAIRS\")\n",
    "print(\"=\"*70)\n",
    "for true_label, pred_label, count in top_confusions[:5]:\n",
    "    print(f\"{true_label:>10} â†’ {pred_label:<10} : {count:>4} times\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ce84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Save Model with Timestamp\n",
    "# =======================================================================\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"emotion_recognition_{timestamp}.keras\"\n",
    "\n",
    "if is_on_kaggle():\n",
    "    output_path = \"/kaggle/working/\"\n",
    "else:\n",
    "    output_path = \".\"\n",
    "\n",
    "full_path = Path(output_path) / model_name\n",
    "model.save(str(full_path))\n",
    "\n",
    "print(f\"\\nğŸ’¾ Model saved: {full_path}\")\n",
    "print(f\"ğŸ“Š Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Ensemble Training (Optional)\n",
    "# =======================================================================\n",
    "\n",
    "if cfg.get(\"use_ensemble\", False):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ¯ TRAINING ENSEMBLE MODELS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    n_models = cfg.get(\"n_ensemble_models\", 3)\n",
    "    ensemble_models = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Training Ensemble Model {i+1}/{n_models}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Vary hyperparameters slightly\n",
    "        cfg_copy = cfg.copy()\n",
    "        cfg_copy[\"learning_rate\"] = cfg[\"learning_rate\"] * (0.8 + 0.4 * np.random.random())\n",
    "        cfg_copy[\"dropout_rate\"] = 0.3 + 0.2 * np.random.random()\n",
    "        \n",
    "        # Build model\n",
    "        if cfg[\"backbone\"] in [\"mobilenet\", \"efficientnet\"]:\n",
    "            ensemble_model, _ = build_transfer_learning_model(cfg_copy)\n",
    "        else:\n",
    "            ensemble_model, _ = build_improved_cnn(cfg_copy)\n",
    "        \n",
    "        # Train\n",
    "        history_ens = ensemble_model.fit(\n",
    "            train_set,\n",
    "            validation_data=validation_set,\n",
    "            epochs=30,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        ensemble_models.append(ensemble_model)\n",
    "        \n",
    "        # Save\n",
    "        ensemble_model.save(f\"ensemble_model_{i+1}.keras\")\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ¯ ENSEMBLE PREDICTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    validation_set.reset()\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for i, ens_model in enumerate(ensemble_models):\n",
    "        print(f\"Getting predictions from model {i+1}...\")\n",
    "        pred = ens_model.predict(validation_set, verbose=0)\n",
    "        ensemble_predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    avg_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "    ensemble_predicted_classes = np.argmax(avg_predictions, axis=1)\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    ensemble_accuracy = np.mean(ensemble_predicted_classes == true_classes)\n",
    "    \n",
    "    print(f\"\\nâœ… Ensemble Accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
    "    print(f\"ğŸ“ˆ Improvement over single model: {(ensemble_accuracy - accuracy)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Ensemble training disabled (set 'use_ensemble': True to enable)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
