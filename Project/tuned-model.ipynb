{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0697d144",
   "metadata": {},
   "source": [
    "Tuning opportunities\n",
    "1. Configuration-Based Hyperparameter Tuning\n",
    "2. Enhanced Data Augmentation\n",
    "3. Improved Model Architecture\n",
    "4. Advanced Callbacks\n",
    "5. Transfer Learning (Often Best Results)\n",
    "6. Class Imbalance Handling\n",
    "7. Ensemble Methods\n",
    "8. Systematic Tuning Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9fe6a",
   "metadata": {},
   "source": [
    "Quick Start Guide:\n",
    "For best results immediately: Set \"backbone\": \"mobilenet\" and \"fine_tune\": True\n",
    "For faster training: Set \"backbone\": \"custom_cnn\" and \"aug_level\": \"light\"\n",
    "For maximum accuracy: Enable ensemble with \"use_ensemble\": True\n",
    "For experimentation: Uncomment Cell 17 to run systematic tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d00b4b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.1\n",
      "Python executable: c:\\Users\\marty\\anaconda3\\envs\\tf311_env\\python.exe\n",
      "‚úÖ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Facial Emotion Recognition - Enhanced with 8 Tuning Improvements\n",
    "# =======================================================================\n",
    "\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning libraries\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Flatten, Dropout, Dense, Input, \n",
    "    GlobalAveragePooling2D, Conv2D, \n",
    "    BatchNormalization, Activation, MaxPooling2D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, \n",
    "    ReduceLROnPlateau, LearningRateScheduler)\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c880f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Running on local machine\n",
      "Data folder path: data/images/\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Environment Detection\n",
    "# =======================================================================\n",
    "\n",
    "def is_on_kaggle():\n",
    "    \"\"\"Detect if running on Kaggle.\"\"\"\n",
    "    return os.path.exists('/kaggle/input')\n",
    "\n",
    "def get_data_path():\n",
    "    \"\"\"Detect environment and return appropriate data path.\"\"\"\n",
    "    if is_on_kaggle():\n",
    "        print(\"üåê Running on Kaggle\")\n",
    "        import kagglehub\n",
    "        image_path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
    "        folder_path = os.path.join(image_path, \"images\")\n",
    "    else:\n",
    "        print(\"üíª Running on local machine\")\n",
    "        folder_path = \"data/images/\"\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "folder_path = get_data_path()\n",
    "print(f\"Data folder path: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1475dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  backbone: custom_cnn\n",
      "  picture_size: 48\n",
      "  color_mode: grayscale\n",
      "  batch_size: 128\n",
      "  epochs: 20\n",
      "  learning_rate: 0.0001\n",
      "  dropout_rate: 0.5\n",
      "  dense_units: [512, 256]\n",
      "  aug_level: light\n",
      "  precision: mixed\n",
      "  fine_tune: False\n",
      "  fine_tune_epochs: 0\n",
      "  optimizer: adam\n",
      "  weight_decay: 0.0001\n",
      "  use_lr_schedule: True\n",
      "  use_class_weights: True\n",
      "  use_ensemble: False\n",
      "  n_ensemble_models: 3\n",
      "  no_of_classes: 7\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Configuration with Tuning Options\n",
    "# =======================================================================\n",
    "\n",
    "cfg = {\n",
    "    # Model Architecture\n",
    "    \"backbone\": \"custom_cnn\",  # Options: \"custom_cnn\", \"mobilenet\", \"efficientnet\"\n",
    "    \n",
    "    # Image Parameters\n",
    "    \"picture_size\": 48,  # Try: 64, 96 for more detail\n",
    "    \"color_mode\": \"grayscale\",  # \"grayscale\" or \"rgb\" (rgb required for transfer learning)\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch_size\": 128,  # Reduced from 128 for better gradient estimates\n",
    "    \"epochs\": 20,  # Increased from 30\n",
    "    \"learning_rate\": 0.0001,  # Adjusted learning rate\n",
    "    \"dropout_rate\": 0.5,  # Increased from 0.25\n",
    "     \n",
    "    # Dense layers\n",
    "    \"dense_units\": [512,256],\n",
    "    #\"dense_units\": [512],\n",
    "    \n",
    "    # Data Augmentation (Improvement #2)\n",
    "    \"aug_level\": \"light\",  # Options: \"none\", \"light\", \"strong\", \"aggressive\"\n",
    "    \n",
    "    # Advanced Training\n",
    "    \"precision\": \"mixed\",  # \"float32\" or \"mixed\"\n",
    "    \"fine_tune\": False,  # Enable fine-tuning for transfer learning\n",
    "    \"fine_tune_epochs\": 0,\n",
    "    \n",
    "    # Optimizer\n",
    "    \"optimizer\": \"adam\",  # Options: \"adam\", \"adamw\", \"sgd\"\n",
    "    \"weight_decay\": 1e-4,  # For AdamW\n",
    "    \n",
    "    # Learning Rate Schedule\n",
    "    \"use_lr_schedule\": True,  # Cosine annealing (Improvement #5)\n",
    "    \n",
    "    # Class Weights (Improvement #3)\n",
    "    \"use_class_weights\": True,\n",
    "    \n",
    "    # Ensemble (Improvement #7)\n",
    "    \"use_ensemble\": False,  # Set True to train multiple models\n",
    "    \"n_ensemble_models\": 3,\n",
    "    \n",
    "    # Model Parameters\n",
    "    \"no_of_classes\": 7,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract commonly used values\n",
    "picture_size = cfg[\"picture_size\"]\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "epochs = cfg[\"epochs\"]\n",
    "learning_rate = cfg[\"learning_rate\"]\n",
    "no_of_classes = cfg[\"no_of_classes\"]\n",
    "dropout_rate = cfg[\"dropout_rate\"]\n",
    "dense_units = cfg[\"dense_units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb74f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mixed precision training enabled - expect 2-3x speedup!\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Mixed Precision Training\n",
    "# =======================================================================\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "if cfg.get(\"precision\", \"float32\") == \"mixed\":\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"‚úÖ Mixed precision training enabled - expect 2-3x speedup!\")\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "    print(\"Using float32 precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "365719a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using 'light' augmentation level\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Data Augmentation\n",
    "# =======================================================================\n",
    "\n",
    "aug_map = {\n",
    "    \"none\": dict(rescale=1./255),\n",
    "    \n",
    "    \"light\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        horizontal_flip=True\n",
    "    ),\n",
    "    \n",
    "    \"strong\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    ),\n",
    "    \n",
    "    \"aggressive\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.25,\n",
    "        brightness_range=[0.6, 1.4],\n",
    "        horizontal_flip=True,\n",
    "        channel_shift_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create data generators\n",
    "datagen_train = ImageDataGenerator(**aug_map[cfg[\"aug_level\"]])\n",
    "datagen_validation = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(f\"‚úÖ Using '{cfg['aug_level']}' augmentation level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5db6c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n",
      "\n",
      "‚úÖ Data loaded successfully\n",
      "Training samples: 28821\n",
      "Validation samples: 7066\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Load Training and Validation Data\n",
    "# =======================================================================\n",
    "\n",
    "# Determine color mode\n",
    "color_mode = cfg[\"color_mode\"]\n",
    "\n",
    "# Create training set\n",
    "train_set = datagen_train.flow_from_directory(\n",
    "    os.path.join(folder_path, \"train\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Create validation set\n",
    "validation_set = datagen_validation.flow_from_directory(\n",
    "    os.path.join(folder_path, \"validation\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "print(f\"Training samples: {train_set.n}\")\n",
    "print(f\"Validation samples: {validation_set.n}\")\n",
    "print(f\"Class indices: {train_set.class_indices}\")\n",
    "\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a196b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Class weights calculated:\n",
      "       Angry: 1.031\n",
      "     Disgust: 9.443\n",
      "        Fear: 1.003\n",
      "       Happy: 0.575\n",
      "     Neutral: 0.826\n",
      "         Sad: 0.834\n",
      "    Surprise: 1.285\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Calculate Class Weights for Imbalanced Data\n",
    "# =======================================================================\n",
    "\n",
    "class_weight_dict = None\n",
    "\n",
    "if cfg.get(\"use_class_weights\", False):\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_set.classes),\n",
    "        y=train_set.classes\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    print(\"\\n‚úÖ Class weights calculated:\")\n",
    "    for emotion, weight in zip(class_labels, class_weights):\n",
    "        print(f\"  {emotion:>10}: {weight:.3f}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Class weights disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baa95eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Building model with 'custom_cnn' backbone...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marty\\anaconda3\\envs\\tf311_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 112\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cfg[\u001b[33m\"\u001b[39m\u001b[33mbackbone\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mcustom_cnn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m      model, base_model = \u001b[43mbuild_improved_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mremoved mobilenet and efficientnet model code\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mbuild_improved_cnn\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m     27\u001b[39m model.add(Dropout(dropout_rate,name=\u001b[33m'\u001b[39m\u001b[33mdropout_1\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Block 2 - Double Conv\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m model.add(Conv2D(filters=\u001b[32m64\u001b[39m, \n\u001b[32m     32\u001b[39m                   kernel_size=(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), \n\u001b[32m     33\u001b[39m                   padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     34\u001b[39m                   input_shape=input_shape,\n\u001b[32m     35\u001b[39m                   name=\u001b[33m'\u001b[39m\u001b[33mconv2d_2\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     36\u001b[39m model.add(BatchNormalization(name=\u001b[33m'\u001b[39m\u001b[33mbn_2\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     37\u001b[39m model.add(Activation(\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mbuild_improved_cnn\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m     27\u001b[39m model.add(Dropout(dropout_rate,name=\u001b[33m'\u001b[39m\u001b[33mdropout_1\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Block 2 - Double Conv\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m model.add(Conv2D(filters=\u001b[32m64\u001b[39m, \n\u001b[32m     32\u001b[39m                   kernel_size=(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), \n\u001b[32m     33\u001b[39m                   padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     34\u001b[39m                   input_shape=input_shape,\n\u001b[32m     35\u001b[39m                   name=\u001b[33m'\u001b[39m\u001b[33mconv2d_2\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     36\u001b[39m model.add(BatchNormalization(name=\u001b[33m'\u001b[39m\u001b[33mbn_2\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     37\u001b[39m model.add(Activation(\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:1368\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:1311\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marty\\anaconda3\\envs\\tf311_env\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marty\\anaconda3\\envs\\tf311_env\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marty\\anaconda3\\envs\\tf311_env\\Lib\\threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marty\\anaconda3\\envs\\tf311_env\\Lib\\threading.py:331\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Model Building Functions\n",
    "# =======================================================================\n",
    "\n",
    "from pyexpat import model\n",
    "\n",
    "\n",
    "def build_improved_cnn(cfg):\n",
    "    \"\"\"Enhanced CNN with better architecture.\"\"\"\n",
    "    \n",
    "    \n",
    "    #color_mode = cfg.get(\"color_mode\", \"grayscale\")\n",
    "    channels = 1 if color_mode == \"grayscale\" else 3\n",
    "    input_shape = (picture_size, picture_size, channels)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1 - Double Conv\n",
    "    model.add(Conv2D(filters=64, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same', \n",
    "                      input_shape=input_shape,\n",
    "                      name='conv2d_1'))\n",
    "    model.add(BatchNormalization(name='bn_1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_1'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_1'))\n",
    "    \n",
    "    \n",
    "    # Block 2 - Double Conv\n",
    "    model.add(Conv2D(filters=64, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same', \n",
    "                      input_shape=input_shape,\n",
    "                      name='conv2d_2'))\n",
    "    model.add(BatchNormalization(name='bn_2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_2'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_2'))\n",
    "    \n",
    "    # Block 3 - Double Conv\n",
    "    model.add(Conv2D(filters=128, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same', \n",
    "                      input_shape=input_shape,\n",
    "                      name='conv2d_3'))\n",
    "    model.add(BatchNormalization(name='bn_3'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_3'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_3'))\n",
    "    \n",
    "    # Block 4 - Double Conv\n",
    "    model.add(Conv2D(filters=256, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same', \n",
    "                      input_shape=input_shape,\n",
    "                      name='conv2d_4'))\n",
    "    model.add(BatchNormalization(name='bn_4'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_4'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_4'))\n",
    "    \n",
    "    # Block 5 - Double Conv\n",
    "    model.add(Conv2D(filters=512, \n",
    "                      kernel_size=(3, 3), \n",
    "                      padding='same', \n",
    "                      input_shape=input_shape,\n",
    "                      name='conv2d_5'))\n",
    "    model.add(BatchNormalization(name='bn_5'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_5'))\n",
    "    model.add(Dropout(dropout_rate,name='dropout_5'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(no_of_classes, activation='softmax', dtype='float32', name='out_layer'))\n",
    "    \n",
    "    # Compile with optimizer choice\n",
    "    optimizer_name = cfg.get(\"optimizer\", \"adam\")\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        opt = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=cfg.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate,\n",
    "            momentum=0.9,\n",
    "            nesterov=True\n",
    "        )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    \n",
    "    return model, None\n",
    "\n",
    "# Build model based on configuration\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Building model with '{cfg['backbone']}' backbone...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if cfg[\"backbone\"] == \"custom_cnn\":\n",
    "     model, base_model = build_improved_cnn(cfg)\n",
    "else:\n",
    "    print (\"removed mobilenet and efficientnet model code\")\n",
    "\n",
    "print(f\"\\n‚úÖ Model built successfully\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e05a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Advanced Training Callbacks\n",
    "# =======================================================================\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping with more patience\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,  # Increased from 10\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,  # Increased from 5\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Cosine annealing schedule (Improvement #5)\n",
    "def cosine_annealing(epoch, lr):\n",
    "    \"\"\"Cosine annealing learning rate schedule.\"\"\"\n",
    "    import math\n",
    "    epochs = cfg.get(\"epochs\", 50)\n",
    "    initial_lr = cfg.get(\"learning_rate\", 1e-4)\n",
    "    min_lr = 1e-7\n",
    "    \n",
    "    if epoch < 5:  # Warmup phase\n",
    "        return initial_lr * (epoch + 1) / 5\n",
    "    else:\n",
    "        progress = (epoch - 5) / (epochs - 5)\n",
    "        return min_lr + (initial_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "if cfg.get(\"use_lr_schedule\", False):\n",
    "    lr_scheduler = LearningRateScheduler(cosine_annealing, verbose=1)\n",
    "    callbacks_list.append(lr_scheduler)\n",
    "    print(\"‚úÖ Using cosine annealing learning rate schedule\")\n",
    "else:\n",
    "    callbacks_list.append(reduce_lr)\n",
    "    print(\"‚úÖ Using ReduceLROnPlateau\")\n",
    "\n",
    "print(f\"‚úÖ Callbacks configured: {len(callbacks_list)} callbacks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Model Training\n",
    "# =======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Target: {epochs} epochs with early stopping\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Augmentation: {cfg['aug_level']}\")\n",
    "print(f\"Backbone: {cfg['backbone']}\")\n",
    "print(f\"Class weights: {'Enabled' if class_weight_dict else 'Disabled'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    steps_per_epoch=train_set.n // train_set.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=validation_set.n // validation_set.batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weight_dict,  # Improvement #3\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Initial training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Training History Visualization\n",
    "# =======================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "train_loss, train_acc = model.evaluate(train_set, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(validation_set, verbose=0)\n",
    "\n",
    "print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"Training Loss:       {train_loss:.4f}\")\n",
    "print(f\"Validation Loss:     {val_loss:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692049e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Detailed Performance Analysis\n",
    "# =======================================================================\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "my_model = load_model('best_model.keras', compile=False)\n",
    "\n",
    "# Get predictions\n",
    "print(\"Generating predictions on validation set...\")\n",
    "validation_set.reset()\n",
    "predictions = my_model.predict(validation_set, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = validation_set.classes\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "print(f\"\\n‚úÖ Best Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be851daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Performance Visualizations\n",
    "# =======================================================================\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray')\n",
    "plt.title('Confusion Matrix - Emotion Recognition', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Normalized Confusion Matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Percentage'})\n",
    "plt.title('Normalized Confusion Matrix (%)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà DETAILED CLASSIFICATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                           target_names=class_labels,\n",
    "                           digits=4))\n",
    "\n",
    "# 4. Per-Class Metrics Bar Chart\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    true_classes, predicted_classes, labels=range(7)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = np.arange(len(class_labels))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, precision, width, label='Precision', color='#3498db')\n",
    "bars2 = ax.bar(x, recall, width, label='Recall', color='#2ecc71')\n",
    "bars3 = ax.bar(x + width, f1, width, label='F1-Score', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Emotion', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Per-Emotion Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Summary Table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Emotion': class_labels,\n",
    "    'Precision': [f'{p:.2%}' for p in precision],\n",
    "    'Recall': [f'{r:.2%}' for r in recall],\n",
    "    'F1-Score': [f'{f:.2%}' for f in f1],\n",
    "    'Support': support.astype(int)\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä PERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 6. Misclassification Analysis\n",
    "misclassified = cm.copy()\n",
    "np.fill_diagonal(misclassified, 0)\n",
    "\n",
    "top_confusions = []\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        if i != j:\n",
    "            top_confusions.append((class_labels[i], class_labels[j], misclassified[i, j]))\n",
    "\n",
    "top_confusions.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ö†Ô∏è  TOP 5 MISCLASSIFICATION PAIRS\")\n",
    "print(\"=\"*70)\n",
    "for true_label, pred_label, count in top_confusions[:5]:\n",
    "    print(f\"{true_label:>10} ‚Üí {pred_label:<10} : {count:>4} times\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ce84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Save Model with Timestamp\n",
    "# =======================================================================\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"emotion_recognition_{timestamp}.keras\"\n",
    "\n",
    "if is_on_kaggle():\n",
    "    output_path = \"/kaggle/working/\"\n",
    "else:\n",
    "    output_path = \"outputs/\"+timestamp+\"/\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "full_path = Path(output_path) / model_name\n",
    "model.save(str(full_path))\n",
    "\n",
    "print(f\"\\nüíæ Model saved: {full_path}\")\n",
    "print(f\"üìä Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Ensemble Training (Optional)\n",
    "# =======================================================================\n",
    "\n",
    "if cfg.get(\"use_ensemble\", False):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéØ TRAINING ENSEMBLE MODELS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    n_models = cfg.get(\"n_ensemble_models\", 3)\n",
    "    ensemble_models = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Training Ensemble Model {i+1}/{n_models}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Vary hyperparameters slightly\n",
    "        cfg_copy = cfg.copy()\n",
    "        cfg_copy[\"learning_rate\"] = cfg[\"learning_rate\"] * (0.8 + 0.4 * np.random.random())\n",
    "        cfg_copy[\"dropout_rate\"] = 0.3 + 0.2 * np.random.random()\n",
    "        \n",
    "        # Build model\n",
    "        if cfg[\"backbone\"] in [\"mobilenet\", \"efficientnet\"]:\n",
    "            ensemble_model, _ = build_transfer_learning_model(cfg_copy)\n",
    "        else:\n",
    "            ensemble_model, _ = build_improved_cnn(cfg_copy)\n",
    "        \n",
    "        # Train\n",
    "        history_ens = ensemble_model.fit(\n",
    "            train_set,\n",
    "            validation_data=validation_set,\n",
    "            epochs=30,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        ensemble_models.append(ensemble_model)\n",
    "        \n",
    "        # Save\n",
    "        ensemble_model.save(f\"ensemble_model_{i+1}.keras\")\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéØ ENSEMBLE PREDICTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    validation_set.reset()\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for i, ens_model in enumerate(ensemble_models):\n",
    "        print(f\"Getting predictions from model {i+1}...\")\n",
    "        pred = ens_model.predict(validation_set, verbose=0)\n",
    "        ensemble_predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    avg_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "    ensemble_predicted_classes = np.argmax(avg_predictions, axis=1)\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    ensemble_accuracy = np.mean(ensemble_predicted_classes == true_classes)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Ensemble Accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
    "    print(f\"üìà Improvement over single model: {(ensemble_accuracy - accuracy)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Ensemble training disabled (set 'use_ensemble': True to enable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff50765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Sample Predictions Visualization\n",
    "# =======================================================================\n",
    "import random\n",
    "\n",
    "# Get a random batch from validation set\n",
    "random_batch_idx = random.randint(0, len(validation_set) - 1)\n",
    "sample_images, sample_labels = validation_set[random_batch_idx]\n",
    "\n",
    "# Predict\n",
    "sample_preds = my_model.predict(sample_images, verbose=0)\n",
    "sample_pred_classes = np.argmax(sample_preds, axis=1)\n",
    "sample_true_classes = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "# Randomly select 16 indices from the batch\n",
    "num_samples = min(16, len(sample_images))\n",
    "random_indices = random.sample(range(len(sample_images)), num_samples)\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    axes[i].imshow(sample_images[idx].squeeze(), cmap='gray')\n",
    "    \n",
    "    true_label = class_labels[sample_true_classes[idx]]\n",
    "    pred_label = class_labels[sample_pred_classes[idx]]\n",
    "    confidence = sample_preds[idx][sample_pred_classes[idx]] * 100\n",
    "\n",
    "    # Color: green if correct, red if wrong\n",
    "    color = 'green' if sample_true_classes[idx] == sample_pred_classes[idx] else 'red'\n",
    "    \n",
    "    axes[i].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
    "                     color=color, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
