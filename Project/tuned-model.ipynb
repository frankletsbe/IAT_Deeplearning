{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0697d144",
   "metadata": {},
   "source": [
    "Tuning opportunities\n",
    "1. Configuration-Based Hyperparameter Tuning\n",
    "2. Enhanced Data Augmentation\n",
    "3. Improved Model Architecture\n",
    "4. Advanced Callbacks\n",
    "5. Transfer Learning (Often Best Results)\n",
    "6. Class Imbalance Handling\n",
    "7. Ensemble Methods\n",
    "8. Systematic Tuning Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9fe6a",
   "metadata": {},
   "source": [
    "Quick Start Guide:\n",
    "For best results immediately: Set \"backbone\": \"mobilenet\" and \"fine_tune\": True\n",
    "For faster training: Set \"backbone\": \"custom_cnn\" and \"aug_level\": \"light\"\n",
    "For maximum accuracy: Enable ensemble with \"use_ensemble\": True\n",
    "For experimentation: Uncomment Cell 17 to run systematic tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00b4b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.1\n",
      "Python executable: c:\\Users\\marty\\anaconda3\\envs\\tf311_env\\python.exe\n",
      "‚úÖ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Facial Emotion Recognition - Enhanced with 8 Tuning Improvements\n",
    "# =======================================================================\n",
    "\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning libraries\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Flatten, Dropout, Dense, Input, \n",
    "    GlobalAveragePooling2D, Conv2D, \n",
    "    BatchNormalization, Activation, MaxPooling2D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, \n",
    "    ReduceLROnPlateau, LearningRateScheduler)\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c880f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Running on local machine\n",
      "Data folder path: data/images/\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Environment Detection\n",
    "# =======================================================================\n",
    "\n",
    "def is_on_kaggle():\n",
    "    \"\"\"Detect if running on Kaggle.\"\"\"\n",
    "    return os.path.exists('/kaggle/input')\n",
    "\n",
    "def get_data_path():\n",
    "    \"\"\"Detect environment and return appropriate data path.\"\"\"\n",
    "    if is_on_kaggle():\n",
    "        print(\"üåê Running on Kaggle\")\n",
    "        import kagglehub\n",
    "        image_path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
    "        folder_path = os.path.join(image_path, \"images\")\n",
    "    else:\n",
    "        print(\"üíª Running on local machine\")\n",
    "        folder_path = \"data/images/\"\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "folder_path = get_data_path()\n",
    "print(f\"Data folder path: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  backbone: mobilenet\n",
      "  picture_size: 48\n",
      "  color_mode: rgb\n",
      "  batch_size: 32\n",
      "  epochs: 1\n",
      "  learning_rate: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  cnn_layers: [{'filters': 64, 'kernel_size': (3, 3)}, {'filters': 128, 'kernel_size': (3, 3)}, {'filters': 256, 'kernel_size': (3, 3)}, {'filters': 512, 'kernel_size': (3, 3)}, {'filters': 512, 'kernel_size': (3, 3)}]\n",
      "  dense_units: [512, 256]\n",
      "  aug_level: strong\n",
      "  precision: mixed\n",
      "  fine_tune: True\n",
      "  fine_tune_epochs: 15\n",
      "  optimizer: adam\n",
      "  weight_decay: 0.0001\n",
      "  use_lr_schedule: True\n",
      "  use_class_weights: True\n",
      "  use_ensemble: False\n",
      "  n_ensemble_models: 3\n",
      "  no_of_classes: 7\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Configuration with Tuning Options\n",
    "# =======================================================================\n",
    "\n",
    "cfg = {\n",
    "    # Model Architecture\n",
    "    \"backbone\": \"mobilenet\",  # Options: \"custom_cnn\", \"mobilenet\", \"efficientnet\"\n",
    "    \n",
    "    # Image Parameters\n",
    "    \"picture_size\": 48,  # Try: 64, 96 for more detail\n",
    "    \"color_mode\": \"rgb\",  # \"grayscale\" or \"rgb\" (rgb required for transfer learning)\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch_size\": 32,  # Reduced from 128 for better gradient estimates\n",
    "    \"epochs\": 25,  # Increased from 30\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"dropout_rate\": 0.3,  # Increased from 0.25\n",
    "    \n",
    "    # CNN Architecture (for custom_cnn only)\n",
    "    \"cnn_layers\": [\n",
    "        {\"filters\": 64, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 128, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 256, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 512, \"kernel_size\": (3, 3)},\n",
    "        {\"filters\": 512, \"kernel_size\": (3, 3)},\n",
    "    ],\n",
    "    \n",
    "    # Dense layers\n",
    "    \"dense_units\": [256],\n",
    "    \n",
    "    # Data Augmentation (Improvement #2)\n",
    "    \"aug_level\": \"light\",  # Options: \"none\", \"light\", \"strong\", \"aggressive\"\n",
    "    \n",
    "    # Advanced Training\n",
    "    \"precision\": \"mixed\",  # \"float32\" or \"mixed\"\n",
    "    \"fine_tune\": False,  # Enable fine-tuning for transfer learning\n",
    "    \"fine_tune_epochs\": 0,\n",
    "    \n",
    "    # Optimizer\n",
    "    \"optimizer\": \"adam\",  # Options: \"adam\", \"adamw\", \"sgd\"\n",
    "    \"weight_decay\": 1e-4,  # For AdamW\n",
    "    \n",
    "    # Learning Rate Schedule\n",
    "    \"use_lr_schedule\": False,  # Cosine annealing (Improvement #5)\n",
    "    \n",
    "    # Class Weights (Improvement #3)\n",
    "    \"use_class_weights\": True,\n",
    "    \n",
    "    # Ensemble (Improvement #7)\n",
    "    \"use_ensemble\": False,  # Set True to train multiple models\n",
    "    \"n_ensemble_models\": 3,\n",
    "    \n",
    "    # Model Parameters\n",
    "    \"no_of_classes\": 7,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract commonly used values\n",
    "picture_size = cfg[\"picture_size\"]\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "epochs = cfg[\"epochs\"]\n",
    "learning_rate = cfg[\"learning_rate\"]\n",
    "no_of_classes = cfg[\"no_of_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Mixed Precision Training\n",
    "# =======================================================================\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "if cfg.get(\"precision\", \"float32\") == \"mixed\":\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"‚úÖ Mixed precision training enabled - expect 2-3x speedup!\")\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "    print(\"Using float32 precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365719a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Data Augmentation\n",
    "# =======================================================================\n",
    "\n",
    "aug_map = {\n",
    "    \"none\": dict(rescale=1./255),\n",
    "    \n",
    "    \"light\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True\n",
    "    ),\n",
    "    \n",
    "    \"strong\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    ),\n",
    "    \n",
    "    \"aggressive\": dict(\n",
    "        rescale=1./255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.25,\n",
    "        brightness_range=[0.6, 1.4],\n",
    "        horizontal_flip=True,\n",
    "        channel_shift_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create data generators\n",
    "datagen_train = ImageDataGenerator(**aug_map[cfg[\"aug_level\"]])\n",
    "datagen_validation = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(f\"‚úÖ Using '{cfg['aug_level']}' augmentation level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Load Training and Validation Data\n",
    "# =======================================================================\n",
    "\n",
    "# Determine color mode\n",
    "color_mode = cfg[\"color_mode\"]\n",
    "\n",
    "# Create training set\n",
    "train_set = datagen_train.flow_from_directory(\n",
    "    os.path.join(folder_path, \"train\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Create validation set\n",
    "validation_set = datagen_validation.flow_from_directory(\n",
    "    os.path.join(folder_path, \"validation\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "print(f\"Training samples: {train_set.n}\")\n",
    "print(f\"Validation samples: {validation_set.n}\")\n",
    "print(f\"Class indices: {train_set.class_indices}\")\n",
    "\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a196b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Calculate Class Weights for Imbalanced Data\n",
    "# =======================================================================\n",
    "\n",
    "class_weight_dict = None\n",
    "\n",
    "if cfg.get(\"use_class_weights\", False):\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_set.classes),\n",
    "        y=train_set.classes\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    print(\"\\n‚úÖ Class weights calculated:\")\n",
    "    for emotion, weight in zip(class_labels, class_weights):\n",
    "        print(f\"  {emotion:>10}: {weight:.3f}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Class weights disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa95eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Model Building Functions\n",
    "# =======================================================================\n",
    "\n",
    "def build_improved_cnn(cfg):\n",
    "    \"\"\"Enhanced CNN with better architecture.\"\"\"\n",
    "    \n",
    "    picture_size = cfg.get(\"picture_size\", 48)\n",
    "    no_of_classes = cfg.get(\"no_of_classes\", 7)\n",
    "    learning_rate = cfg.get(\"learning_rate\", 1e-4)\n",
    "    dropout_rate = cfg.get(\"dropout_rate\", 0.4)\n",
    "    \n",
    "    color_mode = cfg.get(\"color_mode\", \"grayscale\")\n",
    "    channels = 1 if color_mode == \"grayscale\" else 3\n",
    "    input_shape = (picture_size, picture_size, channels)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1 - Double Conv\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate * 0.5))\n",
    "    \n",
    "    # Block 2 - Double Conv\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate * 0.6))\n",
    "    \n",
    "    # Block 3 - Double Conv\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate * 0.7))\n",
    "    \n",
    "    # Block 4 - Double Conv\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense layers with progressive dropout\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate * 0.7))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(no_of_classes, activation='softmax', dtype='float32'))\n",
    "    \n",
    "    # Compile with optimizer choice\n",
    "    optimizer_name = cfg.get(\"optimizer\", \"adam\")\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        opt = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=cfg.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate,\n",
    "            momentum=0.9,\n",
    "            nesterov=True\n",
    "        )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, None\n",
    "\n",
    "\n",
    "def build_transfer_learning_model(cfg):\n",
    "    \"\"\"Transfer learning with MobileNetV2 or EfficientNetB0 (Improvement #1).\"\"\"\n",
    "    \n",
    "    picture_size = cfg.get(\"picture_size\", 48)\n",
    "    no_of_classes = cfg.get(\"no_of_classes\", 7)\n",
    "    learning_rate = cfg.get(\"learning_rate\", 1e-4)\n",
    "    \n",
    "    # Must use RGB for transfer learning\n",
    "    input_shape = (picture_size, picture_size, 3)\n",
    "    \n",
    "    # Choose backbone\n",
    "    backbone = cfg.get(\"backbone\", \"mobilenet\")\n",
    "    \n",
    "    if backbone == \"mobilenet\":\n",
    "        base_model = MobileNetV2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif backbone == \"efficientnet\":\n",
    "        base_model = EfficientNetB0(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(no_of_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "\n",
    "# Build model based on configuration\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Building model with '{cfg['backbone']}' backbone...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if cfg[\"backbone\"] in [\"mobilenet\", \"efficientnet\"]:\n",
    "    model, base_model = build_transfer_learning_model(cfg)\n",
    "else:\n",
    "    model, base_model = build_improved_cnn(cfg)\n",
    "\n",
    "print(f\"\\n‚úÖ Model built successfully\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e05a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Advanced Training Callbacks\n",
    "# =======================================================================\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping with more patience\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Increased from 5\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,  # Increased from 3\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Cosine annealing schedule (Improvement #5)\n",
    "def cosine_annealing(epoch, lr):\n",
    "    \"\"\"Cosine annealing learning rate schedule.\"\"\"\n",
    "    import math\n",
    "    epochs = cfg.get(\"epochs\", 50)\n",
    "    initial_lr = cfg.get(\"learning_rate\", 1e-4)\n",
    "    min_lr = 1e-7\n",
    "    \n",
    "    if epoch < 5:  # Warmup phase\n",
    "        return initial_lr * (epoch + 1) / 5\n",
    "    else:\n",
    "        progress = (epoch - 5) / (epochs - 5)\n",
    "        return min_lr + (initial_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "if cfg.get(\"use_lr_schedule\", False):\n",
    "    lr_scheduler = LearningRateScheduler(cosine_annealing, verbose=1)\n",
    "    callbacks_list.append(lr_scheduler)\n",
    "    print(\"‚úÖ Using cosine annealing learning rate schedule\")\n",
    "\n",
    "print(f\"‚úÖ Callbacks configured: {len(callbacks_list)} callbacks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Model Training\n",
    "# =======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Target: {epochs} epochs with early stopping\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Augmentation: {cfg['aug_level']}\")\n",
    "print(f\"Backbone: {cfg['backbone']}\")\n",
    "print(f\"Class weights: {'Enabled' if class_weight_dict else 'Disabled'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    steps_per_epoch=train_set.n // train_set.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=validation_set.n // validation_set.batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weight_dict,  # Improvement #3\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Initial training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Fine-Tuning Phase (for Transfer Learning)\n",
    "# =======================================================================\n",
    "\n",
    "if cfg.get(\"backbone\") in [\"mobilenet\", \"efficientnet\"] and cfg.get(\"fine_tune\", False):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîß STARTING FINE-TUNING PHASE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Unfreeze the last layers\n",
    "    base_model.trainable = True\n",
    "    fine_tune_at = len(base_model.layers) - 20  # Unfreeze last 20 layers\n",
    "    \n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    print(f\"Unfrozen layers: {sum([1 for layer in base_model.layers if layer.trainable])}\")\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate/10),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Fine-tune for additional epochs\n",
    "    fine_tune_epochs = cfg.get(\"fine_tune_epochs\", 15)\n",
    "    \n",
    "    history_fine = model.fit(\n",
    "        train_set,\n",
    "        validation_data=validation_set,\n",
    "        epochs=fine_tune_epochs,\n",
    "        callbacks=callbacks_list,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Merge histories\n",
    "    for key in history.history.keys():\n",
    "        history.history[key].extend(history_fine.history[key])\n",
    "    \n",
    "    print(\"‚úÖ Fine-tuning completed!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Skipping fine-tuning (only for transfer learning models)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Training History Visualization\n",
    "# =======================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "train_loss, train_acc = model.evaluate(train_set, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(validation_set, verbose=0)\n",
    "\n",
    "print(f\"Training Accuracy:   {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"Training Loss:       {train_loss:.4f}\")\n",
    "print(f\"Validation Loss:     {val_loss:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692049e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Detailed Performance Analysis\n",
    "# =======================================================================\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load best model\n",
    "my_model = load_model('best_model.keras', compile=False)\n",
    "\n",
    "# Get predictions\n",
    "print(\"Generating predictions on validation set...\")\n",
    "validation_set.reset()\n",
    "predictions = my_model.predict(validation_set, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = validation_set.classes\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "print(f\"\\n‚úÖ Best Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be851daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Enhanced Performance Visualizations\n",
    "# =======================================================================\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray')\n",
    "plt.title('Confusion Matrix - Emotion Recognition', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Normalized Confusion Matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Percentage'})\n",
    "plt.title('Normalized Confusion Matrix (%)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Emotion', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà DETAILED CLASSIFICATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                           target_names=class_labels,\n",
    "                           digits=4))\n",
    "\n",
    "# 4. Per-Class Metrics Bar Chart\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    true_classes, predicted_classes, labels=range(7)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = np.arange(len(class_labels))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, precision, width, label='Precision', color='#3498db')\n",
    "bars2 = ax.bar(x, recall, width, label='Recall', color='#2ecc71')\n",
    "bars3 = ax.bar(x + width, f1, width, label='F1-Score', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Emotion', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Per-Emotion Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Summary Table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Emotion': class_labels,\n",
    "    'Precision': [f'{p:.2%}' for p in precision],\n",
    "    'Recall': [f'{r:.2%}' for r in recall],\n",
    "    'F1-Score': [f'{f:.2%}' for f in f1],\n",
    "    'Support': support.astype(int)\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä PERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 6. Misclassification Analysis\n",
    "misclassified = cm.copy()\n",
    "np.fill_diagonal(misclassified, 0)\n",
    "\n",
    "top_confusions = []\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        if i != j:\n",
    "            top_confusions.append((class_labels[i], class_labels[j], misclassified[i, j]))\n",
    "\n",
    "top_confusions.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ö†Ô∏è  TOP 5 MISCLASSIFICATION PAIRS\")\n",
    "print(\"=\"*70)\n",
    "for true_label, pred_label, count in top_confusions[:5]:\n",
    "    print(f\"{true_label:>10} ‚Üí {pred_label:<10} : {count:>4} times\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ce84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Save Model with Timestamp\n",
    "# =======================================================================\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"emotion_recognition_{timestamp}.keras\"\n",
    "\n",
    "if is_on_kaggle():\n",
    "    output_path = \"/kaggle/working/\"\n",
    "else:\n",
    "    output_path = \".\"\n",
    "\n",
    "full_path = Path(output_path) / model_name\n",
    "model.save(str(full_path))\n",
    "\n",
    "print(f\"\\nüíæ Model saved: {full_path}\")\n",
    "print(f\"üìä Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Ensemble Training (Optional)\n",
    "# =======================================================================\n",
    "\n",
    "if cfg.get(\"use_ensemble\", False):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéØ TRAINING ENSEMBLE MODELS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    n_models = cfg.get(\"n_ensemble_models\", 3)\n",
    "    ensemble_models = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Training Ensemble Model {i+1}/{n_models}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Vary hyperparameters slightly\n",
    "        cfg_copy = cfg.copy()\n",
    "        cfg_copy[\"learning_rate\"] = cfg[\"learning_rate\"] * (0.8 + 0.4 * np.random.random())\n",
    "        cfg_copy[\"dropout_rate\"] = 0.3 + 0.2 * np.random.random()\n",
    "        \n",
    "        # Build model\n",
    "        if cfg[\"backbone\"] in [\"mobilenet\", \"efficientnet\"]:\n",
    "            ensemble_model, _ = build_transfer_learning_model(cfg_copy)\n",
    "        else:\n",
    "            ensemble_model, _ = build_improved_cnn(cfg_copy)\n",
    "        \n",
    "        # Train\n",
    "        history_ens = ensemble_model.fit(\n",
    "            train_set,\n",
    "            validation_data=validation_set,\n",
    "            epochs=30,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        ensemble_models.append(ensemble_model)\n",
    "        \n",
    "        # Save\n",
    "        ensemble_model.save(f\"ensemble_model_{i+1}.keras\")\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéØ ENSEMBLE PREDICTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    validation_set.reset()\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for i, ens_model in enumerate(ensemble_models):\n",
    "        print(f\"Getting predictions from model {i+1}...\")\n",
    "        pred = ens_model.predict(validation_set, verbose=0)\n",
    "        ensemble_predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    avg_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "    ensemble_predicted_classes = np.argmax(avg_predictions, axis=1)\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    ensemble_accuracy = np.mean(ensemble_predicted_classes == true_classes)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Ensemble Accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
    "    print(f\"üìà Improvement over single model: {(ensemble_accuracy - accuracy)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Ensemble training disabled (set 'use_ensemble': True to enable)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
