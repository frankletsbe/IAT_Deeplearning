{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc5c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.1\n",
      "Python executable: c:\\Users\\marty\\anaconda3\\envs\\tf311_env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Facial Emotion Recognition Model - Optimized for Snapdragon X Elite\n",
    "# =======================================================================\n",
    "# Configuration: MOBILENET with optimized hyperparameters\n",
    "# Target: <1 hour training time with maximum accuracy\n",
    "\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Import TensorFlow and configure for optimal performance\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Import deep learning libraries\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Flatten, Dropout, Dense, Input, \n",
    "                                     GlobalAveragePooling2D, Conv2D, \n",
    "                                     BatchNormalization, Activation, MaxPooling2D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043d2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder path: data/images/\n"
     ]
    }
   ],
   "source": [
    "# Auto-detect folder path\n",
    "if sys.executable.startswith('/anaconda/envs/azureml_py38_PT_TF/bin/python'):\n",
    "    folder_path = \"Users/martyn.frank/IATD_Deeplearning/Project/data/images/\"\n",
    "else:\n",
    "    folder_path = 'data/images/'\n",
    "    \n",
    "print(f\"Data folder path: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f69506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision training enabled - expect 2-3x speedup!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Configuration Parameters\n",
    "# =======================================================================\n",
    "\n",
    "\n",
    "import yaml\n",
    "\n",
    "def load_cfg(path=\"config.yaml\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data\n",
    "\n",
    "cfg = load_cfg(\"config.yaml\")\n",
    "\n",
    "# optionally, map top-level training params from cfg\n",
    "picture_size   = cfg.get(\"picture_size\", 48)\n",
    "batch_size     = cfg.get(\"batch_size\", 128)\n",
    "epochs         = cfg.get(\"epochs\", 30)\n",
    "no_of_classes  = cfg.get(\"no_of_classes\", 7)\n",
    "learning_rate  = cfg.get(\"learning_rate\", 1e-4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Enable mixed precision for faster training on Snapdragon X Elite\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Precision Swicth\n",
    "if cfg[\"precision\"] == \"mixed\":\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "print(\"Mixed precision training enabled - expect 2-3x speedup!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fe93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Image Validation and Cleaning\n",
    "# =======================================================================\n",
    "\n",
    "def is_image_valid(filepath):\n",
    "    \"\"\"Validate image integrity.\"\"\"\n",
    "    try:\n",
    "        with Image.open(filepath) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except (UnidentifiedImageError, OSError):\n",
    "        return False\n",
    "\n",
    "def delete_if_corrupt(filepath):\n",
    "    \"\"\"Delete corrupted images.\"\"\"\n",
    "    try:\n",
    "        with Image.open(filepath) as img:\n",
    "            img.verify()\n",
    "        return False\n",
    "    except (UnidentifiedImageError, OSError):\n",
    "        print(f\"Deleting corrupted image: {filepath}\")\n",
    "        os.remove(filepath)\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2933bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Advanced Image Preprocessing\n",
    "# =======================================================================\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Apply histogram equalization for better feature extraction.\n",
    "    Improves contrast and enhances facial features.\n",
    "    \"\"\"\n",
    "    # Convert to uint8 if needed\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    if len(image.shape) == 2:  # Grayscale\n",
    "        enhanced = clahe.apply(image)\n",
    "    else:  # If RGB, convert to grayscale first\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    return enhanced.astype(np.float32) / 255.0\n",
    "\n",
    "class PreprocessingImageDataGenerator(ImageDataGenerator):\n",
    "    \"\"\"Custom generator with advanced preprocessing.\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, preprocessing_function=None, **kwargs):\n",
    "        super().__init__(*args, preprocessing_function=preprocessing_function, **kwargs)\n",
    "    \n",
    "    def standardize(self, x):\n",
    "        x = super().standardize(x)\n",
    "        # Apply additional preprocessing\n",
    "        return preprocess_image(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338d51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10019.jpg', '10023.jpg', '10074.jpg', '10096.jpg', '10106.jpg', '10126.jpg', '10138.jpg', '10141.jpg', '1020.jpg', '10218.jpg', '10237.jpg', '10248.jpg', '10257.jpg', '1027.jpg', '10273.jpg', '10276.jpg', '10312.jpg', '10317.jpg', '10344.jpg', '10362.jpg', '10367.jpg', '10370.jpg', '10432.jpg', '10456.jpg', '10467.jpg', '10468.jpg', '10480.jpg', '10528.jpg', '10540.jpg', '10552.jpg', '1056.jpg', '10571.jpg', '1058.jpg', '10622.jpg', '10638.jpg', '10640.jpg', '10644.jpg', '10647.jpg', '10683.jpg', '10703.jpg', '1074.jpg', '10770.jpg', '10773.jpg', '10792.jpg', '1081.jpg', '10811.jpg', '10841.jpg', '10879.jpg', '10903.jpg', '10935.jpg', '10956.jpg', '10992.jpg', '11019.jpg', '1111.jpg', '11150.jpg', '11208.jpg', '1121.jpg', '11236.jpg', '1130.jpg', '11345.jpg', '11349.jpg', '11392.jpg', '1141.jpg', '11500.jpg', '11508.jpg', '11516.jpg', '1152.jpg', '11530.jpg', '11549.jpg', '11552.jpg', '11558.jpg', '11573.jpg', '11575.jpg', '11588.jpg', '1159.jpg', '11594.jpg', '11604.jpg', '11614.jpg', '11637.jpg', '11646.jpg', '11658.jpg', '11717.jpg', '11733.jpg', '11763.jpg', '11766.jpg', '11772.jpg', '11785.jpg', '11793.jpg', '11808.jpg', '11814.jpg', '11819.jpg', '11835.jpg', '11842.jpg', '11850.jpg', '11885.jpg', '11927.jpg', '12011.jpg', '1202.jpg', '12024.jpg', '12098.jpg', '12120.jpg', '12129.jpg', '12141.jpg', '12191.jpg', '12239.jpg', '12257.jpg', '12284.jpg', '12321.jpg', '12329.jpg', '12349.jpg', '12359.jpg', '12376.jpg', '12379.jpg', '12381.jpg', '12410.jpg', '1246.jpg', '12487.jpg', '12492.jpg', '12497.jpg', '12557.jpg', '12560.jpg', '12581.jpg', '12600.jpg', '12611.jpg', '12672.jpg', '12705.jpg', '12725.jpg', '12729.jpg', '12772.jpg', '12776.jpg', '12789.jpg', '12861.jpg', '12904.jpg', '12936.jpg', '12951.jpg', '12956.jpg', '12957.jpg', '13037.jpg', '13073.jpg', '1309.jpg', '13105.jpg', '13108.jpg', '13127.jpg', '13139.jpg', '13151.jpg', '1316.jpg', '13204.jpg', '13228.jpg', '13283.jpg', '13317.jpg', '13322.jpg', '1334.jpg', '13348.jpg', '13353.jpg', '13363.jpg', '13366.jpg', '13385.jpg', '1341.jpg', '13427.jpg', '13428.jpg', '13449.jpg', '13456.jpg', '13476.jpg', '13502.jpg', '13526.jpg', '13528.jpg', '13570.jpg', '13584.jpg', '13590.jpg', '13615.jpg', '13618.jpg', '13655.jpg', '13703.jpg', '13706.jpg', '13715.jpg', '13757.jpg', '13761.jpg', '13792.jpg', '13802.jpg', '1381.jpg', '13833.jpg', '13848.jpg', '13874.jpg', '13877.jpg', '139.jpg', '13911.jpg', '13912.jpg', '13925.jpg', '1395.jpg', '13955.jpg', '13968.jpg', '13969.jpg', '13991.jpg', '14063.jpg', '14092.jpg', '141.jpg', '14139.jpg', '14152.jpg', '14155.jpg', '14169.jpg', '14236.jpg', '14278.jpg', '14282.jpg', '14292.jpg', '14310.jpg', '14314.jpg', '14327.jpg', '14348.jpg', '14360.jpg', '14371.jpg', '14378.jpg', '14419.jpg', '14427.jpg', '14448.jpg', '14473.jpg', '14475.jpg', '14516.jpg', '14517.jpg', '14518.jpg', '14546.jpg', '14586.jpg', '14593.jpg', '14611.jpg', '14700.jpg', '14730.jpg', '14757.jpg', '14759.jpg', '14792.jpg', '14877.jpg', '1491.jpg', '14965.jpg', '14973.jpg', '15039.jpg', '15060.jpg', '15077.jpg', '15099.jpg', '1512.jpg', '15147.jpg', '15181.jpg', '15212.jpg', '15216.jpg', '15221.jpg', '15229.jpg', '15257.jpg', '15269.jpg', '15271.jpg', '15292.jpg', '15310.jpg', '15323.jpg', '15331.jpg', '15335.jpg', '1538.jpg', '15397.jpg', '15400.jpg', '15409.jpg', '15426.jpg', '15432.jpg', '15438.jpg', '15443.jpg', '15455.jpg', '15494.jpg', '15520.jpg', '15523.jpg', '15589.jpg', '15616.jpg', '15621.jpg', '15677.jpg', '15708.jpg', '15758.jpg', '15767.jpg', '15791.jpg', '15843.jpg', '15854.jpg', '15885.jpg', '15910.jpg', '15966.jpg', '15976.jpg', '15983.jpg', '16037.jpg', '16042.jpg', '16064.jpg', '16076.jpg', '16081.jpg', '16106.jpg', '16108.jpg', '16120.jpg', '16141.jpg', '16192.jpg', '16198.jpg', '16238.jpg', '16275.jpg', '1628.jpg', '16308.jpg', '16370.jpg', '16375.jpg', '1640.jpg', '16407.jpg', '16423.jpg', '16444.jpg', '16460.jpg', '16511.jpg', '16550.jpg', '16562.jpg', '16583.jpg', '16588.jpg', '16596.jpg', '16604.jpg', '16611.jpg', '16619.jpg', '16633.jpg', '16649.jpg', '16667.jpg', '16699.jpg', '167.jpg', '1670.jpg', '16700.jpg', '16712.jpg', '16734.jpg', '16738.jpg', '16751.jpg', '16752.jpg', '16759.jpg', '16770.jpg', '16795.jpg', '16799.jpg', '16809.jpg', '16818.jpg', '16952.jpg', '16967.jpg', '16971.jpg', '1699.jpg', '17002.jpg', '17007.jpg', '17010.jpg', '17021.jpg', '17022.jpg', '17032.jpg', '1704.jpg', '17041.jpg', '1707.jpg', '17098.jpg', '17104.jpg', '17117.jpg', '17188.jpg', '17194.jpg', '17207.jpg', '17220.jpg', '17319.jpg', '17367.jpg', '17381.jpg', '17397.jpg', '17402.jpg', '17447.jpg', '17462.jpg', '17470.jpg', '17484.jpg', '17485.jpg', '17494.jpg', '17498.jpg', '17506.jpg', '17524.jpg', '17541.jpg', '17543.jpg', '17552.jpg', '17609.jpg', '17624.jpg', '17654.jpg', '1768.jpg', '17682.jpg', '17684.jpg', '17692.jpg', '17694.jpg', '17698.jpg', '1770.jpg', '17715.jpg', '17772.jpg', '17799.jpg', '17802.jpg', '17821.jpg', '1787.jpg', '17904.jpg', '1793.jpg', '17936.jpg', '18016.jpg', '18018.jpg', '18025.jpg', '18033.jpg', '18037.jpg', '18080.jpg', '18082.jpg', '1815.jpg', '18165.jpg', '18173.jpg', '18205.jpg', '18226.jpg', '18237.jpg', '18245.jpg', '18249.jpg', '18250.jpg', '18256.jpg', '18259.jpg', '18297.jpg', '18308.jpg', '18383.jpg', '18405.jpg', '18424.jpg', '18425.jpg', '18442.jpg', '18443.jpg', '18471.jpg', '18476.jpg', '18483.jpg', '18487.jpg', '18503.jpg', '18505.jpg', '18531.jpg', '18541.jpg', '18556.jpg', '18568.jpg', '18578.jpg', '18655.jpg', '18662.jpg', '1869.jpg', '187.jpg', '18700.jpg', '18729.jpg', '18783.jpg', '18822.jpg', '18827.jpg', '18834.jpg', '18835.jpg', '18849.jpg', '18861.jpg', '1887.jpg', '18873.jpg', '18885.jpg', '18898.jpg', '18904.jpg', '18930.jpg', '18944.jpg', '18948.jpg', '18952.jpg', '19008.jpg', '19012.jpg', '19025.jpg', '19056.jpg', '19062.jpg', '19063.jpg', '19074.jpg', '19105.jpg', '19127.jpg', '19130.jpg', '19132.jpg', '19137.jpg', '19148.jpg', '19160.jpg', '19162.jpg', '1919.jpg', '192.jpg', '1920.jpg', '19210.jpg', '19245.jpg', '19263.jpg', '19269.jpg', '19284.jpg', '19291.jpg', '19317.jpg', '19318.jpg', '19323.jpg', '19346.jpg', '19357.jpg', '19370.jpg', '19377.jpg', '19378.jpg', '1938.jpg', '19398.jpg', '19402.jpg', '19438.jpg', '19449.jpg', '19478.jpg', '19492.jpg', '19496.jpg', '19499.jpg', '19514.jpg', '1953.jpg', '19536.jpg', '19548.jpg', '19568.jpg', '19589.jpg', '19597.jpg', '196.jpg', '19600.jpg', '19605.jpg', '19668.jpg', '19680.jpg', '19696.jpg', '19700.jpg', '19709.jpg', '19711.jpg', '1974.jpg', '19744.jpg', '19747.jpg', '19748.jpg', '19768.jpg', '19803.jpg', '19837.jpg', '19883.jpg', '19889.jpg', '19918.jpg', '19957.jpg', '19958.jpg', '19962.jpg', '19968.jpg', '2001.jpg', '20023.jpg', '20025.jpg', '20032.jpg', '20039.jpg', '20048.jpg', '20091.jpg', '20111.jpg', '2012.jpg', '20120.jpg', '20122.jpg', '20140.jpg', '20155.jpg', '20165.jpg', '20181.jpg', '20196.jpg', '20208.jpg', '20213.jpg', '20216.jpg', '20218.jpg', '20229.jpg', '20239.jpg', '20252.jpg', '20267.jpg', '20285.jpg', '20296.jpg', '20318.jpg', '20355.jpg', '20365.jpg', '20371.jpg', '20377.jpg', '20412.jpg', '20430.jpg', '20445.jpg', '20490.jpg', '20500.jpg', '20507.jpg', '20519.jpg', '20547.jpg', '20561.jpg', '20567.jpg', '2058.jpg', '20580.jpg', '20595.jpg', '20616.jpg', '2064.jpg', '20666.jpg', '20675.jpg', '20684.jpg', '20685.jpg', '2069.jpg', '20745.jpg', '20821.jpg', '20829.jpg', '20850.jpg', '20857.jpg', '20865.jpg', '20866.jpg', '20889.jpg', '20918.jpg', '20941.jpg', '20945.jpg', '20949.jpg', '20958.jpg', '20972.jpg', '20984.jpg', '20988.jpg', '20994.jpg', '210.jpg', '21006.jpg', '21027.jpg', '21033.jpg', '21077.jpg', '21097.jpg', '21098.jpg', '21120.jpg', '21143.jpg', '21177.jpg', '21185.jpg', '2120.jpg', '21200.jpg', '2122.jpg', '21235.jpg', '21292.jpg', '213.jpg', '21305.jpg', '21316.jpg', '21348.jpg', '2135.jpg', '2137.jpg', '21376.jpg', '21384.jpg', '21394.jpg', '21439.jpg', '21441.jpg', '21460.jpg', '21473.jpg', '21483.jpg', '21501.jpg', '2152.jpg', '21524.jpg', '21538.jpg', '21574.jpg', '2159.jpg', '21593.jpg', '21602.jpg', '21605.jpg', '21618.jpg', '21699.jpg', '21708.jpg', '21750.jpg', '21778.jpg', '21783.jpg', '21787.jpg', '2182.jpg', '21825.jpg', '21835.jpg', '2184.jpg', '21846.jpg', '21876.jpg', '21899.jpg', '21927.jpg', '21942.jpg', '21943.jpg', '21961.jpg', '21990.jpg', '2204.jpg', '22056.jpg', '22064.jpg', '22080.jpg', '22097.jpg', '22111.jpg', '22138.jpg', '22140.jpg', '22150.jpg', '22154.jpg', '22178.jpg', '22179.jpg', '22191.jpg', '22194.jpg', '22201.jpg', '22247.jpg', '22289.jpg', '22290.jpg', '22301.jpg', '2231.jpg', '22340.jpg', '22346.jpg', '22347.jpg', '22351.jpg', '22380.jpg', '22388.jpg', '22395.jpg', '22424.jpg', '22459.jpg', '22466.jpg', '22506.jpg', '22532.jpg', '22545.jpg', '22560.jpg', '22574.jpg', '22600.jpg', '22604.jpg', '22612.jpg', '22614.jpg', '22671.jpg', '22679.jpg', '22711.jpg', '22750.jpg', '22754.jpg', '22763.jpg', '22778.jpg', '22784.jpg', '22804.jpg', '22805.jpg', '2282.jpg', '22834.jpg', '2284.jpg', '22863.jpg', '2287.jpg', '22894.jpg', '22900.jpg', '22910.jpg', '2293.jpg', '22935.jpg', '22991.jpg', '23028.jpg', '2305.jpg', '2307.jpg', '2308.jpg', '23096.jpg', '23101.jpg', '23114.jpg', '23122.jpg', '23170.jpg', '23238.jpg', '2324.jpg', '2327.jpg', '23293.jpg', '23319.jpg', '23320.jpg', '23321.jpg', '23334.jpg', '23377.jpg', '23380.jpg', '23381.jpg', '23419.jpg', '23440.jpg', '23453.jpg', '23462.jpg', '2350.jpg', '23501.jpg', '23525.jpg', '23555.jpg', '23559.jpg', '23572.jpg', '23590.jpg', '23612.jpg', '23621.jpg', '23664.jpg', '23667.jpg', '2374.jpg', '2377.jpg', '23770.jpg', '23786.jpg', '23801.jpg', '23813.jpg', '23848.jpg', '23862.jpg', '23865.jpg', '23866.jpg', '23891.jpg', '23897.jpg', '23920.jpg', '23933.jpg', '23946.jpg', '24027.jpg', '2403.jpg', '24054.jpg', '24055.jpg', '24077.jpg', '24079.jpg', '24099.jpg', '2411.jpg', '24123.jpg', '24137.jpg', '24148.jpg', '24161.jpg', '24189.jpg', '24200.jpg', '2421.jpg', '24211.jpg', '24219.jpg', '24224.jpg', '2424.jpg', '24241.jpg', '24259.jpg', '24263.jpg', '24286.jpg', '24289.jpg', '24292.jpg', '24297.jpg', '24299.jpg', '24340.jpg', '24354.jpg', '24355.jpg', '2436.jpg', '24360.jpg', '24380.jpg', '24390.jpg', '24391.jpg', '24393.jpg', '24395.jpg', '24410.jpg', '24465.jpg', '24492.jpg', '2450.jpg', '24509.jpg', '24521.jpg', '24530.jpg', '24535.jpg', '24536.jpg', '24570.jpg', '24607.jpg', '24633.jpg', '24652.jpg', '24656.jpg', '24680.jpg', '24692.jpg', '24699.jpg', '247.jpg', '24718.jpg', '2472.jpg', '24731.jpg', '24747.jpg', '24764.jpg', '24769.jpg', '24777.jpg', '24783.jpg', '24823.jpg', '2483.jpg', '24845.jpg', '24884.jpg', '24906.jpg', '24910.jpg', '2492.jpg', '24942.jpg', '24946.jpg', '25006.jpg', '25017.jpg', '25028.jpg', '25037.jpg', '25039.jpg', '25048.jpg', '25058.jpg', '25123.jpg', '25163.jpg', '25180.jpg', '25186.jpg', '25199.jpg', '25223.jpg', '25271.jpg', '25275.jpg', '25287.jpg', '25322.jpg', '25328.jpg', '25337.jpg', '25342.jpg', '25383.jpg', '25396.jpg', '25414.jpg', '25420.jpg', '25431.jpg', '25438.jpg', '25443.jpg', '25454.jpg', '25472.jpg', '25517.jpg', '25533.jpg', '2554.jpg', '2556.jpg', '25578.jpg', '2559.jpg', '25602.jpg', '25604.jpg', '25649.jpg', '25652.jpg', '25658.jpg', '25686.jpg', '25705.jpg', '25714.jpg', '25719.jpg', '25720.jpg', '25744.jpg', '25747.jpg', '25759.jpg', '25775.jpg', '25809.jpg', '25839.jpg', '25887.jpg', '25902.jpg', '25927.jpg', '25937.jpg', '25949.jpg', '25993.jpg', '26018.jpg', '2603.jpg', '26032.jpg', '26034.jpg', '26046.jpg', '26077.jpg', '26098.jpg', '26107.jpg', '2611.jpg', '26159.jpg', '26160.jpg', '26169.jpg', '2620.jpg', '26212.jpg', '26224.jpg', '2629.jpg', '26338.jpg', '26370.jpg', '26397.jpg', '2640.jpg', '26456.jpg', '26459.jpg', '26468.jpg', '26477.jpg', '2649.jpg', '26511.jpg', '2655.jpg', '26563.jpg', '26578.jpg', '26660.jpg', '26665.jpg', '26667.jpg', '26676.jpg', '26703.jpg', '26720.jpg', '26736.jpg', '26775.jpg', '2678.jpg', '26819.jpg', '26840.jpg', '26850.jpg', '26873.jpg', '26888.jpg', '26891.jpg', '26906.jpg', '26909.jpg', '26913.jpg', '26935.jpg', '26960.jpg', '26963.jpg', '26967.jpg', '26978.jpg', '26981.jpg', '27048.jpg', '27051.jpg', '27105.jpg', '27106.jpg', '27128.jpg', '27140.jpg', '27152.jpg', '27162.jpg', '27172.jpg', '27187.jpg', '27196.jpg', '27197.jpg', '27204.jpg', '27212.jpg', '27227.jpg', '27246.jpg', '27277.jpg', '27294.jpg', '2730.jpg', '27326.jpg', '27333.jpg', '27334.jpg', '27365.jpg', '27367.jpg', '27404.jpg', '27407.jpg', '27426.jpg', '27446.jpg', '2745.jpg', '27452.jpg', '27474.jpg', '27508.jpg', '2754.jpg', '27554.jpg', '27563.jpg', '27575.jpg', '27616.jpg', '27619.jpg', '27625.jpg', '27636.jpg', '27645.jpg', '27647.jpg', '27648.jpg', '27662.jpg', '27671.jpg', '27675.jpg', '27701.jpg', '2771.jpg', '2774.jpg', '27779.jpg', '27823.jpg', '27854.jpg', '2790.jpg', '27928.jpg', '27931.jpg', '27932.jpg', '27940.jpg', '27944.jpg', '27949.jpg', '2796.jpg', '28040.jpg', '28046.jpg', '2805.jpg', '2806.jpg', '2810.jpg', '28105.jpg', '28108.jpg', '28115.jpg', '28138.jpg', '28140.jpg', '2816.jpg', '2820.jpg', '28249.jpg', '28256.jpg', '28264.jpg', '28273.jpg', '28282.jpg', '28367.jpg', '28376.jpg', '28379.jpg', '28383.jpg', '28415.jpg', '28474.jpg', '28502.jpg', '28522.jpg', '28529.jpg', '2857.jpg', '28581.jpg', '28590.jpg', '28594.jpg', '28600.jpg', '2861.jpg', '28632.jpg', '2867.jpg', '28676.jpg', '28688.jpg', '28772.jpg', '28797.jpg', '28807.jpg', '28814.jpg', '2885.jpg', '28871.jpg', '28897.jpg', '28928.jpg', '28934.jpg', '28938.jpg', '28949.jpg', '28954.jpg', '28955.jpg', '28962.jpg', '28963.jpg', '28982.jpg', '29003.jpg', '29019.jpg', '29020.jpg', '29067.jpg', '29071.jpg', '29074.jpg', '29111.jpg', '29123.jpg', '2913.jpg', '29185.jpg', '29211.jpg', '29214.jpg', '29248.jpg', '29258.jpg', '29290.jpg', '2930.jpg', '29300.jpg', '29329.jpg', '29365.jpg', '29370.jpg', '2938.jpg', '29398.jpg', '29415.jpg', '29423.jpg', '29456.jpg', '29460.jpg', '29464.jpg', '29467.jpg', '29475.jpg', '2948.jpg', '29504.jpg', '29555.jpg', '29578.jpg', '29589.jpg', '29645.jpg', '29647.jpg', '29648.jpg', '29649.jpg', '2965.jpg', '29680.jpg', '29697.jpg', '29699.jpg', '29707.jpg', '29724.jpg', '29766.jpg', '29769.jpg', '29773.jpg', '29821.jpg', '29834.jpg', '29844.jpg', '2985.jpg', '29889.jpg', '29919.jpg', '29979.jpg', '29981.jpg', '29987.jpg', '29991.jpg', '30.jpg', '30006.jpg', '30016.jpg', '30069.jpg', '30099.jpg', '3010.jpg', '30102.jpg', '30114.jpg', '30119.jpg', '30127.jpg', '30143.jpg', '3016.jpg', '30164.jpg', '30188.jpg', '30193.jpg', '30216.jpg', '3022.jpg', '30221.jpg', '3024.jpg', '30241.jpg', '30245.jpg', '3029.jpg', '30297.jpg', '30328.jpg', '30332.jpg', '30337.jpg', '30338.jpg', '30341.jpg', '30400.jpg', '30407.jpg', '30424.jpg', '30478.jpg', '30585.jpg', '30646.jpg', '30651.jpg', '30652.jpg', '30661.jpg', '30675.jpg', '30683.jpg', '30689.jpg', '3069.jpg', '30704.jpg', '30728.jpg', '30737.jpg', '30738.jpg', '30749.jpg', '3077.jpg', '30772.jpg', '30779.jpg', '30793.jpg', '30808.jpg', '30820.jpg', '30822.jpg', '30823.jpg', '30825.jpg', '3083.jpg', '30830.jpg', '30835.jpg', '30851.jpg', '30855.jpg', '30856.jpg', '3086.jpg', '30871.jpg', '30893.jpg', '30909.jpg', '30948.jpg', '30951.jpg', '30961.jpg', '30962.jpg', '30965.jpg', '30981.jpg', '31010.jpg', '31029.jpg', '31043.jpg', '31056.jpg', '3106.jpg', '31080.jpg', '31101.jpg', '31112.jpg', '31137.jpg', '31140.jpg', '31141.jpg', '31145.jpg', '3117.jpg', '3120.jpg', '31209.jpg', '31239.jpg', '31285.jpg', '31295.jpg', '3131.jpg', '31316.jpg', '3132.jpg', '31366.jpg', '3138.jpg', '31384.jpg', '3144.jpg', '31440.jpg', '3146.jpg', '31542.jpg', '31551.jpg', '31571.jpg', '31572.jpg', '3162.jpg', '31627.jpg', '31629.jpg', '31659.jpg', '31697.jpg', '31742.jpg', '31752.jpg', '31806.jpg', '31811.jpg', '3182.jpg', '31833.jpg', '31853.jpg', '31858.jpg', '31870.jpg', '31897.jpg', '31908.jpg', '31929.jpg', '31952.jpg', '31977.jpg', '31987.jpg', '32046.jpg', '32047.jpg', '32048.jpg', '32051.jpg', '3209.jpg', '32142.jpg', '32144.jpg', '3215.jpg', '32177.jpg', '32248.jpg', '32344.jpg', '32354.jpg', '32372.jpg', '32377.jpg', '32382.jpg', '32388.jpg', '32402.jpg', '32439.jpg', '3245.jpg', '325.jpg', '3250.jpg', '32541.jpg', '32544.jpg', '32568.jpg', '32570.jpg', '32574.jpg', '32595.jpg', '3260.jpg', '32607.jpg', '32614.jpg', '32624.jpg', '32627.jpg', '32684.jpg', '32725.jpg', '32763.jpg', '32769.jpg', '32773.jpg', '3278.jpg', '32796.jpg', '32826.jpg', '32835.jpg', '32837.jpg', '32838.jpg', '32849.jpg', '32913.jpg', '32917.jpg', '32950.jpg', '32952.jpg', '32953.jpg', '32958.jpg', '32973.jpg', '32993.jpg', '32997.jpg', '32998.jpg', '33016.jpg', '33017.jpg', '33024.jpg', '33046.jpg', '33065.jpg', '33066.jpg', '33071.jpg', '33084.jpg', '33091.jpg', '33094.jpg', '331.jpg', '3313.jpg', '33144.jpg', '33174.jpg', '33175.jpg', '3318.jpg', '33188.jpg', '33212.jpg', '33216.jpg', '33228.jpg', '33231.jpg', '33240.jpg', '33268.jpg', '33283.jpg', '333.jpg', '33319.jpg', '33320.jpg', '33322.jpg', '33326.jpg', '33343.jpg', '33357.jpg', '33366.jpg', '33375.jpg', '33407.jpg', '33423.jpg', '33455.jpg', '33460.jpg', '33463.jpg', '33518.jpg', '33525.jpg', '33530.jpg', '33533.jpg', '33544.jpg', '33564.jpg', '33610.jpg', '33648.jpg', '33660.jpg', '33675.jpg', '33690.jpg', '33727.jpg', '33757.jpg', '33762.jpg', '33802.jpg', '33807.jpg', '33842.jpg', '33853.jpg', '33874.jpg', '33915.jpg', '33917.jpg', '33933.jpg', '33938.jpg', '33981.jpg', '34015.jpg', '34049.jpg', '34057.jpg', '34098.jpg', '3410.jpg', '34102.jpg', '3411.jpg', '34119.jpg', '34129.jpg', '3414.jpg', '34170.jpg', '34219.jpg', '3422.jpg', '34226.jpg', '34234.jpg', '34244.jpg', '34257.jpg', '34295.jpg', '34302.jpg', '3431.jpg', '34316.jpg', '34361.jpg', '34375.jpg', '34386.jpg', '34397.jpg', '34412.jpg', '34435.jpg', '34437.jpg', '34464.jpg', '34468.jpg', '3447.jpg', '34471.jpg', '34483.jpg', '34498.jpg', '34510.jpg', '3452.jpg', '34567.jpg', '34569.jpg', '34585.jpg', '34599.jpg', '34600.jpg', '34644.jpg', '34645.jpg', '34649.jpg', '3465.jpg', '34688.jpg', '34720.jpg', '34724.jpg', '34737.jpg', '34753.jpg', '34756.jpg', '34759.jpg', '34761.jpg', '34768.jpg', '34772.jpg', '34829.jpg', '34836.jpg', '34840.jpg', '34841.jpg', '34861.jpg', '34941.jpg', '34965.jpg', '34969.jpg', '34978.jpg', '35101.jpg', '35117.jpg', '35142.jpg', '35153.jpg', '35163.jpg', '35177.jpg', '35199.jpg', '35200.jpg', '35209.jpg', '35226.jpg', '35291.jpg', '35321.jpg', '35341.jpg', '35346.jpg', '35364.jpg', '35369.jpg', '35370.jpg', '35372.jpg', '3538.jpg', '3543.jpg', '35454.jpg', '35481.jpg', '35497.jpg', '35520.jpg', '35536.jpg', '35547.jpg', '35552.jpg', '35559.jpg', '35582.jpg', '35598.jpg', '356.jpg', '35603.jpg', '35659.jpg', '35664.jpg', '35677.jpg', '35685.jpg', '35698.jpg', '3570.jpg', '35707.jpg', '35721.jpg', '35724.jpg', '3574.jpg', '35767.jpg', '35771.jpg', '35787.jpg', '35792.jpg', '35794.jpg', '35804.jpg', '35850.jpg', '35856.jpg', '35860.jpg', '35869.jpg', '3590.jpg', '3647.jpg', '366.jpg', '3662.jpg', '3663.jpg', '370.jpg', '3755.jpg', '3763.jpg', '3766.jpg', '3772.jpg', '3811.jpg', '3818.jpg', '3842.jpg', '3875.jpg', '3891.jpg', '3906.jpg', '3958.jpg', '3959.jpg', '3969.jpg', '3977.jpg', '3978.jpg', '3982.jpg', '4029.jpg', '4041.jpg', '4084.jpg', '4090.jpg', '4094.jpg', '41.jpg', '4107.jpg', '4114.jpg', '4133.jpg', '4156.jpg', '4159.jpg', '4165.jpg', '4169.jpg', '4174.jpg', '4182.jpg', '4185.jpg', '4226.jpg', '4248.jpg', '4264.jpg', '4269.jpg', '4284.jpg', '4295.jpg', '4345.jpg', '4363.jpg', '4366.jpg', '440.jpg', '4433.jpg', '446.jpg', '4480.jpg', '4485.jpg', '4492.jpg', '4506.jpg', '4526.jpg', '4549.jpg', '4558.jpg', '4576.jpg', '4580.jpg', '4589.jpg', '4606.jpg', '4607.jpg', '4620.jpg', '4634.jpg', '4640.jpg', '4649.jpg', '4653.jpg', '4666.jpg', '478.jpg', '4786.jpg', '4791.jpg', '4797.jpg', '4803.jpg', '4814.jpg', '4827.jpg', '4832.jpg', '4849.jpg', '485.jpg', '487.jpg', '4910.jpg', '4948.jpg', '4980.jpg', '4988.jpg', '4996.jpg', '5006.jpg', '5008.jpg', '5048.jpg', '5062.jpg', '5089.jpg', '5102.jpg', '5127.jpg', '5154.jpg', '5176.jpg', '5209.jpg', '5264.jpg', '5269.jpg', '527.jpg', '5278.jpg', '5279.jpg', '5289.jpg', '5293.jpg', '5303.jpg', '531.jpg', '5318.jpg', '5340.jpg', '5356.jpg', '5417.jpg', '5445.jpg', '5452.jpg', '5468.jpg', '5477.jpg', '5490.jpg', '5493.jpg', '5523.jpg', '553.jpg', '5548.jpg', '5558.jpg', '5594.jpg', '5618.jpg', '5674.jpg', '568.jpg', '5694.jpg', '5705.jpg', '5714.jpg', '5719.jpg', '5753.jpg', '5766.jpg', '5783.jpg', '5797.jpg', '5800.jpg', '5807.jpg', '5812.jpg', '5835.jpg', '5857.jpg', '5891.jpg', '5904.jpg', '5919.jpg', '594.jpg', '5942.jpg', '5954.jpg', '5968.jpg', '5977.jpg', '5988.jpg', '6029.jpg', '6045.jpg', '6052.jpg', '6095.jpg', '6110.jpg', '6123.jpg', '613.jpg', '6136.jpg', '6169.jpg', '6175.jpg', '6183.jpg', '62.jpg', '620.jpg', '6206.jpg', '6217.jpg', '6246.jpg', '6272.jpg', '628.jpg', '629.jpg', '6368.jpg', '6378.jpg', '639.jpg', '6394.jpg', '6403.jpg', '6416.jpg', '6444.jpg', '6457.jpg', '6473.jpg', '6500.jpg', '6522.jpg', '6532.jpg', '655.jpg', '657.jpg', '6577.jpg', '659.jpg', '6603.jpg', '6616.jpg', '6677.jpg', '6686.jpg', '6689.jpg', '6691.jpg', '6700.jpg', '6703.jpg', '674.jpg', '6744.jpg', '6759.jpg', '6776.jpg', '6784.jpg', '6792.jpg', '681.jpg', '6811.jpg', '6818.jpg', '6865.jpg', '690.jpg', '6914.jpg', '6928.jpg', '693.jpg', '6935.jpg', '6977.jpg', '6989.jpg', '7017.jpg', '7020.jpg', '7026.jpg', '7029.jpg', '7065.jpg', '7080.jpg', '7100.jpg', '7116.jpg', '7159.jpg', '7162.jpg', '7191.jpg', '7200.jpg', '721.jpg', '7244.jpg', '7245.jpg', '7292.jpg', '7299.jpg', '7333.jpg', '7335.jpg', '7366.jpg', '7379.jpg', '738.jpg', '7392.jpg', '7413.jpg', '7425.jpg', '7441.jpg', '7511.jpg', '7531.jpg', '7532.jpg', '7537.jpg', '7548.jpg', '7561.jpg', '7590.jpg', '7603.jpg', '7659.jpg', '7664.jpg', '7672.jpg', '7674.jpg', '7680.jpg', '7700.jpg', '7702.jpg', '7712.jpg', '7713.jpg', '7737.jpg', '774.jpg', '7753.jpg', '7762.jpg', '7804.jpg', '7813.jpg', '7815.jpg', '7827.jpg', '7845.jpg', '7881.jpg', '7892.jpg', '7905.jpg', '7916.jpg', '7948.jpg', '7975.jpg', '7986.jpg', '8.jpg', '80.jpg', '8020.jpg', '8027.jpg', '8034.jpg', '8049.jpg', '8065.jpg', '8082.jpg', '8086.jpg', '8089.jpg', '817.jpg', '8188.jpg', '8228.jpg', '8268.jpg', '8276.jpg', '8284.jpg', '8293.jpg', '8301.jpg', '8303.jpg', '8316.jpg', '8322.jpg', '8331.jpg', '8334.jpg', '8338.jpg', '8355.jpg', '8424.jpg', '8434.jpg', '8449.jpg', '8457.jpg', '8473.jpg', '8539.jpg', '8548.jpg', '8559.jpg', '856.jpg', '8649.jpg', '8657.jpg', '8662.jpg', '8677.jpg', '8682.jpg', '8691.jpg', '8704.jpg', '873.jpg', '8753.jpg', '8756.jpg', '8762.jpg', '880.jpg', '8820.jpg', '8861.jpg', '8864.jpg', '8886.jpg', '8915.jpg', '8940.jpg', '895.jpg', '8960.jpg', '897.jpg', '898.jpg', '8993.jpg', '9005.jpg', '906.jpg', '9060.jpg', '9070.jpg', '9071.jpg', '9085.jpg', '9094.jpg', '9147.jpg', '915.jpg', '9152.jpg', '9167.jpg', '9174.jpg', '9180.jpg', '9202.jpg', '9206.jpg', '9222.jpg', '9246.jpg', '9272.jpg', '9286.jpg', '9371.jpg', '9392.jpg', '9412.jpg', '9416.jpg', '942.jpg', '9437.jpg', '9442.jpg', '9476.jpg', '9486.jpg', '951.jpg', '9538.jpg', '9542.jpg', '9570.jpg', '9571.jpg', '9598.jpg', '9599.jpg', '9605.jpg', '9640.jpg', '9687.jpg', '973.jpg', '9774.jpg', '9800.jpg', '9833.jpg', '9845.jpg', '9865.jpg', '9890.jpg', '9893.jpg', '9897.jpg', '9901.jpg', '9933.jpg', '9977.jpg', '9979.jpg', '9984.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(folder_path + \"validation/happy/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b1b1339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n",
      "Training samples: 28821\n",
      "Validation samples: 7066\n",
      "Class indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Data Augmentation and Loading\n",
    "# =======================================================================\n",
    "\n",
    "aug_map = {\n",
    "    \"none\": dict(rescale=1./255),\n",
    "    \"light\": dict(rescale=1./255, rotation_range=10, width_shift_range=0.1,\n",
    "                  height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True),\n",
    "    \"strong\": dict(rescale=1./255, rotation_range=20, width_shift_range=0.15,\n",
    "                   height_shift_range=0.15, shear_range=0.15, zoom_range=0.15,\n",
    "                   brightness_range=[0.8,1.2], horizontal_flip=True)\n",
    "}\n",
    "\n",
    "# Training data generator with standard augmentation\n",
    "datagen_train = ImageDataGenerator(**aug_map[cfg[\"aug_level\"]])\n",
    "\n",
    "datagen_validation = ImageDataGenerator(rescale=1./255)                                        \n",
    "\n",
    "# Create training set\n",
    "train_set = datagen_train.flow_from_directory(\n",
    "    os.path.join(folder_path, \"train\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Create validation set\n",
    "validation_set = datagen_validation.flow_from_directory(\n",
    "    os.path.join(folder_path, \"validation\"),\n",
    "    target_size=(picture_size, picture_size),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,  # stable evaluation\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Training samples: {train_set.n}\")\n",
    "print(f\"Validation samples: {validation_set.n}\")\n",
    "print(f\"Class indices: {train_set.class_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aaac0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     base = EfficientNetB0(weights=\u001b[33m'\u001b[39m\u001b[33mimagenet\u001b[39m\u001b[33m'\u001b[39m, include_top=\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape=(\u001b[32m48\u001b[39m,\u001b[32m48\u001b[39m,\u001b[32m3\u001b[39m))\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m cfg[\u001b[33m\"\u001b[39m\u001b[33mbackbone\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mcustom_cnn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# define your own small CNN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     y = \u001b[43mlayers\u001b[49m.Conv2D(\u001b[32m32\u001b[39m,\u001b[32m3\u001b[39m,activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m,padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m)(x)\n\u001b[32m     16\u001b[39m     y = layers.MaxPooling2D()(y)\n\u001b[32m     17\u001b[39m     y = layers.Conv2D(\u001b[32m64\u001b[39m,\u001b[32m3\u001b[39m,activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m,padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m)(y)\n",
      "\u001b[31mNameError\u001b[39m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Model Architecture - MobileNetV2 (Transfer Learning)\n",
    "# =======================================================================\n",
    "# Build model (one path only)\n",
    "inputs = Input(shape=(48, 48, 1))\n",
    "rgb = tf.keras.layers.Concatenate()([inputs, inputs, inputs])  # gray->RGB\n",
    "# =========== Backbone switch =============\n",
    "\n",
    "if cfg[\"backbone\"] == \"mobilenet_v2\":\n",
    "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(48,48,3))\n",
    "elif cfg[\"backbone\"] == \"efficientnet_b0\":\n",
    "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(48,48,3))\n",
    "elif cfg[\"backbone\"] == \"custom_cnn\":\n",
    "    # define your own small CNN\n",
    "    y = layers.Conv2D(32,3,activation='relu',padding='same')(x)\n",
    "    y = layers.MaxPooling2D()(y)\n",
    "    y = layers.Conv2D(64,3,activation='relu',padding='same')(y)\n",
    "    y = layers.GlobalAveragePooling2D()(y)\n",
    "    outputs = layers.Dense(7, activation='softmax', dtype='float32')(y)\n",
    "    model = Model(inputs, outputs)\n",
    "    base = None\n",
    "else:\n",
    "    # simple custom CNN path\n",
    "    x = Conv2D(32, 3, activation='relu', padding='same')(rgb)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(no_of_classes, activation='softmax', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    base_model = None\n",
    "\n",
    "if base is not None:\n",
    "    base.trainable = False  # initial freeze\n",
    "    y = base(x, training=False)\n",
    "    y = layers.GlobalAveragePooling2D()(y)\n",
    "    y = layers.Dense(256, activation='relu')(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "    outputs = layers.Dense(7, activation='softmax', dtype='float32')(y)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "# Using Transfer Learning with MobileNetV2 (Transfer Learning)\n",
    "\n",
    "# Load pre-trained base model\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(48, 48, 3)  # RGB input for transfer learning\n",
    ")\n",
    "\n",
    "# Freeze base model layers initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build complete model\n",
    "inputs = Input(shape=(48, 48, 1))\n",
    "\n",
    "# Convert grayscale to RGB by repeating channels\n",
    "x = tf.keras.layers.Concatenate()([inputs, inputs, inputs])\n",
    "\n",
    "# Pass through base model\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Add custom classification head\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(no_of_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "print(f\"Using {base_model.name} as feature extractor\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "opt_name = cfg[\"optimizer\"]\n",
    "lr = cfg[\"lr\"]\n",
    "\n",
    "if opt_name == \"adam\":\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "elif opt_name == \"sgd\":\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "elif opt_name == \"adamw\":\n",
    "    opt = tf.keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=1e-4)\n",
    "else:\n",
    "    raise ValueError(\"Unknown optimizer\")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data pipeline\n",
    "print(\"\\nðŸ” Testing data pipeline...\")\n",
    "sample_batch, sample_labels = next(iter(train_set))\n",
    "print(f\"Batch shape: {sample_batch.shape}\")\n",
    "print(f\"Batch dtype: {sample_batch.dtype}\")\n",
    "print(f\"Batch range: [{sample_batch.min():.3f}, {sample_batch.max():.3f}]\")\n",
    "print(f\"Labels shape: {sample_labels.shape}\")\n",
    "\n",
    "# Test model prediction with error handling\n",
    "try:\n",
    "    test_pred = model.predict(sample_batch[:1], verbose=0)\n",
    "    print(f\"Prediction shape: {test_pred.shape}\")\n",
    "    print(f\"Prediction values: {test_pred[0]}\")\n",
    "    print(\"âœ… Data pipeline working!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Prediction failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Training Callbacks\n",
    "# =======================================================================\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"best_model.keras\",\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,  # Increased patience\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_delta=0.0001,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping, reduce_learningrate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Model Training\n",
    "# =======================================================================\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Target: {epochs} epochs with early stopping\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(\"Mixed precision: ENABLED\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    steps_per_epoch=train_set.n // train_set.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=validation_set.n // validation_set.batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"âœ… Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Phase 2: fine-tune (switch applied here) ----\n",
    "def apply_freeze_strategy(base_model, strategy=\"partial\", n_layers=40):\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-n_layers]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-n_layers:]:\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False  # keep BN frozen\n",
    "\n",
    "apply_freeze_strategy(base_model, strategy=\"partial\", n_layers=40)\n",
    "\n",
    "# Recompile with lower LR\n",
    "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Optional: shorter patience for fine-tuning\n",
    "history_ft = model.fit(train_set, validation_data=validation_set, epochs=10, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4420334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Save (versioned)\n",
    "# =======================================================================\n",
    "import re, os, json\n",
    "\n",
    "def sanitize(s: str) -> str:\n",
    "    # keep alnum and a few safe chars\n",
    "    return re.sub(r'[^a-zA-Z0-9._-]+', '', str(s))\n",
    "\n",
    "def cfg_tag(cfg: dict, keys=('backbone','aug_level','optimizer','lr','precision','freeze','fine_tune_layers')):\n",
    "    # build compact tag like: b-mbv2_aug-strong_opt-adam_lr-1e-4_mp-true_ft-part40\n",
    "    kmap = {\n",
    "        'backbone': 'b',\n",
    "        'aug_level': 'aug',\n",
    "        'optimizer': 'opt',\n",
    "        'lr': 'lr',\n",
    "        'precision': 'prec',\n",
    "        'freeze': 'ft',\n",
    "        'fine_tune_layers': 'n',\n",
    "    }\n",
    "    parts = []\n",
    "    for k in keys:\n",
    "        if k in cfg:\n",
    "            v = cfg[k]\n",
    "            if k == 'backbone' and v == 'mobilenet_v2':\n",
    "                v = 'mbv2'\n",
    "            parts.append(f\"{kmap.get(k,k)}-{sanitize(v)}\")\n",
    "    return \"_\".join(parts)\n",
    "\n",
    "def save_model_versioned(model, base_name='emotion_model', extension='.keras',\n",
    "                         directory='.', save_weights=True, cfg=None):\n",
    "    tag = cfg_tag(cfg) if cfg else None\n",
    "    name_with_tag = f\"{base_name}_{tag}\" if tag else base_name\n",
    "\n",
    "    existing = [f for f in os.listdir(directory)\n",
    "                if re.match(rf'{re.escape(name_with_tag)}_v\\d+{re.escape(extension)}$', f)]\n",
    "    if existing:\n",
    "        vers = [int(re.search(rf'_v(\\d+){re.escape(extension)}$', f).group(1)) for f in existing]\n",
    "        next_v = max(vers) + 1\n",
    "    else:\n",
    "        next_v = 1\n",
    "\n",
    "    model_filename = f\"{name_with_tag}_v{next_v}{extension}\"\n",
    "    model_path = os.path.join(directory, model_filename)\n",
    "    model.save(model_path)\n",
    "    print(f\"ðŸ’¾ Saved model: {model_path}\")\n",
    "\n",
    "    paths = {'model': model_path}\n",
    "\n",
    "    if save_weights:\n",
    "        weights_filename = f\"{name_with_tag}_v{next_v}.weights.h5\"\n",
    "        weights_path = os.path.join(directory, weights_filename)\n",
    "        model.save_weights(weights_path)\n",
    "        print(f\"ðŸ’¾ Saved weights: {weights_path}\")\n",
    "        paths['weights'] = weights_path\n",
    "\n",
    "    # Optional: also save full cfg as JSON alongside\n",
    "    if cfg:\n",
    "        cfg_filename = f\"{name_with_tag}_v{next_v}.cfg.json\"\n",
    "        with open(os.path.join(directory, cfg_filename), 'w') as f:\n",
    "            json.dump(cfg, f, indent=2)\n",
    "        paths['cfg'] = os.path.join(directory, cfg_filename)\n",
    "\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b26579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Training Visualization\n",
    "# =======================================================================\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('Model Loss', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Model Accuracy', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aef709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Model Evaluation\n",
    "# =======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "train_loss, train_acc = model.evaluate(train_set, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(validation_set, verbose=0)\n",
    "\n",
    "print(f\"ðŸ“Š FINAL RESULTS\")\n",
    "print(f\"Training Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {test_loss:.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fde5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Detailed Performance Analysis\n",
    "# =======================================================================\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import load_model\n",
    "\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "# Load best model\n",
    "my_model = load_model('best_model.keras', compile=False)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "print(\"Generating predictions on validation set...\")\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for i in range(len(validation_set)):\n",
    "    batch_images, batch_labels = validation_set[i]\n",
    "    batch_predictions = my_model.predict(batch_images, verbose=0)\n",
    "    predictions.extend(np.argmax(batch_predictions, axis=1))\n",
    "    true_labels.extend(np.argmax(batch_labels, axis=1))\n",
    "    if i >= validation_set.n // test_set.batch_size:\n",
    "        break\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='rocket', \n",
    "            xticklabels=class_labels, \n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Facial Emotion Recognition', fontsize=16, pad=20)\n",
    "plt.xlabel('Predicted Emotion', fontsize=12)\n",
    "plt.ylabel('True Emotion', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“ˆ DETAILED CLASSIFICATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(true_labels, predictions, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff496014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================================\n",
    "# Export to ONNX for Snapdragon Optimization\n",
    "# =======================================================================\n",
    "\n",
    "try:\n",
    "    import tf2onnx\n",
    "    import onnx\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ Exporting model to ONNX format for Snapdragon optimization...\")\n",
    "    \n",
    "    # Convert to ONNX\n",
    "    spec = (tf.TensorSpec((None, 48, 48, 1), tf.float32, name=\"input\"),)\n",
    "    output_path = \"emotion_model.onnx\"\n",
    "    \n",
    "    model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n",
    "    \n",
    "    print(f\"âœ… Model exported to {output_path}\")\n",
    "    print(\"This model is optimized for Snapdragon X Elite inference!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ tf2onnx not installed. Run: pip install tf2onnx\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ONNX export failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\nðŸŽ‰ Training complete! Your optimized model is ready.\")\n",
    "print(f\"â±ï¸ Expected training time: 30-50 minutes on Snapdragon X Elite\")\n",
    "print(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
